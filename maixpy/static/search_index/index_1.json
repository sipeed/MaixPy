{"/maixpy/doc/zh/peripheral/hid.html":{"title":"MaixCAM MaixPy 使用 USB HID（作为设备）","content":" title: MaixCAM MaixPy 使用 USB HID（作为设备） ## 简介 HID（Human Interface Device）设备是一类计算机外围设备，用于向计算机传输输入数据，或从计算机接收输出数据。HID 设备最常见的例子包括键盘、鼠标、游戏控制器、触摸屏、和手写板等。HID 协议是一种用于人机交互设备的通信协议，它允许这些设备通过 USB、蓝牙或其他连接方式与主机进行数据交换。 MaixPy目前支持作为 USB HID 设备，比如作为键盘、鼠标和触摸屏给电脑使用，下面将会介入如何使用 MaixPy 通过 HID 来控制你的个人电脑～ > 如果你想将 USB 作为 host 模式以连接 HID 设备到 MaixCAM, 则在 `设置` 应用中将 USB 模式设置为 `host`模式即可。 ## 一定要操作的前期准备 > MaixPy 固件版本应该 > 4.5.1 在操作HID前一定要先使能HID设备，有两种方法： 1. 打开MaixCAM自带的`Settings`应用，依次点击`USB Settings` >勾选需要的HID设备，如`Keyboard`、`Mouse`、`Touchscreen`，然后点击`Confirm`后重启MaixCAM 2. 通过MaixVision中的`Examples/tools/maixcam_switch_usb_mode.py`示例，修改代码`device_list`中需要开启的HID设备，运行后重启MaixCAM 注意：由于最多只支持4个USB设备，因此在`ncm`，`rndis`，`keyboard`，`mouse`，`touchpad`之中只能同时启动4个设备，根据实际需求选择，其中`ncm`和`rndis`是USB网络协议设备，如果不需要可以关掉，默认是打开的。 ## 用MaixPy编写一个键盘 需要使能了`HID Keyboard`后才能运行。 下面示例中，向PC发送按键事件 ```python from maix import hid, time keyboard hid.Hid(hid.DeviceType.DEVICE_KEYBOARD) def press(keyboard, key): keyboard.write([0, 0, key, 0, 0, 0, 0, 0]) time.sleep_ms(50) keyboard.write([0, 0, 0, 0, 0, 0, 0, 0]) # key 0, means release def press2(keyboard, key0 0, key1 0, key2 0, key3 0, key4 0, key5 0): keyboard.write([0, 0, key0, key1, key2, key3, key4, key5]) time.sleep_ms(50) keyboard.write([0, 0, 0, 0, 0, 0, 0, 0]) # key 0, means release # key0: 0x1:left ctrl 0x2:left shift 0x4:left alt 0x8:left windows # 0x10:right ctrl 0x20:right shift 0x40:right alt 0x80:right windows def press3(keyboard, key0, key1): keyboard.write([key0, 0, key1, 0, 0, 0, 0, 0]) time.sleep_ms(50) keyboard.write([0, 0, 0, 0, 0, 0, 0, 0]) # key 0, means release # 按键编号参考[USB HID文档](https://www.usb.org))的\"Universal Serial Bus HID Usage Tables\"部分 press(keyboard, 21) # press 'r' press2(keyboard, 23, 24) # press 'tu' press3(keyboard, 0x2, 25) # press 'left shift + v' ``` 创建`hid`对象后，通过`write`方法来发送按键事件，按键事件由一个8字节的数组表示，其中： 第1字节：指示 `ctrl`、`shift`、`alt` 等修饰键状态，字节每一位代表一个修饰键：`bit0： 左ctrl`，`bit1：左shift`， `bit2：左alt`，`bit3：左GUI（例如windows键）`，`bit4：右ctrl`，`bit5：右shift`，`bit6：右alt`，`bit7：右GUI` 第2字节：保留字节 第3字节：主按键值，0代表松开按键。按键编号参考[USB HID文档](https://www.usb.org))的\"Universal Serial Bus HID Usage Tables\"部分 第4～8字节：其他按键，可以用来实现一次按下多个按键，0代表松开按键 具体使用方法可以参考上面示例的代码 ## 用MaixPy编写一个鼠标 需要使能了`HID Mouse`后才能运行。 下面示例中，每隔100ms移动鼠标5个像素。 ```python from maix import hid, time mouse hid.Hid(hid.DeviceType.DEVICE_MOUSE) button 0 # 按键状态，0表示松开，1表示按下左键，2表示按下右键，4表示按下滚轮键 x_oft 0 # 相对当前位置的偏移量，数值范围是 127~127 y_oft 0 # 相对当前位置的偏移量，数值范围是 127~127 wheel_move 0 # 滚轮移动距离，数值范围是 127~127 count 0 while True: x_oft + 5 y_oft + 5 mouse.write([button, x_oft, y_oft, wheel_move]) time.sleep_ms(100) count + 1 if count > 50: break ``` ## 用MaixPy编写一个触摸屏 需要使能了`HID Touchpad`后才能运行。 下面示例中，每隔100ms移动触摸屏150个单位，注意触摸屏的坐标系是绝对坐标，而不是相对坐标，另外需要将屏幕实际尺寸映射到[1, 0x7FFF]区间，坐标(1,1)表示左上角，坐标(0x7FFF,0x7FFF)表示右下角。 ```python from maix import hid, time touchpad hid.Hid(hid.DeviceType.DEVICE_TOUCHPAD) def touchpad_set(button, x_oft, y_oft, wheel_move): touchpad.write([button, # 按键状态，0表示松开，1表示按下左键，2表示按下右键，4表示按下滚轮键 x_oft & 0xff, (x_oft >> 8) & 0xff, # 绝对位置，最左为1, 最右为0x7fff，0表示不操作，数值范围是0～0x7fff y_oft & 0xff, (y_oft >> 8) & 0xff, # 绝对位置，最上为1, 最下为0x7fff，0表示不操作，数值范围是0～0x7fff wheel_move]) # 滚轮移动距离，数值范围是 127~127 button 0 x_oft 0 y_oft 0 wheel_move 0 count 0 while True: x_oft + 150 y_oft + 150 touchpad_set(button, x_oft, y_oft, wheel_move) time.sleep_ms(100) count + 1 if count > 50: break ```"},"/maixpy/doc/zh/peripheral/pinmap.html":{"title":"MaixCAM MaixPy Pinmap 使用介绍","content":" title: MaixCAM MaixPy Pinmap 使用介绍 update: date: 2024 06 11 author: iawak9lkm version: 1.0.0 content: 初版文档 date: 2025 08 08 author: Neucrack version: 1.1.0 content: 重构文档，更以于初学者理解 ## 什么是引脚/管脚(Pin) 引脚就是芯片/开发板硬件物理上引出来的针脚，在芯片周围，看得见摸得着的，英文我们用`Pin`来表示。 ## 什么是片上外设(Peripheral) 即芯片上（内置）的除了 CPU 计算核心以外的挂件，这里的“外”是相对于`CPU 内核`的外，和另外我们后面会说的`片外模块`则是指相对于整个芯片以外的模块区别。 比如下图是 `MaixCAM/MaixCAM Pro` 芯片内部架构图： ![](../../assets/maixcam_cpu_arch.jpg) 我们可以看到核心有 2个 RISC V 内核和一个 8051 内核，除此之外，还有很多外设比如`GPIO/UART/H.264编解码器`等等，可以成他们均为片上外设。 主要注意的是，这里的**外设不一定需要引脚引出芯片**，比如`H.264编解码器`也是一个外设，但是不需要引出引脚和外界交互。 另外需要注意，这里`GPIO`是一个外设功能，在芯片内部，和物理上引出芯片的的引脚`Pin`不等同。 ## 引脚复用/引脚映射是什么 对于一些需要用引脚与外界交互的外设，比如`GPIO / I2C`， `GPIO` 可以控制引脚输入输出，`I2C`可以通过 `2(SDA/SCL)`两个引脚和其它芯片进行通信。 最简单的做法就是每个芯片引脚对应一个引脚`Pin`，比如上面的芯片架构图中`GPIO` 有`54`个，`I2C`有 `5` 个，一共需要`54 + 2 x 5 64`个引脚。 需要引脚的外设功能越多，需要引出芯片的引脚就越多，芯片体积就需要做得越大，而实际应用中往往不需要同时用`54`个`GPIO`功能和`5`个`I2C`，我们希望在外设和引脚之间加一个引脚复用电路，实现一个引脚可以切换到`GPIO`功能，也能切换到`I2C`功能，这样我们只需要引出很少的引脚就能实现我们的应用。 比如使用 `50`个引脚，其中`10`个引脚可以选择`GPIO`功能，也能选择成为`I2C`功能，这就是引脚复用，一般英文叫`pinmux`。 由于硬件设计限制，大多数芯片一个引脚只能映射几个固定的功能，比如对于`MaixCAM Pro` 引脚映射入下图： ![maixcam_pro_io](/static/image/maixcam_pro_io.png) 以右边的 `A17`引脚为例，它有三个功能`GPIOA17 / UART0_RX / PWM5`，我们可以根据需要选择这个引脚的功能，比如这个引脚默认功能是`UART0_RX`，我们想用`PWM5`这个功能，则需要设置引脚复用。 MaixPy 中提供了`maix.peripheral.pinmap`(也可以`maix.pinmap`) 这个模块来查询和设置引脚功能复用（引脚功能映射）。 > 另外， 引脚复用的好处可以参考 > * 节省引脚数量：SoC 集成了大量的功能模块，如 CPU、GPU、内存控制器、I/O 接口、通信模块等。如果每个功能都分配独立的引脚，会导致需要的引脚数量非常庞大，增加封装的复杂性和成本。通过引脚复用，一个引脚可以在不同的模式下支持不同的功能，从而显著减少引脚的总数。 > * 降低芯片封装和制造成本：减少引脚数量可以选择更小的封装尺寸，从而降低封装和制造成本。小封装不仅降低了材料成本，还减少了芯片在电路板上的占用空间，有利于设计更紧凑的电子产品。 > * 提高设计灵活性：引脚复用提供了更大的设计灵活性。不同的应用场景可能需要不同的功能组合，通过软件配置可以根据具体需求启用不同的引脚功能。例如，同一个引脚在一个实际应用中可以作为 UART 通信接口，而在另一个实际应用中可以作为 SPI 总线接口。 > * 简化 PCB 布局：减少引脚数量可以简化印刷电路板（PCB）的布局设计。更少的引脚意味着更少的布线层数和过孔，从而简化了 PCB 设计，降低了生产难度和成本。 > * 优化性能：在某些情况下，通过复用引脚可以优化信号路径和性能。例如，通过选择适当的引脚功能组合，可以减少信号传输路径上的干扰和噪声，提高系统的整体性能和可靠性。 ## MaixPy 中使用 Pinmap ### 引脚功能图 MaixPy 支持不同的板型引出的引脚不同，这里提供了每个设备的引脚映射简图，更详细的可以看原理图或者芯片手册 Pinmux 章节： 设备型号 引脚简图 说明 完整原理图和芯片手册 MaixCAM ![](https://wiki.sipeed.com/hardware/zh/lichee/assets/RV_Nano/intro/RV_Nano_3.jpg) 板子丝印比如`A19`是引脚名，`GPIOA19/PWM7`是功能名 在[硬件资料](https://wiki.sipeed.com/hardware/zh/maixcam/index.html) 中查看 MaixCAM Pro ![maixcam_pro_io](/static/image/maixcam_pro_io.png) 第一个名如`A19`是引脚名，对应`GPIOA19/PWM7`是功能名 在[硬件资料](https://wiki.sipeed.com/hardware/zh/maixcam/maixcam_pro.html) 中查看 MaixCAM2 ![maixcam2_io](/static/image/maixcam2_io.png) 第一个名如`A2`是引脚名，对应`GPIOA2/SPI1_CS0`是功能名 在[硬件资料](https://wiki.sipeed.com/hardware/zh/maixcam/maixcam2.html) 中查看 > 注意，对于 MaixCAM2，原理图以及芯片资料中可能会有 `GPIO1_A25` 这种写法，为了看起来更简洁，我们将其定义成`B25`，是等效的，又比如`GPIO0_A2`对应 `MaixPy`中的`GPIOA2`，`GPIO3_A2`对应`MaixPy`中的`C2`。 > 即`GPIOn`这里`n`取值`0` 对应了`MaixPy`中定义的`A`，`1`对应了`B`，`GPIO1_A25`的`A25`对应 `MaixPy` 中的`25`即去掉了`A`。 ### MaixPy 中映射引脚功能 介绍了那么多，其实 `MaixPy` 使用`maix.pinmap.set_pin_function` 函数即可设置引脚功能。 以设置`MaixCAM/MaixCAM Pro` `A17`引脚为例： ```python from maix import pinmap pinmap.set_pin_function(\"A17\", \"GPIOA17\") ``` 这里`A17`是引脚的名字，`GPIOA17` 是片上外设`GPIO`的功能名，我们就能把这个默认是`UART0_RX`的功能改为`GPIO`功能了，即便我们往芯片的`UART0`发送数据，由于变成了`GPIO`功能，芯片内部也收不到信息了。 设置完引脚功能后，比如这里是设置为`GPIO`，我们就可以按照[GPIO使用](./gpio.html) 文档把这个引脚当作 `GPIO` 输出高低电平，或者读取电平使用了。 ### 获得引脚所有功能 我们可以用`maix.pinmap.get_pin_functions` 函数获得一个引脚对应的所有功能： ```python from maix import pinmap funcs pinmap.get_pin_functions(\"A17\") print(funcs) ``` 也可以打印所有引脚和对应的所有功能： ```python from maix.peripheral import pinmap print(\"All pins of MaixCAM:\") print(pinmap.get_pins()) print(\"All pin's functions:\") for pin in pinmap.get_pins(): funcs pinmap.get_pin_functions(pin) print(f\"{pin:10s}: {', '.join(funcs)}\") ``` ### 查询引脚当前功能 可以获取到当前引脚设置的功能，注意这个函数对不同板型的支持程度可能不用： * `MaixCAM / MaixCAM Pro`: 映射信息储存在一个数组里，不是直接从硬件获取，所以需要先设置过，得到的信息才是准确的。（有兴趣可以提交 PR 优化， 源码在[这里](https://github.com/sipeed/MaixCDK/blob/main/components/peripheral/port/maixcam/maix_pinmap.cpp)） * `MaixCAM2`：支持直接从硬件获取当前设置的功能，能准确无误查询到当前的功能。 ```python from maix import pinmap func pinmap.get_pin_function(\"A17\") print(func) ``` ### 更多例程 在[MaixPy](https://github.com/sipeed/MaixPy/tree/main/examples/peripheral/pinmap) 中可以看到更多例程。 ## API 文档 更详细的 Pinmap 的 API 说明请看 [Pinmap API 文档](../../../api/maix/peripheral/pinmap.html) ## 引脚默认功能和注意点 需要注意的是，引脚默认用做不同用途，使用时应注意： 设备型号 引脚简图 默认功能 需要注意的引脚 MaixCAM ![](https://wiki.sipeed.com/hardware/zh/lichee/assets/RV_Nano/intro/RV_Nano_3.jpg) 参考 `MaixCAM Pro` 1. `UART0`是系统日志+默认串口<br>WiFi(SDIO1 + A26)。<br>2. `A14` 默认是系统状态灯，初始化为`GPIO`后可以当作普通输出`GPIO`使用。<br>3. user按键默认系统已经有`key`驱动用来检测按键按下，不建议用`GPIO`读取。<br>4. 再次强调 IO 是`3.3v`电平，不要直接接`5v`电压。 MaixCAM Pro ![maixcam_pro_io](/static/image/maixcam_pro_io.png) 1. 参考外壳丝印，比如`29`就是`GPIO`，`RX` 就是串口；<br>2. `6pin` 默认`UART`和`I2C` 1. 同 `MaixCAM`。<br>2. `B3` 接了一个照明`LED` ，高电平使能。 MaixCAM2 ![maixcam2_io](/static/image/maixcam2_io.png) 1. 参考外壳丝印, 比如`A4`就是`GPIO`，`U2R` 就是串口；<br>2. `6pin` 默认`UART`和`I2C` 1. `B25` 接了一个照明`LED`，高电平使能。<br>2. `A6`引脚接了系统状态灯，初始化为`GPIO`后可以当作普通输出`GPIO`使用。<br>3. 再次强调 IO 是`3.3v`电平，不要直接接`5v`电压。"},"/maixpy/doc/zh/peripheral/uart.html":{"title":"MaixCAM MaixPy UART 串口使用介绍","content":" title: MaixCAM MaixPy UART 串口使用介绍 update: date: 2024 03 07 author: Neucrack version: 1.0.0 content: 初版文档 date: 2024 08 01 author: Neucrack version: 1.1.0 content: 优化文档，更多详细内容 date: 2025 08 08 author: Neucrack version: 1.2.0 content: 添加 MaixCAM2 支持 ## 前置知识 请先学会使用[pinmap](./pinmap.html) 模块设置引脚功能。 要让一个引脚能使用 `UART` 功能，先用`pinmap`设置对应引脚功能为`UART`。 ## 串口简介 串口是一种通信方式，包含了硬件和通信协议的定义。 * 硬件包括： * 3 个引脚： `GND`， `RX`， `TX`，通信双发**交叉连接** `RX` `TX`， 即一方 `TX` 发送到另一方的 `RX`， 双方 `GND` 连接到一起。 * 控制器，一般在芯片内部，也叫 `UART` 外设，一般一个芯片有一个或者多个 `UART` 控制器，每个控制器有相对应的引脚。 * 串口通信协议： 为了让双方能顺利通信，规定了一套协议，即以什么样的时序通信，具体可以自行学习，常见的参数有 波特率 校验位等，波特率是我们用得最多的参数。 通过板子的串口，可以和其它单片机或者 SOC 进行数据通信，比如可以在 MaixCAM 上实现人体检测功能，检测到坐标后通过串口发送给 STM32/Arduino 单片机。 ## 选择合适的 I2C 使用 首先我们需要知道设备有哪些引脚和 I2C，如图： 设备型号 引脚简图 引脚复用说明 MaixCAM ![](https://wiki.sipeed.com/hardware/zh/lichee/assets/RV_Nano/intro/RV_Nano_3.jpg) 板子丝印比如`A19`是引脚名，`UART1_TX`是功能名 MaixCAM Pro ![maixcam_pro_io](/static/image/maixcam_pro_io.png) 第一个名如`A19`是引脚名，对应`UART1_TX`是功能名 MaixCAM2 ![maixcam2_io](/static/image/maixcam2_io.png) 第一个名如`A21`是引脚名，对应`UART4_TX`是功能名 需要注意的是，引脚默认可能用做其它用途，最好避开这些引脚，请看[pinmap](./pinmap.html) 文档中的说明。 ### MaixCAM/MaixCAM Pro 串口使用注意点： * 默认从 USB 口引出了一个串口0，可以插上配套的 Type C 转接小板，就能直接使用上面的串口引脚，也可以不用转接板，直接使用板子上的 `A16(TX)` 和 `A17(RX)`引脚, 和 USB 口引出的是同样的引脚，是等效的。 * 对于 MaixCAM 使用 USB 引出的串口时需要**注意**，Typc C 正插和反插，转接小板上的 `RX` 和 `TX`会交换(默认 **Type C 母口朝前**和丝印符合)，所以当你发现无法通信时，有可能就是 RX TX 反了，可以尝试将 Type C 翻转一面插再看看通信是否正常。这个算是设计缺陷，不过一般也不会经常拔插所以适应一下也能接受。 * **MaixCAM 的`串口0` 在开机时会打印一部分开机日志**， 启动完毕后会打印`serial ready`字样，如果和单片机通信需要注意丢弃这部分信息，如果出现系统启动出现问题也可以通过查看`串口0`的开机打印来诊断问题。 * MaixCAM 的 `TX`(`UART0`) 引脚也是启动模式检测引脚之一，所以在**串口0开机时不能是被拉低**的状态，不然会导致无法开机，是芯片的特性，如果你在做 `3.3v` 转 `5v` 的电平转换电路要十分注意不要默认拉低请保持浮空（可以考虑使用电平转换芯片）。以及如果你发现无法开机，也可以先检查一下 `TX` 是否被拉低了。 * 综上，`UART0` 如果你遇到了问题不好解决，建议使用其它串口比如`UART1`。 * `UART0` 也是系统默认`maix protocol` 串口。 ### MaixCAM2 使用注意点 * `MaixCAM2`引出的串口很多，有`UART0 / UART1 / UART2 / UART3 / UART4`共 4 组串口，使用时不要混淆。 * `UART0`是系统终端和日志串口。 ### 波特率限制 注意，不是所有波特率都能使用的，推荐没有特殊需求使用 `115200`，这是芯片都支持的，其它波特率误码率可能会很高或者驱动未支持导致数据传输丢失。 这里列举不同设备的常见测试可用波特率（欢迎PR）： * `MaixCAM / MaixCAM Pro`: `115200`。 * `MaixCAM2`: `115200`。理论最高能到`4000000 bits/s`，底层`baud uart_clk /(小数分频 * 16)`，默认`uart_clk`是 `200000000`，小数分频值整数部分`uart_clk / (baud * 16)`，小数部分`round((uart_clk % (baud * 16)) * 16 / (baud * 16)) / 16`，比如`115200`计算出来分频器设置为`108.5`，实际验证精度`(115200 (uart_clk / (108.5 * 16))) / 115200 0.0064%`，所以如果你切换波特率，也可以根据这个公式进行计算精度。 ## 串口硬件接线 两个设备通信， 接三个引脚，`GND`， `RX`， `TX`，通信双发**交叉连接** `RX` `TX`， 即一方 `TX` 发送到另一方的 `RX`， 双方 `GND` 连接到一起即可。 ## MaixPy 中使用串口 将两个通信的板子双方连接好后（通信双发交叉连接 RX TX， 即一方 TX 发送到另一方的 RX， 双方 GND 连接到一起），就可以使用软件了。 通过 MaixPy 使用串口，核心代码： ```python from maix import uart serial_dev uart.UART(\"/dev/ttyS0\", 115200) serial_dev.write_str(\"Hello MaixPy\") ``` `/dev/ttyS0` 是串口设备，可以通过`print(uart.list_devices())`看到所有串口设备。 一般`/dev/ttyS*`,`*`就是串口号。 对于默认对应引脚就是串口功能的串口可以这样直接使用，其它串口则需要先用`pinmap`映射引脚功能为对应的`UART`功能，然后创建`UART`对象即可： ```python from maix import uart, pinmap, time, sys, err # ports uart.list_devices() # 列出所有串口 # get pin and UART number according to device id device_id sys.device_id() if device_id \"maixcam2\": pin_function { \"A21\": \"UART4_TX\", \"A22\": \"UART4_RX\" # \"B0\": \"UART2_TX\", # \"B1\": \"UART2_RX\" } device \"/dev/ttyS4\" # device \"/dev/ttyS2\" else: pin_function { \"A16\": \"UART0_TX\", \"A17\": \"UART0_RX\" # \"A19\": \"UART1_TX\" # \"A18\": \"UART1_RX\", } device \"/dev/ttyS0\" # device \"/dev/ttyS1\" for pin, func in pin_function.items(): err.check_raise(pinmap.set_pin_function(pin, func), f\"Failed set pin{pin} function to {func}\") # Init UART serial_dev uart.UART(device, 115200) serial_dev.write_str(\"Hello MaixPy\") ``` ## 串口连接电脑 * 有开发者可能会问：为什么插上 USB 电脑没出现串口设备？ 答： 因为设备的 USB 口是 USB 功能，不是 USB 转串口功能，而且默认会虚拟成 USB 网卡，如果要访问设备的终端，请使用 ssh 连接。 * 我想电脑和板子串口通信，怎么办？ 答： 现代电脑一般只有 USB 口，所以想电脑和板子的 UART 通信，中间需要一个 USB 转 UART 的转接板，比如[这个](https://item.taobao.com/item.htm?spm a1z10.5 c s.w4002 24984936573.13.73cc59d6AkB9bS&id 610365562537)，USB 连接电脑，串口连接开发板的串口就能通信了。 * 我想在电脑看板子串口终端打印的日志，或者终端交互，怎么操作？ 答：一般推荐通过网络 ssh 进行终端交互，如果遇到问题，可以用以下方法进入串口终端： * 对于 MaixCAM/MaixCAM Pro： 将 USB 转 UART 的转接板和板子的`串口0`（`A16(TX)`和 `A17(RX)`）引脚交叉相连，提前将系统内`/boot/uEnv.txt`中的`consoledev`一行前面加`#`号注释掉或者直接删掉使能串口0作为终端，然后重启系统就能通过串口0看到开机日志和终端交互了。 * 对于 MaixCAM2: 将 USB 转 UART 的转接板和板子的`串口0`(`U0T`/`U0R`)引脚交叉相连，就可以进行串口终端交互了，开机也会打印日志。 ## 发送数据 主要有两个函数`write_str`和`write`函数。 `write_str`函数来发送字符串，`write`用来发送字节流，即`str`和`bytes`类型，两者可以互相转换，比如: * `\"A\"` 调用`encode()`方法变成`b\"A\"`，反过来`b\"A\"`调用`decode()`方法变成`\"A\"`。 * `str` 没法显示一些不可见字符比如 ASCII 码中的值`0`，在字符串中也是`\\0`一般作为结束符，在`bytes`类型中就可以用`b\"\\x00\"`来储存。 * 对于非 ASCII 编码的字符串更有用，比如`UTF 8`编码中中文`好`是由三个字节`\\xe5\\xa5\\xbd`来表示的，我们可以通过`\"好\".encode(\"utf 8\")`得到`b\"\\xe5\\xa5\\xbd\"`，也可以通过`b'\\xe5\\xa5\\xbd'.decode(\"utf 8)`得到`\"好\"`。 所以如果我们需要发送字节数据，则用`write()`方法发送即可, 比如: ```python bytes_content b'\\x01\\x02\\x03' serial.write(bytes_content) ``` 所以对于 `str` 类型，也可以不用`write_str`，而是使用`serial.write(str_content.encode())` 来发送。 如果你有其它类型的数据，想将它们变成一个**字符串发送**，可以使用`Python 字符串格式化`来创建一个字符串，比如： 想发送`I have xxx apple`，这里`xxx` 想用一个整型变量，则： ```python num 10 content \"I have {} apple\".format(num) content2 f\"I have {num} apple\" content3 \"I have {:04d} apple\".format(num) content4 f\"I have {num:d} apple\" print(content) print(content2) print(content3) print(content4) print(type(content)) serial.write_str(content) ``` 另外你也可以把数据编码成**二进制流数据发送**，比如前 4 个字节是十六进制的 `AABBCCDD`，中间发送一个 `int` 类型的数值，最后再加一个`0xFF`结尾，使用`struct.pack`来进行编码（看不懂可以看后文的介绍）： ```python from struct import pack num 10 bytes_content b'\\xAA\\xBB\\xCC\\xDD' bytes_content + pack(\"<i\", num) bytes_content + b'\\xFF' print(bytes_content, type(bytes_content)) serial.write(bytes_content) ``` 这里 `pack(\"<i\", num)` 把 `num`编码为`int`类型即`4字节`的有符号数，`<`符号意思是小端编码，低位在前，这里`num 10`，十六进制 `4 字节`表示就是`0x0000000A`，小端就是把低字节`0x0A`放在前面，得到一个`b'\\x0A\\x00\\x00\\x00'`的字节类型数据。 > 这里只举例使用`i`编码`int`类型的数据，还有其它类型比如`B`表示`unsigned char`等等，更多的`struct.pack`格式化用法可以自行搜索`python struct pack`。 这样最终发送的就是`AA BB CC DD 0A 00 00 00 FF`二进制数据了。 ## 接收 使用`read`方法进行读取数据，直接： ```python while not app.need_exit(): data serial.read() if data: print(data) time.sleep_ms(1) ``` 同样，`read`方法获得的数据也是`bytes`类型，这里`read`会读取对方一次性发送的一串数据，如果没有数据就是`b''`即空字节。 这里用了`time.sleep_ms(1)`进行睡眠了`1ms`，用来释放 CPU，不让这个线程占用所有 CPU 资源，而且`1ms`不影响我们程序的效率，特别是在多线程时有用。 另外`read`函数有两个参数： * `len`：代表想接收的最大长度，默认` 1`代表缓冲区有多少就返回多少，传`>0`的值则代表最多返回这个长度的数据。 * `timeout`： * 默认 `0` 代表从缓冲区读取数据立马返回数据，如果`len`为 ` 1`则返回所有数据，如果指定了`len`则返回长度不超过`len` 的数据。 * `<0` 代表一直等待直到接收到了数据才返回，如果`len`为 ` 1`则等待到接收到数据才返回（一串连续接收到的数据，即阻塞式读取所有数据），如果指定了`len`则等待接收数量达到`len`才返回。 * `>0` 代表无论有没有接收到数据，超过这个时间就会返回。 看起来有点复杂，常见的参数组合： * `read()`: 即`read( 1, 0)`，从缓冲区读取收到的数据，通常是对方一次性发来的一串数据，等到对方没有发送（一个字符的发送时间内没有再发）就立刻返回。 * `read(len 1, timeout 1)`: 阻塞式读取一串数据，等到对方发送了数据并且一个字符的发送时间内没有再发才返回。 * `read(len 10, timeout 1000)`: 阻塞式读取 10 个字符，读取到 10 个字符或者 超过 1000ms 还没收到就返回已经收到的数据。 ## 设置接收回调函数 在 MCU 开发中，串口收到数据通常会有中断事件发生， MaixPy 已经在底层处理好了中断，开发者无需再处理中断。 如果你想在接收到数据时调用一个回调函数，可以用`set_received_callback`设置回调函数： ```python from maix import uart, app, time def on_received(serial : uart.UART, data : bytes): print(\"received:\", data) # send back serial.write(data) device \"/dev/ttyS0\" serial uart.UART(device, 115200) serial.set_received_callback(on_received) serial0.write_str(\"hello\\r\\n\") print(\"sent hello\") print(\"wait data\") while not app.need_exit(): time.sleep_ms(100) # sleep to make CPU free ``` 在接收到数据后会在**另外一个线程**里调用设置的回调函数，因为是在另外的线程里调用的，所以不像中断函数要尽快退出函数，你可以在回调函数里处理一些事务再退出也是可以的，注意多线程常见问题。 使用回调函数的方式接收数据请不要再使用`read`函数读取，否则会读取出错。 ## 更多串口例程 看[MaixPy examples](https://github.com/sipeed/MaixPy/tree/main/examples/peripheral/uart)。 ## 串口API 文档 更多 API 看 [UART API 文档](https://wiki.sipeed.com/maixpy/api/maix/peripheral/uart.html) ## 应用层通信协议 ### 概念和字符协议 串口只是规定了保证硬件通信的时序，为了让接收方知道发送方发送的字符流的含义，我们一般会规定一个应用通信协议。 比如发送放需要发送一个坐标，包含了`x, y`两个整型值，为了让接收方能理解我们发送的字节流的含义，我们规定： * **帧头**：当我开始发送`$`符号时，就代表我要开始发送有效的数据啦。 > **内容**：设计一个开头符号的原因是串口是流式传输，比如发送两次`12345`有可能在某个时刻接收到了`12345123`这样的数据，第二帧的`45`还没有接收到，我们可以根据起始和结尾符号来判断一个完整的数据帧。 * x， y 的取值范围是 0~65535， 即两个字节的无符号短整型(`unsinged short`)，我会先发 x 再发 y，用逗号隔开，比如`10,20`。 * **帧尾**：最后我会再发一个`*`标记来代表我这次数据发送完成了。 这样发送一次数据就类似`$10,20*`这样一个字符串，对方如果用 C 语言接收和解析： ```c // 1. 接收数据 // 2. 根据帧头帧尾判断是否接收完毕了，并将完整的一帧数据存到 buff 数组里面 // 3. 解析一帧数据 uint16_t x, y; sscanf(buff, \"$%d,%d*\", &x, &y); ``` 这样我们就制定了最简单的字符通信协议，具有一定的可靠性。 但是由于我们串口一般用的参数是`115200 8 N 1`，这里的`N`就是无奇偶校验，我们可以在自己的协议里面加一个**校验值**放在末尾，比如： * 这里我们规定 x,y 后还有一个校验值，取值范围是 0 到 255，它的值为前面所有字符加起来的和对 255 取余。 * 这里以 `$10,20`举例，在`Python`只需要使用`sum`函数就可以`sum(b'$10,20') % 255 > 20`，最终发送`$10,20,20*`。 * 接收放接收到数据后读取到校验值`20`，然后自己也同样的方式计算一遍`$10,20`的校验值，如果也是`20`说明数据传输没有发生错误，如果不相同我们则可以认为数据传输过程中发生了错误，可以丢弃等下一个数据包。 比如在 MaixPy 中，我们需要编码一个字符协议，直接使用 `Python 的字符串格式化`功能即可： ```python x 10 y 20 content \"${},{}*\".format(x, y) print(content) ``` ### 二进制通信协议 上面的字符协议有个很明显的特征，我们都是用可见字符的方式在传输数据，传输数据时有点就是简单，人眼能直接看懂； 缺点就是占用字符数量不固定，数据量比较大，比如`$10,20*`和`$1000,2000*`，同样的格式，数值不同长度不同，这里`1000`用了 4 个字符也就是4个字节，我们都知道一个无符号短整型（`uint16`）类型的数据只需要两个字节就能表示`0~65535`的取值范围，用这种表示方法可以少传输数据。 我们也知道可见字符可以通过`ASCII`码表转换成二进制表示形式，比如`$1000`查找`ASCII码表`换成二进制表示就是`0x24 0x31 0x30 0x30 0x30`一共 5 个字节，也就是我们实际传输数据的时候传输的二进制内容，如果现在我们用二进制的方式直接编码`1000`，即`0x03E8`，就可以直接发送`0x24 0x03 0xE8`，最终只需要发送 3 个字节，减少了通信开销。 另外这里`0x03E8`两个字节低位是`0xE8`，先发送低位`0xE8`我们称之为小端编码，反之则是大端编码，两个皆可，双方规定一致即可。 在 MaixPy 中，要将一个数值转换成 bytes 类型也很简单，使用`struct.pack`函数即可，比如这里的`0x03E8`也就是十进制的`1000`，我们用 ```python from struct import pack b pack(\"<H\", 1000) print(b) ``` 这里`<H`表示小端编码，`H`表示一个 `uint16`类型的数据，最终得到`b'\\xe8\\x03'`的 bytes 类型数据。 同样的，二进制协议也可以有 帧头，数据内容，校验值，帧尾等，也可以不要帧尾，而是设计一个帧长的字段，看个人喜好即可。 ### MaixPy MaixPy 内置通信协议 另外 MaixPy 也内置了一个通信协议可以直接使用，使用这个协议可以实现串口甚至 TCP 来切换应用、控制应用、获取应用发出的数据等。 比如 AI 检测应用检测到物体后发出的坐标就可以通过这个协议解析到。 ## 其它教程 * [【MaixPy/MaixCAM】视觉利器 MaixCAM 入门教程二](https://www.bilibili.com/video/BV1vcvweCEEe/?spm_id_from 333.337.search card.all.click) 看串口讲解部分 * [视觉模块和STM32如何进行串口通信](https://www.bilibili.com/video/BV175vWe5EfV/?spm_id_from 333.337.search card.all.click&vd_source 6c974e13f53439d17d6a092a499df304) * [[MaixCam]使用心得二：UART串口通信](https://blog.csdn.net/ButterflyBoy0/article/details/140577441) * 更多请自行互联网搜索"},"/maixpy/doc/zh/peripheral/spi.html":{"title":"MaixCAM MaixPy SPI 串行外设接口使用介绍","content":" title: MaixCAM MaixPy SPI 串行外设接口使用介绍 update: date: 2024 06 11 author: iawak9lkm version: 1.0.0 content: 初版文档 date: 2025 08 08 author: Neucrack version: 1.1.0 content: 重构文档，更以于初学者理解 ## 前置知识 请先学会使用[pinmap](./pinmap.html) 模块设置引脚功能。 要让一个引脚能使用 `SPI` 功能，先用`pinmap`设置对应引脚功能为`SPI`。 ## SPI 简介 前面介绍了 `I2C`，通过两根线就能实现总线一对多通信，但是有局限，比如通信速度比较低（一般`200k/400k`）， `SPI` (Serial Peripheral Interface，即串行外设接口) 也是一种一对多总线通信方式，速度更快，但是需要 `4`根线通信： * `MISO`：即主设备输入从设备输出（Master Output Slave Input），该引脚在从模式下发送数据，在主模式下接收数据。 * `MOSI`：即主设备输出从设备输入（Master Input Slave Output），该引脚在主模式下发送数据，在从模式下接收数据。 * `SCK`：串行总线时钟，由主设备输出，从设备输入。 * `NSS`/`CS`：从设备选择。它作为片选引脚，让主设备可以单独地与特定从设备通信，避免数据线上的冲突。 常用在： * 读写 Flash。 * 两个设备通信。 * 通信方式转换，比如 SPI 转以太网。 * LCD显示驱动器。 * 输出特定方波，比如 WS2812 灯，除了用 GPIO 控制， 用 SPI 输出的数据是方波的特性，也能输出特定方波信号。 在通信协议上，SPI 行为一般如下： * SPI 支持一主多从，主设备通过片选引脚来选择需要进行通信的从设备，一般情况下，从设备 SPI 接口只需一根片选引脚，而主设备的片选引脚数量等同于设备数量。主设备使能某个从设备的片选信号期间，该从设备会响应主设备的所有请求，其余从设备会忽略总线上的所有数据。 * SPI 有四种模式，取决于极性（CPOL）和相位（CPHA）的配置。 极性，影响 SPI 总线空闲时的时钟信号电平。 1. CPOL 1：表示空闲时是高电平 2. CPOL 0：表示空闲时是低电平 相位，决定 SPI 总线采集数据的跳变沿。 1. CPHA 0：表示从第一个跳变沿开始采样 2. CPHA 1：表示从第二个跳变沿开始采样 极性与相位组合成了 SPI 的四种模式： Mode CPOL CPHA 0 0 0 1 0 1 2 1 0 3 1 1 * SPI 通常支持全双工和半双工通信。 * SPI 不规定最大传输速率，没有地址方案；SPI 也没规定通信应答机制，没有规定流控制规则。 SPI 是非常常见的通信接口，通过 SPI 接口，SoC 能控制各式各样的的外围设备。 ## 选择合适的 SPI 使用 首先我们需要知道设备有哪些引脚和 SPI，如图： 设备型号 引脚简图 引脚复用说明 MaixCAM ![](https://wiki.sipeed.com/hardware/zh/lichee/assets/RV_Nano/intro/RV_Nano_3.jpg) 板子丝印比如`A24`是引脚名，`SPI4_CS`是功能名 MaixCAM Pro ![maixcam_pro_io](/static/image/maixcam_pro_io.png) 第一个名如`A24`是引脚名，对应`SPI4_CS`是功能名 MaixCAM2 ![maixcam2_io](/static/image/maixcam2_io.png) 第一个名如`B21`是引脚名，对应`SPI2_CS1`是功能名 需要注意的是，引脚默认可能用做其它用途，最好避开这些引脚，请看[pinmap](./pinmap.html) 文档中的说明。 比如： * `MaixCAM/MaixCAM Pro`: 由于其 SPI 外设的限制，只能作为 SPI 主设备使用,MaixCAM 的 SPI 暂时不支持修改硬件 CS 引脚有效电平，所有 SPI 硬件 CS 的有效电平为低电平。如需要使用其他的 CS 有效电平，请在 SPI API 中配置软件 CS 引脚及其有效电平。SPI4 为软件模拟的 SPI，实测最大速率为 1.25MHz，使用方法与硬件 SPI 无异。 * `MaixCAM2`: 默认有 2 个硬件 SPI 引脚，SPI2 默认功能就是 SPI, SPI1 的引脚需要先设置引脚复用，具体看`pinmap`。 ## MaixPy 中使用 SPI 通过 MaixPy 使用 SPI，先设置好 `pinmap`，构造`SPI`对象通信即可。 这里一个例子，先连接该 SPI 的 `MOSI` 和 `MISO`，自己全双工收发： ```python from maix import spi, pinmap, sys, err # get pin and SPI number according to device id device_id sys.device_id() if device_id \"maixcam2\": pin_function { \"B21\": \"SPI2_CS1\", \"B19\": \"SPI2_MISO\", \"B18\": \"SPI2_MOSI\", \"B20\": \"SPI2_SCK\" } spi_id 2 else: pin_function { \"A24\": \"SPI4_CS\", \"A23\": \"SPI4_MISO\", \"A25\": \"SPI4_MOSI\", \"A22\": \"SPI4_SCK\" } spi_id 4 for pin, func in pin_function.items(): err.check_raise(pinmap.set_pin_function(pin, func), f\"Failed set pin{pin} function to {func}\") spidev spi.SPI(spi_id, spi.Mode.MASTER, 1250000) ### Example of full parameter passing, fully documention see API documentation. # spidev spi.SPI(id 4, # SPI ID # mode spi.Mode.MASTER, # SPI mode # freq 1250000, # SPI speed # polarity 0, # CPOL 0/1, default is 0 # phase 0, # CPHA 0/1, default is 0 # bits 8, # Bits of SPI, default is 8 # hw_cs 1, # use default hardware cs. # soft_cs \"\", # If you want use soft cs, set GPIO name, # # e.g. GPIOA19(MaixCAM), GPIOA2(MaixCAM2) # # you should set pinmap first by yourself. # cs_active_low true # cs pin active low voltage level b bytes(range(0, 8)) res spidev.write_read(b, len(b)) if res b: print(\"loopback test succeed\") else: print(\"loopback test failed\") print(f\"send:{b}\\nread:{res}\") ``` ## 更多例程 看[MaixPy examples](https://github.com/sipeed/MaixPy/tree/main/examples/peripheral/spi)。 ## API 文档 更多 API 看 [SPI API 文档](https://wiki.sipeed.com/maixpy/api/maix/peripheral/spi.html)"},"/maixpy/doc/zh/peripheral/adc.html":{"title":"MaixCAM MaixPy ADC 使用介绍","content":" title: MaixCAM MaixPy ADC 使用介绍 update: date: 2024 06 11 author: iawak9lkm version: 1.0.0 content: 初版文档 ## 支持的设备 设备 是否支持 MaixCAM2 ❌ MaixCAM / MaixCAM Pro ✅ ## ADC 简介 ADC，即模拟信号数字转换器，将一个输入电压信号转换为一个输出的数字信号。由于数字信号本身不具有实际意义，仅仅表示一个相对大小。故任何一个模数转换器都需要一个参考模拟量作为转换的标准，参考标准一般为最大的可转换信号大小。而输出的数字量则表示输入信号相对于参考信号的大小。 ADC 外设一般有两个主要参数：分辨率和参考电压。 * 分辨率：ADC 的分辨率以输出二进制（或十进制）数的位数来表示。它说明 A/D 转换器对输入信号的分辨能力。一般来说，n 位输出的 A/D 转换器能区分 2^n 个不同等级的输入模拟电压，能区分输入电压的最小值为满量程输入的 1/(2^n)。在最大输入电压一定时，输出位数愈多，分辨率愈高。 * 参考电压：ADC 参考电压是在 AD 转换过程中与已知电压进行比较来找到未知电压的值的电压。参考电压可以认为是最高上限电压，当信号电压较低时，可以降低参考电压来提高分辨率。 通过板子的 ADC，可以采集外部的电压，并让板子检验电压是否达标，或是在检测到特定的电压时执行特定的任务（例如 ADC 检测多个按钮）。 ## MaixPy 中使用 ADC 通过 MaixPy 使用 ADC 很简单： ```python from maix.peripheral import adc from maix import time a adc.ADC(0, adc.RES_BIT_12) raw_data a.read() print(f\"ADC raw data:{raw_data}\") time.sleep_ms(50) vol a.read_vol() print(f\"ADC vol:{vol}\") ``` 使用 ADC0，从中读取原始的转换数据，或是直接从中读取电压数据。 有关 ADC API 的详细说明请看 [ADC API 文档](../../../api/maix/peripheral/adc.html) ## 关于 MaixCAM ADC 外设的一些说明 MaixCAM 引出一个连接 ADC 的 IO，为 GPIO B3，如下图所示（对于MaixCAM Pro 由于 B3 已经连接到了闪光灯， ADC 无法直接使用）： ![](https://wiki.sipeed.com/hardware/zh/lichee/assets/RV_Nano/intro/RV_Nano_3.jpg) 该 IO 默认为 ADC， 无需额外进行配置。 MaixCAM ADC 外设采样精度为 12bit，也就是说采样输出范围为 0~4095。采样精度为参考电压的 1/4096。 MaixCAM ADC 外设的扫描频率不能高于 320K/s，也就是上述示例中增加延时的原因。 MaixCAM ADC 外设内部参考电压Vref为 1.5V，实际使用时会有些许偏差。因为内部参考电压典型值为 1.5V，所以 Soc 的 ADC 量程为 0～1.5V。该量程的 ADC 应用范围较小，故 MaixCAM 额外为 ADC 外设设计了分压电路来增大 ADC 的应用范围，该分压电路如下图所示。由于电路中电阻阻值存在误差、ADC 外设有阻抗、内部参考电压有些许偏差，该分压电路的参考电压 Vin_max 约为 4.6~5.0V。API 中已经选择一个精度较高的默认值，一般情况下无需传递该参数。 ![](https://wiki.sipeed.com/hardware/zh/lichee/assets/RV_Nano/peripheral/adc.png) 若需要较高的精度，可以通过以下步骤计算出该分压电路的参考电压： * 先测得 ADC_PIN 的实际输入电压 Vin。 * 然后测得 ADC1 处的实际输入电压 Vadc，电阻R10的位置可参考这个 [BOM](https://cn.dl.sipeed.com/fileList/LICHEE/LicheeRV_Nano/03_Designator_drawing/LicheeRV_Nano 70405_iBOM.rar) 表。 * 保持第一步的电压输入，在shell中执行以下命令： ```shell echo 1 > /sys/class/cvi saradc/cvi saradc0/device/cv_saradc cat /sys/class/cvi saradc/cvi saradc0/device/cv_saradc ``` 此时你将获得 ADC 原始数据 adc_data。 * 接地电阻为 R10，另一个电阻为 R6, 记录它们的阻值。通常，MaixCAM 的 R6 阻值为 10KΩ（10 000Ω），R10 阻值为 5.1KΩ（5 100Ω）。 * 将上述参数传递给以下 python 代码，即可得出 ADC_PIN 端的量程 [0, Vin_max] （闭区间）。 ```python def maixcam_get_vin_max(Vin:float, Vadc:float, adc_data:int, r6:int, r10:int, adc_max:int 4095): Vref (Vadc/adc_data)*(adc_max+1) r3 Vadc*r6/(Vin Vadc) Vin_max (Vref/r3)*(r6+r3) return Vin_max Vin 3.3\t\t# step 1 Vadc 1.06\t\t# step 2 adc_data 2700\t# step 3 r6 10000\t\t# step 4 r10 5100\t\t# step 4 if __name__ '__main__': print(maixcam_get_vin_max(Vin, Vadc, adc_data, r6, r10)) ``` 现在将结果传递给 `adc.ADC()` 的第三个参数，你将获得一个高精度的 ADC。"},"/maixpy/doc/zh/peripheral/gpio.html":{"title":"MaixCAM MaixPy 使用 GPIO","content":" title: MaixCAM MaixPy 使用 GPIO ## 简介 使用 GPIO 可以控制引脚输入或者输出高低电平，用来读取信号或者输出控制信号，十分常用。 **注意** `MaixCAM` 的引脚是 `3.3V` 耐受，**请勿**输入 `5V` 电压。 ## 前置知识 请先学会使用[pinmap](./pinmap.html) 模块设置引脚功能。 要让一个引脚能使用 `GPIO` 功能，先用`pinmap`设置对应引脚功能为`GPIO`。 ## 选择合适的 GPIO 使用 首先我们需要知道设备有哪些引脚和 GPIO，如图： 设备型号 引脚简图 引脚复用说明 MaixCAM ![](https://wiki.sipeed.com/hardware/zh/lichee/assets/RV_Nano/intro/RV_Nano_3.jpg) 板子丝印比如`A19`是引脚名，`GPIOA19/PWM7`是功能名 MaixCAM Pro ![maixcam_pro_io](/static/image/maixcam_pro_io.png) 第一个名如`A19`是引脚名，对应`GPIOA19/PWM7`是功能名 MaixCAM2 ![maixcam2_io](/static/image/maixcam2_io.png) 第一个名如`A2`是引脚名，对应`GPIOA2/SPI1_CS0`是功能名，即使用`GPIO`功能只需要在`IO`名前面加一个`GPIO`即可。 需要注意的是，引脚默认可能用做其它用途，最好避开这些引脚，请看[pinmap](./pinmap.html) 文档中的说明。 ## 电路注意点 注意引脚的电压耐受能力和负载能力有限，设计电路时需要注意，避免比如经常有新手问`为什么引脚不能直接让电机转动`等基础问题。 * **引脚电压耐压**：除非有特殊说明，引脚都是`3.3v`电平，请勿外接`5v`电压。 * **引脚输入输出电流**：芯片引脚的输入输出电流有限，一般只拿来作为控制信号，对于大电流需求的器件请使用转换电路。 **举例**：控制 LED 灯，简单的电路如下： ![](../../assets/gpio_led.png) `LED` 直接由引脚输出高电平供电，这是最直观的使用方式，但是要十分小心，芯片引脚的输出和输入电流有上限，也就是驱动能力（一般在芯片手册中会描述）， 这里电流为`3.3v/(LED+电阻 阻值)` < `0.64mA`， 所以能直接这样驱动，如果你的电路电流太大，就会驱动失败甚至导致芯片无法正常工作。 **正确的做法**是外接一个转换电路，让引脚只作为控制开关的信号，比如利用三极管/光耦/继电器转换等，这里不详细阐述，请自行扩展学习。 ## GPIO 输出模式 LED 的电路图如图所示，所以我们只需要给 `A14`(`MaixCAM2` 是 ` A6`) 引脚一个高电平 LED 就会导通并亮起来： ![](../../assets/gpio_led.png) ```python from maix import gpio, pinmap, time, sys, err pin_name \"A6\" if sys.device_id() \"maixcam2\" else \"A14\" gpio_name \"GPIOA6\" if sys.device_id() \"maixcam2\" else \"GPIOA14\" err.check_raise(pinmap.set_pin_function(pin_name, gpio_name), \"set pin failed\") led gpio.GPIO(gpio_name, gpio.Mode.OUT) led.value(0) while 1: led.toggle() time.sleep_ms(500) ``` * 首先根据板子型号获得引脚和功能名。 * 使用`pinmap`设置了引脚的功能为`GPIO`。 * `err.check_raise` 用来检测`set_pin_function`的返回值，如果出错直接报错，防止我们手误写错了值。 * 初始化 `GPIO` 对象，设置为输出模式。 * 每隔`0.5s`翻转一次输出值，效果就是`LED`会交替闪烁。 更多 API 请看 [GPIO API 文档](https://wiki.sipeed.com/maixpy/api/maix/peripheral/gpio.html) ## GPIO 作为输入模式 ```python from maix import gpio, pinmap, time, err err.check_raise(pinmap.set_pin_function(\"A19\", \"GPIOA19\"), \"set pin failed\") led gpio.GPIO(\"GPIOA19\", gpio.Mode.IN) while 1: print(led.value()) time.sleep_ms(1) # sleep to make cpu free ``` ## MaixCAM Pro 使用照明 LED `MaixCAM / MaixCAM Pro` 和 `MaixCAM2` 都有一个 LED 小灯，即接到了引脚 `A14` 和 `A6`， 另外 `MaixCAM Pro` 和 `MaixCAM2` 还板载了一个`照明 LED`，分别连接到了 `B3` 和 `B25` 引脚，也是高电平开启低电平关闭： ```python from maix import gpio, pinmap, time, sys, err pin_name \"B25\" if sys.device_id() \"maixcam2\" else \"B3\" gpio_name \"GPIOB25\" if sys.device_id() \"maixcam2\" else \"GPIOB3\" err.check_raise(pinmap.set_pin_function(pin_name, gpio_name), \"set pin failed\") led gpio.GPIO(gpio_name, gpio.Mode.OUT) led.value(0) while 1: led.toggle() time.sleep_ms(500) ``` ## 更多例程 看[MaixPy examples](https://github.com/sipeed/MaixPy/tree/main/examples/peripheral/gpio)。 ## API 文档 更多 API 看 [GPIO API 文档](https://wiki.sipeed.com/maixpy/api/maix/peripheral/gpio.html)"},"/maixpy/doc/zh/peripheral/wdt.html":{"title":"MaixCAM MaixPy 使用看门狗定时器","content":" title: MaixCAM MaixPy 使用看门狗定时器 ## 简介 为了防止程序出现问题，常常会用到看门狗定时器（WDT), 在程序出问题时自动重启系统。 原理就是有一个倒计时计数器，我们需要在程序的逻辑中定期地去设置这个倒计时时间（也叫喂狗），如果我们的程序在哪儿卡住了导致没有定期去设置倒计时，倒计时到 0 后硬件就会出发系统重启。 ## MaixPy 中使用 WDT ```python from maix import wdt, app, time w wdt.WDT(0, 1000) while not app.need_exit(): w.feed() # here sleep op is our operation # 200 ms is normal, if > 1000ms will cause system reset time.sleep_ms(200) ```"},"/maixpy/doc/zh/gui/i18n.html":{"title":"MaixPy MaixCAM i18n(国际化) 多语言实现","content":" title: MaixPy MaixCAM i18n(国际化) 多语言实现 ## i18n （国际化）简介 i18n 是国际化单词（internationalization）的简称，目的在与根据用户的地域或者喜好切换语言。 我们常用的 中文 和 英文 这个就是语言，语言有对应的地域编码（ LCID），比如中文的地域编码为`zh`，英文为`en`，日文为`ja`，另外还有二级地域编码，比如简体中文对应`zh cn`，一般我们实现`zh`即可。 地域编号可以参考[Windows的地域编码表](https://www.science.co.il/language/Locale codes.php) 或者看 [wikipedia](https://en.wikipedia.org/wiki/Language_localisation)。 ## MaixPy MaixCAM 中使用 i18n 用户使用大致流程如下： * 首先用户使用时，在系统设置中可以选择系统语言，比如出厂默认是`en`即英文。 * 然后程序通过`maix.i18n.get_locale()`可以获得当前系统设置的地域。 * 程序根据系统设置的地域显示对应语言的字符串。 对于应用程序来说，比较麻烦的地方就在这里的第三步，即根据地域设置查表获取对应的字符串，下面提供两种方法，根据自己的需求选择： 完整的例程源码在[MaixPy](https://github.com/sipeed/MaixPy) `examples/gui/i18n`中。 ### 不使用翻译文件，直接使用字典 如果你的程序只有几个字符串，可以直接手动指定翻译字典： ```python from maix import i18n trans_dict { \"zh\": { \"hello\": \"你好\" }, \"en\": { } } trans i18n.Trans(trans_dict) tr trans.tr trans.set_locale(\"zh\") print(tr(\"hello\")) print(tr(\"my friend\")) ``` 这里用`trans.set_locale(\"zh\")`临时设置语言为中文了， 运行就会打印`你好` 和 `my friend` 了， 因为没给`my friend`填加翻译，所以原封不动地返回了。 ### 自动扫描生成字典，并且从翻译文件加载 这种方法比较适合有大量需要翻译的字符串的场景。 前面的方法我们手动指定了字符串翻译，在简单场景很方便，但是如果字符串太多了，手动改字典很容易漏掉，所以我们需要程序自动帮我们找到需要翻译的字符串并生成翻译文件，我们只需要翻译一下文件就好了。 在 MaixPy 中，提供了`maix.i18n.Trans` 这个类，可以用来加载多种语言的翻译文件，调用其成员函数`tr()`，传入想要翻译的文字即可获得翻译，举例： ```python from maix import i18n, err trans i18n.Trans() tr trans.tr e trans.load(\"locales\") err.check_raise(e, \"load translation yamls failed\") print(tr(\"hello\")) ``` 这里从当前目录下的`locales`文件夹加载了翻译文件，然后根据系统的语言设置打印`hello`，比如中文就会打印`你好`。 **翻译文件**： 既然这里加载用到了翻译文件，这些翻译文件怎么制作呢？ 首先我们需要知道我们需要翻译那些文字，显而易见，就是上面我们用函数`tr`调用的字符串，所以我们只需要搜索源码中所有用到了`tr`函数的字符串即可认为是我们需要翻译的所有字符串了。 所以使用流程如下： * 建立一个项目文件夹，里面存放代码入口`main.py`，可以使用 `MaixVision`` 打开这个项目文件夹方便运行。 * 编写`main.py`，让需要翻译的字符串都用上述的`tr`函数调用。 * MaixPy 提供了一个扫描工具，首先确保安装了`maixtool`（电脑通过系统终端 `pip install maixtool U` 命令来安装升级）。 * 然后在目录下仍然使用电脑终端执行`maixtool i18n d . r`来扫描需要翻译的字符串，并且生成一个`locales`目录，里面包含了中英文两种语言的翻译文件，如果要更多语言，执行`maixtool i18n h`查看帮助。 * 生成的文件是键值对组成的，比如`zh.yaml`中的`hello: hello` 的意思就是字符串`hello`中文翻译是`hello`，这显然不对，需要我们手动翻译一下，改成`hello: 你好`即可。注意编辑文件一定要用支持 `UTF 8` 编码的编辑器，特别是在`Windows`下不要将文件改为`GBK`编码了，不然会出错，可以用 MaixVision 或者 VsCode 编辑。 * 然后运行项目，或者打包项目为安装包都可以，记得把 `locales` 目录也一起打包进去。 * 如果后面又更新了源码，需要再次执行`maixtool`命令更新文件，更新会对之前已经翻译了的文件更新，如果你担心程序不小心将之前的错误覆盖，可以先自行备份一份，确认无误后再删除备份。 这样你的程序就会根据系统语言设置更改语言了，如果你调试程序也可以手动调用`trans.set_locale(\"zh\")`来手动临时切换语言。 ## 显示翻译到界面 前面的例子都是在调用`print`函数打印，如果想显示到界面上，还有一步要做，就是需要字库支持，对于英文来说默认都支持了，可是对于中文这种字库庞大的语言，默认是不支持的。 比如： ```python from maix import i18n, image, display, app, time trans_dict { \"zh\": { \"hello\": \"你好\" }, \"en\": { } } trans i18n.Trans(trans_dict) tr trans.tr trans.set_locale(\"zh\") disp display.Display() img image.Image(disp.width(), disp.height()) img.draw_string(10, 10, tr(\"hello\"), image.COLOR_WHITE, scale 2) disp.show(img) while not app.need_exit(): time.sleep_ms(100) ``` 运行会发现显示了一堆`?`，因为没有中文字库，对于`image`模块，可以加载字库，系统内置了一个中文字库，你也可以用你自己的字库： ```python from maix import i18n, image, display, app, time trans_dict { \"zh\": { \"hello\": \"你好\" }, \"en\": { } } trans i18n.Trans(trans_dict) tr trans.tr trans.set_locale(\"zh\") disp display.Display() image.load_font(\"sourcehansans\", \"/maixapp/share/font/SourceHanSansCN Regular.otf\", size 24) image.set_default_font(\"sourcehansans\") img image.Image(disp.width(), disp.height()) img.draw_string(10, 10, tr(\"hello\"), image.COLOR_WHITE, scale 2) disp.show(img) while not app.need_exit(): time.sleep_ms(100) ```"},"/maixpy/doc/zh/video/jpeg_streaming.html":{"title":"MaixCAM MaixPy 视频流 JPEG 推流 / 发送图片到服务器","content":" title: MaixCAM MaixPy 视频流 JPEG 推流 / 发送图片到服务器 update: date: 2024 04 03 author: neucrack version: 1.0.0 content: 初版文档 date: 2024 05 20 author: lxowalle version: 1.0.1 content: 更新JPEG HTTP用法 ## 简介 有时需要将图像发送到服务器，或者将摄像头的视频推送到服务器，这里提供两种方法: 一个最简单的方法，即压缩成 `JPEG` 图片，然后一张一张地发送到服务器。注意，这是一种最简单的方法，不算很正规的视频推流方法，也不适合高分辨率高帧率的视频流，因为这只是一张一张发送图片，如果要高效推送视频流，请使用后文的 `RTSP` 或者 `RTMP` 模块。 建立一个HTTP服务器, 让PC端可以通过浏览器直接访问 ## 作为客户端推流的方法 ```python from maix import image import requests # create image img image.Image(640, 480, image.Format.FMT_RGB) # draw something img.draw_rect(60, 60, 80, 80, image.Color.from_rgb(255, 0, 0)) # convert to jpeg jpeg img.to_format(image.Format.FMT_JPEG) # image.Format.FMT_PNG # get jpeg bytes jpeg_bytes jpeg.to_bytes() # faster way, borrow memory from jpeg object, # but be carefully, when jpeg object is deleted, jpeg_bytes object MUST NOT be used, or program will crash # jpeg_bytes jpeg.to_bytes(copy False) # send image binary bytes to server url \"http://192.168.0.123:8080/upload\" res requests.post(url, data jpeg_bytes) print(res.status_code) print(res.text) ``` 可以看到，先将图片转换成了 `JPEG` 格式，然后将 `JPEG` 图片的二进制数据通过`TCP`发送到服务器。 ## 作为服务器推流的方法 ```python from maix import camera, time, app, http html \"\"\"<!DOCTYPE html> <html> <head> <title>JPG Stream</title> </head> <body> <h1>MaixPy JPG Stream</h1> <img src \"/stream\" alt \"Stream\"> </body> </html>\"\"\" cam camera.Camera(320, 240) stream http.JpegStreamer() stream.set_html(html) stream.start() print(\"http://{}:{}\".format(stream.host(), stream.port())) while not app.need_exit(): t time.ticks_ms() img cam.read() jpg img.to_jpeg() stream.write(jpg) print(f\"time: {time.ticks_ms() t}ms, fps: {1000 / (time.ticks_ms() t)}\") ``` 步骤： 1. 导入image、camera和http模块 ```python from maix import image, camera, http ``` 2. 初始化摄像头 ```python cam camera.Camera(320, 240) # 初始化摄像头，输出分辨率320x240 RGB格式 ``` 3. 初始化Stream对象 ```python stream http.JpegStreamer() stream.start() ``` `http.JpegStreamer()`用来创建一个`JpegStreamer`对象，这个对象将会启动一个`http服务器`，用来向客户端发布`jpeg`图像流 `stream.start()`用来启动`http服务器` 4. 自定义html样式（可选） ```python html \"\"\"<!DOCTYPE html> <html> <head> <title>JPG Stream</title> </head> <body> <h1>MaixPy JPG Stream</h1> <img src \"/stream\" alt \"Stream\"> </body> </html>\"\"\" stream.set_html(html) ``` `html xxx`是`html`代码，可以用来定制自己的网页风格。注意核心代码是`<img src \"/stream\" alt \"Stream\">`，一定不要漏了这行代码。 `stream.set_html(html)`用来设置自定义的`html`代码，这一步是可选的。默认浏览地址是`http://设备的ip:8000`。 5. 从摄像头获取图片并推流 ```python while 1: img cam.read() jpg img.to_jpeg() stream.write(jpg) ``` `img cam.read()`从摄像头获取一张图像，当初始化的方式为`cam camera.Camera(320, 240)`时，`img`对象是一张分辨率为320x240的RGB图。 `jpg img.to_jpeg()`将图像转换为`jpeg`格式 `stream.write(jpg)`向服务器写入图像格式，`http`服务器将会把这个图像发送到`http`客户端。 6. 完成，运行上须代码后, 你可以通过浏览器直接看到视频流, 默认地址为`http://设备的ip:8000`。打开你的浏览器看看吧！"},"/maixpy/doc/zh/video/play.html":{"title":"MaixPy 播放视频","content":" title: MaixPy 播放视频 update: date: 2024 08 19 author: lxowalle version: 1.0.0 content: 初版文档 ## 简介 本文档提供播放视频功能的使用方法。 `MaixPy`支持播放`h264`、`mp4`、`flv`格式的视频，需要注意目前只支持`avc`编码的`mp4`和`flv`文件。此外由于硬件编码器限制，如果播放视频时发现无法解码，先尝试`ffmpeg`重新编码一遍后再试，参考命令： ```shell ffmpeg i input_video.mp4 c:v libx264 x264opts \"bframes 0\" c:a aac strict experimental output_video.mp4 ``` ## 播放`MP4`视频 一个播放`mp4`视频的示例，视频文件路径为`/root/output.mp4` ```python from maix import video, display, app disp display.Display() d video.Decoder('/root/output.mp4') print(f'resolution: {d.width()}x{d.height()} bitrate: {d.bitrate()} fps: {d.fps()}') d.seek(0) while not app.need_exit(): ctx d.decode_video() if not ctx: d.seek(0) continue img ctx.image() disp.show(img) print(f'need wait : {ctx.duration_us()} us') ``` 步骤： 1. 导入模块并初始化摄像头 ```python from maix import video, display, app disp display.Display() ``` `disp display.Display()`用来初始化显示屏，用于显示解码的图像 2. 初始化`Decoder`模块 ```python d video.Decoder('/root/output.mp4') ``` `d video.Decoder('/root/output.mp4')`用来初始化解码器，并设置需要播放的视频文件路径。如果你需要播放`flv`文件，则可以填写`flv`为后缀的文件路径，例如`{your_file_path}.flv`，如果你需要播放`h264`文件，则可以填写`h264`为后缀的文件路径，例如`{your_file_path}.h264` 3. 设置解码的位置 ```python d.seek(0) ``` 可以用来设置播放视频的位置，单位是秒 4. 获取解码后的图像 ```python ctx d.decode_video() img ctx.image() ``` 每次调用都会返回一帧图像的上下文`ctx`，通过`ctx.image()`获取`img`。目前解码后只能支持输出`NV21`格式的图像 5. 显示解码后的图像 ```python disp.show(img) ``` 显示图像时使用`ctx.duration_us()`可以获取每帧图像的时长，单位是微秒 6. 完成，更多`Decoder`的用法请看[API文档](https://wiki.sipeed.com/maixpy/api/maix/video.html)"},"/maixpy/doc/zh/video/record.html":{"title":"MaixCAM MaixPy 录像","content":" title: MaixCAM MaixPy 录像 update: date: 2024 05 20 author: lxowalle version: 1.0.0 content: 初版文档 ## 简介 本文档提供录像功能的使用方法 ## 示例一 一个录入`h265`格式视频的示例 ```python from maix import video, image, camera, app, time cam camera.Camera(640, 480, image.Format.FMT_YVU420SP) e video.Encoder() f open('/root/output.h265', 'wb') record_ms 2000 start_ms time.ticks_ms() while not app.need_exit(): img cam.read() frame e.encode(img) print(frame.size()) f.write(frame.to_bytes()) if time.ticks_ms() start_ms > record_ms: app.set_exit_flag(True) ``` 步骤： 1. 导入模块并初始化摄像头 ```python from maix import video, image, camera, app, time cam camera.Camera(640, 480, image.Format.FMT_YVU420SP) ``` `camera.Camera（）`用来初始化摄像头， 这里初始化摄像头分辨率为`640x480`，注意目前`Encoder`只支持`NV21`格式，因此设置图像格式为`image.Format.FMT_YVU420SP`。 2. 初始化`Encoder`模块 ```python e video.Encoder() ``` `video.Encoder()`模块目前只支持处理`image.Format.FMT_YVU420SP`格式图像，支持`h265`和`h264`编码, 默认为`h265`编码。如果你想使用`h264`编码，则可以修改初始化参数为` video.Encoder(type video.VideoType.VIDEO_H264_CBR)` 注意，同时只能存在一个编码器 3. 编码摄像头的图像 ```python img cam.read() frame e.encode(img) ``` `img cam.read()`读取摄像头图像并保存到`img` `frame e.encode(img)`对`img`编码并保存结果到`frame` 4. 保存编码结果到文件 ```python f open('/root/output.h265', 'wb') f.write(frame.to_bytes(False)) ``` `f open(xxx)`打开并创建一个文件 `f.write(frame.to_bytes(False))`将编码结果`frame`转换为`bytes`类型，然后调用`f.write()`将数据写入文件中 5. 定时2s退出 ```python record_ms 2000 start_ms time.ticks_ms() while not app.need_exit(): if time.ticks_ms() start_ms > record_ms: app.set_exit_flag(True) ``` 这里是定时退出的应用逻辑，自己看看吧 6. 完成 ## 示例二 一个录入`h265`格式视频的示例 ```python from maix import video, time, image, camera, app cam camera.Camera(640, 480, image.Format.FMT_YVU420SP) e video.Encoder(capture True) e.bind_camera(cam) f open('/root/output.h265', 'wb') record_ms 2000 start_ms time.ticks_ms() while not app.need_exit(): frame e.encode() img e.capture() print(frame.size()) f.write(frame.to_bytes(True)) if time.ticks_ms() start_ms > record_ms: app.set_exit_flag(True) ``` 与示例一类似，区别在于调用了`Encoder`对象的`bind_camera`方法，`Encoder`主动取图，这样的优点是可以充分利用硬件特性，增加编码速率 ``` e video.Encoder(capture True) e.bind_camera(cam) frame e.encode() img e.capture() ``` `e video.Encoder(capture True)`使能了`capture`参数，让编码时可以抓取编码的图像 `e.bind_camera(cam)`将摄像头绑定到`Encoder`对象 `frame e.encode()`编码时不需要再传入`img`，而是内部从摄像头取图 `img e.capture()`从`Encoder`对象中抓取编码的图像 ## 转换为MP4格式 如果想要录制`mp4`格式视频，可以先录制好`H265`视频，再使用系统内的`ffmpeg`工具转换为`mp4`格式 ```python import os # Pack h265 to mp4 # /root/output.h265 是h265文件路径 # /root/output.mp4 是mp4文件路径 os.system('ffmpeg loglevel quiet i /root/output.h265 c:v copy c:a copy /root/output.mp4 y') ```"},"/maixpy/doc/zh/video/uvc_streaming.html":{"title":"MaixCAM MaixPy 视频流 UVC 推流 / 化身 UVC 摄像头显示自定义内容","content":" title: MaixCAM MaixPy 视频流 UVC 推流 / 化身 UVC 摄像头显示自定义内容 update: date: 2024 12 20 author: taorye version: 1.0.0 content: 初版文档 ## 简介 `MaixCAM` 化身 `UVC 摄像头`, `UVC` 全称为：USB video(device) class，这里提供两种方法供显示自定义内容: 通过 `maix.uvc.UvcStreamer` 的 `show` 方法来刷新目标图片（支持 YUYV 和 MJPEG）， 通过 `maix.uvc.UvcServer` 注册自定义刷图回调函数来刷新目标图片（仅支持 MJPEG），区别于上一个方法的顺序逻辑，使用有一定的难度 ## 参考例程 首先需要在 `Settings` APP 的 `USB settings` 栏内启用 `UVC` 功能。 连接 usb 线缆后： Windows 用户可在`设置 蓝牙和设备 摄像头`内，看到 UVC Camera设备，点进去即可预览到一张静态小猫图。 Linux 用户，需要下载软件 `guvcview`，并选择分辨率为 320x240，格式为 MJPG，会看到两个小猫中间隔着乱码（原因是该小猫图片实际分辨率为 224x224，该软件自动拼了下一张过来，实际使用时使用正常的分辨率即可） 注意： 当前 Ubuntu 22 及更早系统版本使用的 guvcview 软件版本为 2.0.7，已知现象是显示色彩不对，严重偏绿。请换用更高版本即可正常显示，作者当前使用的版本号是 2.2.1。Ubuntu/Debian 用户可以尝试寻找相关的 PPA（个人包档案）来安装较新的 guvcview 版本。 注意： `UVC` 功能启用后，因为 Linux 的 `UVC Gadget` 实现，仍需一个用户程序处理 `UVC` 设备的事件， 否则整个 `USB` 功能会暂停等待，影响同时启用的其它 `Gadget` 功能，包括 `Rndis` 和 `NCM`，导致断网。 故对于其它 `USB` 功能有需求的用户，在基于 `MaixPy` 开发 UVC 显示功能时建议采用 `UvcStreamer` 的实现。 否则请保证 `MaixCAM` 设备有其它联网途径如 `WIFI` 以确保能正常开发调试。 <video controls autoplay src \"../../assets/maixcam pro_uvcdemo.mp4\" type \"video/mp4\"> 您的浏览器不支持视频播放 </video> ### UvcStreamer 该方法不影响常态下 USB 功能，原理是分了两个进程。官方默认实现了一个 `server` 进程进行`UVC` 设备的事件处理，并封装了易用统一的刷图接口 `show(img)` 供用户使用，当成一个 `display` 线性逻辑操作即可。 参考示例源码路径： `MaixPy/examples/vision/streaming/uvc_stream.py` 示例分析（使用方法）： 1. 初始化 UvcStreamer 对象 ```python uvcs uvc.UvcStreamer() ``` （可选）切换成 MJPEG 模式，默认 YUYV ```python uvcs.use_mjpg(1) ``` 2. 刷图（自动处理格式，MJPEG 中等性能损耗，YUYV 高损耗） ```python uvcs.show(img) ``` ### UvcServer 高性能单进程实现，但仅在运行时 USB 全部功能才可用，故停止该进程时需要注意仍启用的 `Rndis` 和 `NCM` 会暂时失效，断开网络链接。 参考示例源码路径：`MaixPy/examples/vision/streaming/uvc_server.py` 另有封装成 APP 的源码路径：`MaixCDK/projects/app_uvc_camera/main/src/main.cpp` 示例分析（使用方法）： 1. 初始化 UvcServer 对象，需提供刷图回调函数实现 提供了 helper 函数 `helper_fill_mjpg_image` 帮助将更通用的 `Image` 对象刷入 `UVC` 的缓冲区。 ```python cam camera.Camera(640, 360, fps 60) # Manually set resolution # 手动设置分辨率 def fill_mjpg_img_cb(buf, size): img cam.read() return uvc.helper_fill_mjpg_image(buf, size, img) uvcs uvc.UvcServer(fill_mjpg_img_cb) ``` `fill_mjpg_img_cb` 参考实现仅当返回 `0` 时，才会正常触发缓冲区刷新。 故推荐在最后一行使用 helper 函数即可： `return uvc.helper_fill_mjpg_image(buf, size, img)` 2. 启动 uvc，后台启动线程，非阻塞 ```python uvcs.run() ``` 3. 停止 uvc，不再使用时需要调用，可恢复 `UvcStreamer` 方法实现中的后台进程，保证 `USB` 功能正常 目前有 BUG，MaixPy 框架在退出时会强制终止进程，导致并不能执行完 `while not app.need_exit():` 循环后的函数调用，即该 `stop()` 很难得到执行。 故对 **保证 `USB` 功能正常** 有需求的用户可以换用 `UvcStreamer` 方法或是移步 `MaixCDK` 的原始 C++ API，参考例程：`MaixCDK/examples/uvc_demo/main/src/main.cpp`。 ```python uvcs.stop() ```"},"/maixpy/doc/zh/video/rtsp_streaming.html":{"title":"MaixCAM MaixPy 视频流 RTSP 推流","content":" title: MaixCAM MaixPy 视频流 RTSP 推流 update: date: 2024 05 20 author: lxowalle version: 1.0.0 content: 初版文档 ## 简介 本文档提供通过RTSP推流摄像头画面的方法 ## 使用方法 ```python from maix import time, rtsp, camera, image cam camera.Camera(2560, 1440, image.Format.FMT_YVU420SP) server rtsp.Rtsp() server.bind_camera(cam) server.start() print(server.get_url()) while True: time.sleep(1) ``` 步骤： 1. 导入time、rtsp、camera和image模块 ```python from maix import time, rtsp, camera, image ``` 2. 初始化摄像头 ```python cam camera.Camera(2560, 1440, image.Format.FMT_YVU420SP) # 初始化摄像头，输出分辨率2560x1440 NV21格式 ``` 注意RTSP模块目前只支持NV21格式， 因此摄像头需要配置为NV21格式输出 3. 初始化并启动Rtsp对象 ```python server rtsp.Rtsp() server.bind_camera(cam) server.start() ``` `server rtsp.Rtsp()`用来创建一个`Rtsp`对象 `server.bind_camera(cam)`用来绑定一个`Camera`对象， 绑定后原`Camera`对象将不能再使用 `server.start()`用来启动`rtsp`推流 4. 打印当前RTSP流的URL ```python print(server.get_url()) ``` `server.get_url()`用来获取`RTSP`的`播放地址`。 6. 完成，运行上须代码后, 你可以通过[VLC](https://www.videolan.org/vlc/)软件播放视频流, 已测试的`VLC`版本是`3.0.20`. 默认播放地址为`rtsp://设备的ip:8554/live` ## 支持推流音频 MaixPy支持同时推送音视频流, 通过绑定一个`Recorder`对象后可以在推送视频流的同时附带音频数据 > 注:MaixPy v4.7.8之后的版本支持该方法（不包括v4.7.8） 参考代码如下: ```python from maix import time, rtsp, camera, image, audio cam camera.Camera(640, 480, image.Format.FMT_YVU420SP) audio_recorder audio.Recorder() server rtsp.Rtsp() server.bind_camera(cam) server.bind_audio_recorder(audio_recorder) server.start() print(server.get_url()) while True: time.sleep(1) ``` 上文中通过`audio.Recorder()`创建一个`audio_recorder`对象,并使用`Rtsp`的`bind_audio_recorder()`方法绑定该对象, 使用`ffplay rtsp://设备的ip:8554/live`命令或者`vlc 3.0.20`就能接收音视频数据了"},"/maixpy/doc/zh/video/rtmp_streaming.html":{"title":"MaixCAM MaixPy 视频流 RTMP 推流","content":" title: MaixCAM MaixPy 视频流 RTMP 推流 update: date: 2024 05 20 author: lxowalle version: 1.0.0 content: 初版文档 ## 简介 本文档提供通过RTMP推送H264视频流的方法 ## 使用方法 ```python from maix import camera, time, rtmp, image cam camera.Camera(640, 480, image.Format.FMT_YVU420SP) # rtmp://192.168.0.30:1935/live/stream host '192.168.0.30' port 1935 app 'live' stream 'stream' bitrate 1000_000 r rtmp.Rtmp(host, port, app, stream, bitrate) r.bind_camera(cam) r.start() while True: time.sleep(1) ``` 步骤： 1. 导入camera, time, rtmp和image模块 ```python from maix import camera, time, rtmp, image ``` 2. 初始化摄像头 ```python cam camera.Camera(640, 480, image.Format.FMT_YVU420SP) # 初始化摄像头，输出分辨率640x480 NV21格式 ``` 注意RTMP模块目前只支持NV21格式， 因此摄像头需要配置为NV21格式输出 3. 初始化并启动Rtmp对象 ```python r rtmp.Rtmp(host, port, app, stream, bitrate) r.bind_camera(cam) r.start() ``` `r rtmp.Rtmp(host, port, app, stream, bitrate)`用来创建一个`Rtmp`对象，其中`host`指rtmp服务器的ip地址或者域名，`app`指rtmp服务器开放的应用名，`stream`指rtmp流的名称，也可以作为本次推流的密钥 `r.bind_camera(cam)`用来绑定一个`Camera`对象， 绑定后原`Camera`对象将不能再使用 `r.start()`用来启动`rtmp`推流 4. 完成 ## 支持推流音频 MaixPy支持同时推送音视频流, 通过绑定一个`Recorder`对象后可以在推送视频流的同时附带音频数据 > 注:MaixPy v4.7.8之后的版本支持该方法（不包括v4.7.8） 参考代码如下: ```python from maix import camera, time, app, rtmp, image, audio cam camera.Camera(640, 480, image.Format.FMT_YVU420SP) audio_recorder audio.Recorder() host \"192.168.0.63\" port 1935 app_name \"live\" stream_name \"stream\" client rtmp.Rtmp(host, port, app_name, stream_name) client.bind_camera(cam) client.bind_audio_recorder(audio_recorder) client.start() print(f\"rtmp://{host}:{port}/{app_name}/{stream_name}\") while not app.need_exit(): time.sleep(1) ``` 上文中通过`audio.Recorder()`创建一个`audio_recorder`对象,并使用`Rtmp`的`bind_audio_recorder()`方法绑定该对象, 推流的同时把音频数据也推送出去了. ## 向Bilibili推流测试 ### 启动bilibili直播 1. 点击直播 ![](../../../static/image/bilibili_click_live.png) 2. 点击开播设置 ![](../../../static/image/bilibili_click_live_setting.png) 3. 通过`我的直播间链接`找到直播地址 ![](../../../static/image/bilibili_check_live_link.png) 4. 往下翻，选择一个`分类`，再点击开始直播 ![](../../../static/image/bilibili_live_start.png) 5. 执行步骤4后，可以看到 ![](../../../static/image/bilibili_check_rtmp_url.png) 直播服务器的地址为：`rtmp://live push.bilivideo.com/live bvc` 串流密钥为：`?streamname live_xxxx&key 1fbfxxxxxxxxxxxxxffe0&schedule rtmp&pflag 1` 组合起来的`rtmp`推流地址就是：`rtmp://live push.bilivideo.com/live bvc/?streamname live_xxxx&key 1fbfxxxxxxxxxxxxxffe0&schedule rtmp&pflag 1` ### 运行RTMP客户端 ```python from maix import camera, time, rtmp, image cam camera.Camera(640, 480, image.Format.FMT_YVU420SP) # rtmp://live push.bilivideo.com/live bvc/?streamname live_xxxx&key 1fbfxxxxxxxxxxxxxffe0&schedule rtmp&pflag 1 host 'live push.bilivideo.com' port 1935 app 'live bvc' stream '?streamname live_xxxx&key 1fbfxxxxxxxxxxxxxffe0&schedule rtmp&pflag 1' bitrate 1000_000 r rtmp.Rtmp(host, port, app, stream, bitrate) r.bind_camera(cam) r.start() while True: time.sleep(1) ``` 上面拿到bilibili的推流地址为`rtmp://live push.bilivideo.com/live bvc/?streamname live_xxxx&key 1fbfxxxxxxxxxxxxxffe0&schedule rtmp&pflag 1` 可以拆出 1. 服务器地址为`live push.bilivideo.com` 2. 端口号为`1935`，即没有端口号则默认为`1935` 3. 应用名为`live bvc` 4. 流名称为`?streamname live_xxxx&key 1fbfxxxxxxxxxxxxxffe0&schedule rtmp&pflag 1` 运行代码，就能在直播间看到`maixcam`的画面了，如果发现直播没有显示，可以尝试先关闭直播间，再重新打开直播间，再运行代码。 动手试试吧～"},"/maixpy/doc/zh/modules/tmc2209.html":{"title":"MaixPy tmc2209 单串口驱动使用介绍","content":" title: MaixPy tmc2209 单串口驱动使用介绍 update: date: 2024 08 21 author: iawak9lkm version: 1.0.0 content: 初版文档 ## TMC2209 简介 TMC2209是一款由德国Trinamic公司生产的步进电机驱动芯片。它专为2相步进电机设计，具有低功耗、高效率和良好的噪声抑制能力。TMC2209支持高达2.8A的电流，适用于各种步进电机应用，如3D打印机、CNC机床、机器人等。 ## MaixPy 中使用 tmc2209 驱动步进电机 * 请确保您的步进电机为两相四线步进电机, 然后确认您的电机步进角度(step_angle), 需要使用的微步数(micro_step), 以及该电机旋转一圈时, 负载移动的距离(screw_pitch或round_mm). 以便我们后续配置驱动参数. * 一般来说, 市面上的 TMC2209 的驱动板有以下这些引脚(如果您嫌麻烦, 可以采购我司在售的 TMC2209 驱动板, 链接[暂未上架,敬请期待]): ``` EN VM MS1 GND MS2 2B RX 2A TX 1A NC 1B STEP VDD DIR GND ``` `EN`: EN 为使能脚, 将该引脚接到 `GND` 以硬件使能 TMC2209. `MS1`: MS1 为微步进选择引脚之一，与 MS2 引脚配合使用，用于设置步进电机的微步进模式。 `MS2`: MS2 为微步进选择引脚之一，与 MS1 引脚配合使用，用于设置步进电机的微步进模式。 **This driver program only supports the UART mode of TMC2209. In UART mode, the original microstep selection pins `MS1` and `MS2` are redefined as `AD0` and `AD1`, respectively. The combination of the logic levels of these two pins determines the UART address of the TMC2209, with a value range from 0x00 to 0x03. This means that a single UART port can connect up to 4 TMC2209 drivers with different addresses. For example, when `MS1` is at a low level (0) and `MS2` is at a high level (1), the UART address is binary 0b10, which is hexadecimal 0x02.** `TX`: TX 为串行通信发送引脚，用于与外部微控制器进行串口通信。 `RX`: RX 为串行通信接收引脚，用于与外部微控制器进行串口通信。 在 TMC2209 上, 同时使用 `RX` 和 `TX` 时, 请确保 TMC2209 驱动板 `RX` 与主控芯片 `TX` 间存在 1K 欧姆的电阻. 否则会出现通信数据异常. `NC`: NC 为未连接引脚，表示该引脚在正常使用中不需要连接。 `STEP`: STEP 为步进信号输入引脚，每接收到一个脉冲信号，步进电机前进一个步进角度。因为本驱动为纯 UART 方式驱动,故该引脚不需要连接, 悬空即可. `DIR`: DIR 为方向信号输入引脚，用于控制步进电机的旋转方向。当 DIR 为高电平时，电机顺时针旋转；当 DIR 为低电平时，电机逆时针旋转。因为本驱动为纯 UART 方式驱动,故该引脚不需要连接, 悬空即可. `VM`: VM 为电源输入引脚，连接到步进电机的电源正极。 `GND`: GND 为接地引脚，连接到电源的负极。 `2B`, `2A`, `1B`, `1A`: 这些引脚为步进电机的相位输出引脚，分别连接到步进电机的两相线圈。 `VDD`: VDD 为逻辑电源输入引脚，为芯片内部的逻辑电路提供电源。 * 使用 MaixPy 中的 TMC2209 驱动 以一个步进角度为18,微步数为256,螺距为3mm的丝杆步进电机为例: ```python from maix import pinmap, ext_dev, err, time port \"/dev/ttyS1\" uart_addr 0x00 uart_baudrate 115200 step_angle 18 micro_step 256 screw_pitch 3 speed 6 use_internal_sense_resistors True run_current_per 100 hold_current_per 100 if port \"/dev/ttyS1\": ret pinmap.set_pin_function(\"A19\", \"UART1_TX\") if ret ! err.Err.ERR_NONE: print(\"Failed in function pinmap...\") exit( 1) ret pinmap.set_pin_function(\"A18\", \"UART1_RX\") if ret ! err.Err.ERR_NONE: print(\"Failed in function pinmap...\") exit( 1) slide ext_dev.tmc2209.ScrewSlide(port, uart_addr, uart_baudrate, step_angle, micro_step, screw_pitch, speed, use_internal_sense_resistors, run_current_per, hold_current_per) def reset_callback() > bool: if 2 > 1: # An event occurs (e.g., a sensor is triggered), # indicating that the slide has moved to the boundary and the motor needs to stop. print(\"Reset finish...\") return True # Not occurred, no need to stop the motor. return False def move_callback(per:float) > bool: # per is the percentage of the current distance moved by move() # out of the total distance required for the current move(), ranging from 0 to 100. print(f\"Slide moving... {per}\") if per > 50: # Example: Stop moving when 50% of the total distance for the current move() has been covered. print(f\"{per} > 50%, stop.\") return True return False slide.reset(reset_callback) slide.move(screw_pitch*2, 1, move_callback) slide.move( screw_pitch) while True: slide.move(screw_pitch*2) slide.move( (screw_pitch*2)) time.sleep_ms(100) ``` 程序中需要先使用 `pinmap` 确保 UART1 被启用. 然后创建一个 `ScrewSlide` 对象, 默认使用内部参考电阻, 默认使用 100% 的电机运行电流和 100% 的电机保持电流. 这些参数可能需要根据您的电机进行调整. 然后例程声明了一个reset回调函数和一个move回调函数并分别传入reset()函数和move()函数中. reset() 和 move() 会每隔一段时间调用回调函数以确认是否需要立即停止电机(当回调函数返回True). move() 和 reset() 函数均为阻塞函数, 只有在回调函数返回True时(move还能在运动完指定长度时)停止电机并返回. ## MaixPy 中使用 tmc2209 驱动恒定负载的步进电机 **!!!丝杆步进电机携带恒定负载也不能视为带恒定负载的步进电机, 因为丝杆步进电机有限位装置以保证负载在杠上的运动方向是可知的, 丝杆步进电机运行时会与限位装置经常碰撞导致电机负载并不是恒定的. 其他情况举一反三即可知是否为恒定负载步进电机.** 某些应用场景中, 步进电机全程的负载恒定, 只有在接触到边缘堵转时负载变高. 那么可以使用 `Slide` 类代替 `ScrewSlide` 类, 在这种情况下 `Slide` 具备堵转检测功能. 使用 `ScrewSlide` 也是可行的, 不具备堵转检测但是更加灵活. 请结合使用场景来选择这两个类, 本节只讲 `Slide` 类. * 实现原理 TMC2209 内部存在一个寄存器 `SG_RESULT`, 该寄存器保存的数据与驱动电机剩余力矩成正比. 如果电机负载恒定, 该寄存器值变化幅度很小, 在堵转时, 该寄存器值将会快速减小并维持一个较低的值. 找到该恒定负载电机这个寄存器的运行平均值和堵转平均值, 即可衡量该电机在某时刻是否堵转. * 获取 `SG_RESULT` 寄存器的平均值 `maix.ext_dev.tmc2209` 中提供了获取并保存该平均值的函数 `maix.ext_dev.tmc2209.slide_scan`. example: ```python from maix import ext_dev, pinmap, err port \"/dev/ttyS1\" uart_addr 0x00 uart_baudrate 115200 step_angle 1.8 micro_step 256 round_mm 60 speed 60 use_internal_sense_resistors True run_current_per 100 hold_current_per 100 if port \"/dev/ttyS1\": ret pinmap.set_pin_function(\"A19\", \"UART1_TX\") if ret ! err.Err.ERR_NONE: print(\"Failed in function pinmap...\") exit( 1) ret pinmap.set_pin_function(\"A18\", \"UART1_RX\") if ret ! err.Err.ERR_NONE: print(\"Failed in function pinmap...\") exit( 1) ext_dev.tmc2209.slide_scan(port, uart_addr, uart_baudrate, step_angle, micro_step, round_mm, speed, True, True, run_current_per, hold_current_per, conf_save_path './slide_scan_example.bin', force_update False) ``` 配置好串口和驱动器参数, 然后调用 `slide_scan`. `slide_scan` 的最后一个参数 `force_update` 决定了在该配置文件已经存在时的行为: > 如果 `force_update` 为 True, 将会用新的配置覆盖旧的配置 > > 如果 `force_update` 为 False, 运行平均值将会更新为新旧值的平均值, 堵转平均值将会更新成新旧堵转平均值中较大的那一个值(例如一个滑胎有左右边界, 左边界堵转平均值小于右边界堵转平均值, 也就是说右边界比左边界更容易堵转, 保存最容易堵转的平均值). 该程序执行后, 步进电机会一直保持正向旋转, 当遇到堵转时, 稍等300ms左右, 停止该程序. 程序会记录运行时的 `SG_RESULT` 寄存器平均值和堵转时的寄存器平均值到 `conf_save_path` 中. 后续 `Slide` 类可以加载该配置文件实现堵转时停止电机. * 验证配置文件的值 或许您会好奇这个配置到底能不能用. `maix.ext_dev.tmc2209` 提供了测试该配置文件的函数 `slide_test`. 先保证电机微处于堵转状态, 然后修改参数以匹配您调用 `slide_scan` 的参数, 执行以下代码. example ```python from maix import ext_dev, pinmap, err port \"/dev/ttyS1\" uart_addr 0x00 uart_baudrate 115200 step_angle 1.8 micro_step 256 round_mm 60 speed 60 use_internal_sense_resistors True run_current_per 100 hold_current_per 100 if port \"/dev/ttyS1\": ret pinmap.set_pin_function(\"A19\", \"UART1_TX\") if ret ! err.Err.ERR_NONE: print(\"Failed in function pinmap...\") exit( 1) ret pinmap.set_pin_function(\"A18\", \"UART1_RX\") if ret ! err.Err.ERR_NONE: print(\"Failed in function pinmap...\") exit( 1) ext_dev.tmc2209.slide_test(port, uart_addr, uart_baudrate, step_angle, micro_step, round_mm, speed, True, True, run_current_per, hold_current_per, conf_save_path './slide_scan_example.bin') ``` 电机将会在堵转瞬间停止转动, 程序也会随之结束. `Slide.move()` 和 `Slide.reset()` 堵转停止逻辑也是如此. * 使用 `Slide` 使用 `Slide` 的思路与 `ScrewSlide` 基本无异, 只是 `Slide` 取消了回调函数并增加了堵转停止逻辑. 如果使用 `Slide` 时未传入配置文件, `Slide`也是可以使用的. 堵转检测阈值为电机运行开始时的平均数*`Slide.stop_default_per()`/100. 电机运行近期平均数低于该值时电机停止. 可以通过 `Slide.stop_default_per()` 获取和修改该值. ```python from maix import pinmap, ext_dev, err, time port \"/dev/ttyS1\" uart_addr 0x00 uart_baudrate 115200 step_angle 1.8 micro_step 256 round_mm 60 speed 60 use_internal_sense_resistors True run_current_per 100 hold_current_per 100 if port \"/dev/ttyS1\": ret pinmap.set_pin_function(\"A19\", \"UART1_TX\") if ret ! err.Err.ERR_NONE: print(\"Failed in function pinmap...\") exit( 1) ret pinmap.set_pin_function(\"A18\", \"UART1_RX\") if ret ! err.Err.ERR_NONE: print(\"Failed in function pinmap...\") exit( 1) slide ext_dev.tmc2209.Slide(port, uart_addr, uart_baudrate, step_angle, micro_step, round_mm, speed, cfg_file_path \"./slide_conf.bin\") slide.reset() slide.move(60) slide.move( 60) ``` ## 注意事项 **本驱动程序由纯串口实现, 优点是占有引脚占用引脚较少即可实现至多4个较高精度的电机驱动. 缺点是不适用于高精度要求的应用场景.** 已知问题: * 请勿使用 MaixCAM 的 UART0 作为驱动串口, 会导致 MaixCAM 无法正常开机等问题. **!!!如有BUG, 非常欢迎您提交 PR 反馈.** ## 免责声明 本电机驱动程序（以下简称“程序”）是由[Sipeed]基于BSD 3开源协议的仓库 [janelia arduino/TMC2209](https://github.com/janelia arduino/TMC2209) 进行修改和使用的。本程序仅供学习和研究使用，不保证在所有环境和条件下都能正常工作。使用本程序的风险由用户自行承担。 [Sipeed]不对因使用或无法使用本程序而导致的任何损失或损害承担责任，包括但不限于直接损失、间接损失、偶然损失、特殊损失、惩罚性损失或后果性损失。 用户在实际应用中使用本程序前，应自行进行充分的测试和验证，确保程序符合其特定需求和环境。[Sipeed]不对程序的准确性、可靠性、完整性或适用性做出任何明示或暗示的保证。 用户在使用本程序时应遵守所有适用的法律法规，并确保不侵犯任何第三方的合法权益。[Sipeed]不对因用户违反法律法规或侵犯第三方权益而导致的任何后果承担责任。 本免责声明的解释权归[Sipeed]所有，并保留随时修改本免责声明的权利。"},"/maixpy/doc/zh/modules/thermal_cam.html":{"title":"MaixCAM MaixPy 使用热红外图像传感器","content":" title: MaixCAM MaixPy 使用热红外图像传感器 ## 效果演示 单热成像效果图: ![](../../assets/thermal002.jpg) 热成像和可见光融合效果图 (左侧为冷饮,右侧为工作中的小主机): ![](../../assets/thermal001.png) 该 APP 已集成到 MaixCAM Release 镜像中, 安装支持的模块, 启动 `Thermal Camera` APP 即可 [APP 安装地址](https://maixhub.com/app/87) [源码地址](https://github.com/sipeed/MaixCDK/tree/main/projects/app_thermal_camera) ## 适配列表 * PMOD_Thermal32 [咨询购买地址](https://wiki.sipeed.com/en/store.html) ### PMOD_Thermal32 ![](../../assets/thermal003.jpg) PMOD_Thermal32 是工业标准并经过完全校准的 32*24 像素热红外阵列传感器, 模块参数: 参数名称 分辨率32x24 测温范围 40～450℃ 帧率1~30fps 接口I2C 安装 PMOD_Thermal32 模块后, 可以使用 MaixPy 提供的 API 获得模块测得的温度数据矩阵、伪彩图、最近一帧数据中的最小最大以及中心温度的值和对应的坐标等信息, 详情见 [模块 API 文档](../../../api/maix/ext_dev/mlx90640.html) 您也可以参考我们的效果演示 APP 编写您的应用代码."},"/maixpy/doc/zh/modules/bluetooth.html":{"title":"MaixCAM 蓝牙使用介绍","content":" title: MaixCAM 蓝牙使用介绍 update: date: 2025 04 08 author: lxowalle version: 1.0.0 content: 初版文档 ## 蓝牙使用介绍 ​\t蓝牙是一种常见的短距离无线通信技术，主要用于在两个或多个设备之间建立低功耗、点对点或局部网络的连接。它工作在2.4GHz的频段，最初被设计来替代有线数据线，实现设备之间的小量数据传输。在现代生活中，蓝牙已经成为我们日常使用频率极高的一种技术。例如，当我们在驾车时将手机连接到车载蓝牙系统，可以实现免提通话或播放音乐；使用蓝牙耳机听音乐或打电话时，摆脱了传统耳机线的束缚；在智能家居中，通过蓝牙与门锁、灯光、温湿度传感器等设备联动，构建便捷、高效的居住环境。 ## 使用准备 ​\t对于 MaixCAM和MaixCAM Pro内置了AIC8800D WIFI/蓝牙双模芯片，但是由于IO资源紧张，默认没有连通主控和蓝牙。如果想要使用蓝牙，则需要将`GPIOA18`,`GPIOA19`,`GPIOA28`,`GPIOA29`与蓝牙的通路间各焊接一颗0欧电阻。 MaixCAM焊接0欧电阻的位置如下图所示： ![](../../assets/maixcam_enable_ble.png) MaixCAM Pro焊接0欧电阻的位置如下图所示： ![](../../assets/maixcam_pro_enable_ble.png) > 注意下文主要通过命令行描述蓝牙基础，如果有更多开发需求的同学请先自己探索一下～ ## 使能蓝牙 ```shell hciattach n /dev/ttyS1 any 1500000 & hciconfig hci0 up ``` ## 连接蓝牙鼠标 这里使用bluetoothctl工具配置蓝牙 ```shell bluetoothctl\t\t\t# 启动bluetoothctl ## 在bluetoothctl的终端下输入下面命令 ## power on # 开启蓝牙 agent on # 开启 agent default agent # 设置为默认代理 scan on # 扫描设备 # 扫描时找到需要连接的蓝牙MAC地址 pair {设备的MAC地址} # 配对设备 trust {设备的MAC地址} # 信任设备 connect {设备的MAC地址} # 连接设备 # 连接成功后退出 exit ``` 验证鼠标数据 ```shell # 执行hcidump命令，可以观察到终端打印所有hci消息 hcidump # 执行btmon命令，同样可以观察到捕获的HCI事件 btmon ``` ## 其它参考 * [使用MaixCAM的蓝牙功能 · 硬件篇](https://maixhub.com/share/58) * [使用MaixCAM的蓝牙功能 · 软件篇](https://maixhub.com/share/62)"},"/maixpy/doc/zh/modules/fp5510.html":{"title":"MaixPy FP5510 使用说明","content":" title: MaixPy FP5510 使用说明 update: date: 2024 12 02 author: lxowalle version: 1.0.0 content: 初版文档 ## FP5510 简介 FP5510是一款单10位DAC,具有120mA输出的电流音圈电机,专为自动对焦操作设计,常用于相机,手机等需要对焦的电子设备. ## MaixPy 中使用 FP5510 MaixPy支持使用`FP5510`对象来操作`fp5510` 示例代码: ```python from maix.ext_dev import fp5510 fp fp5510.FP5510() fp.set_pos(value) position fp.get_pos() print(f'set position to {position}') ``` 使用`fp5510.FP5510()`方法构造一个操作`fp5510`的对象.一般情况, fp5510可能有`0x0e`和`0x0c`两种从机地址, 通过`slave_addr`参数指定从机地址, 例如: > 注意: 如果发现fp5510的地址在`0x0e`和`0x0c`间变化,可能是因为`fp5510`与`摄像头`共用了reset引脚,当使能reset脚时fp5510地址是`0x0c`, 当失能reset脚时fp5510地址是`0x0e` ```python fp fp5510.FP5510(slave_addr 0x0c) ``` 使用`FP5510`类的`set_pos`方法来设置音圈电机的位置,范围为[0, 1023], 例如: ```python fp.set_pos(500) ``` 使用`FP5510`类的`get_pos`方法来获取音圈电机的位置, 例如: ```python position fp.get_pos() print(f'set position to {position}') ```"},"/maixpy/doc/zh/modules/pmu.html":{"title":"MaixCAM MaixPy 电源管理单元","content":" title: MaixCAM MaixPy 电源管理单元 update: date: 2024 11 08 author: 916BGAI version: 1.0.0 content: 初版文档 <br/> >! 警告 ！！！ >设置错误的电压可能会损坏 `MaixCAM Pro`。除非明确了解调整目的和后果，否则请勿修改 `DCDC2~DCDC5`、`ALDO1~ALDO4` 和 `BLDO1~BLDO2` 的电压。 ## 简介 `MaixCAM Pro` 板载了 `AXP2101` 电源管理单元，提供多通道电源输出、充电管理以及系统保护功能。`AXP2101` 支持线性充电，拥有 `5` 个 `DC DC` 通道和 `11` 个 `LDO` 通道，能够满足多种电源需求。它还配备了多通道 `ADC`，用于实时监控电压和温度，并集成了过压、过流和过温等保护功能，确保系统的稳定性和安全性。 > MaixCAM 没有板载电源管理单元，如需使用电源管理功能请自行外接。 ## MaixPy 中使用电源管理单元 使用 `PMU` 模块操作 `AXP2101` 设备。 示例代码: ```python from maix import time, app from maix.ext_dev import pmu p pmu.PMU(\"axp2101\") # Get battery percent print(f\"Battery percent: {p.get_bat_percent()}%\") # Set the max battery charging current p.set_bat_charging_cur(1000) print(f\"Max charging current: {p.get_bat_charging_cur()}mA\") # Set DCDC1 voltage (!!! Do not modify the voltage of other channels, # as it may damage the device.) old_dcdc1_voltage p.get_vol(pmu.PowerChannel.DCDC1) print(f\"Old DCDC1 voltage: {old_dcdc1_voltage}mV\") p.set_vol(pmu.PowerChannel.DCDC1, 3000) new_dcdc1_voltage p.get_vol(pmu.PowerChannel.DCDC1) print(f\"New DCDC1 voltage: {new_dcdc1_voltage}mV\") # Get all channel voltages channels [ pmu.PowerChannel.DCDC1, pmu.PowerChannel.DCDC2, pmu.PowerChannel.DCDC3, pmu.PowerChannel.DCDC4, pmu.PowerChannel.DCDC5, pmu.PowerChannel.ALDO1, pmu.PowerChannel.ALDO2, pmu.PowerChannel.ALDO3, pmu.PowerChannel.ALDO4, pmu.PowerChannel.BLDO1, pmu.PowerChannel.BLDO2 ] print(\" All channel voltages: \") for channel in channels: print(f\"{channel.name}: {p.get_vol(channel)}\") print(\" \") # Poweroff (Important! Power will be cut off immediately) # p.poweroff() while not app.need_exit(): time.sleep_ms(1000) ``` > 也可以使用 `AXP2101` 模块对电源管理单元进行设置。使用方法和 `PMU` 模块类似，可以参考例程 [axp2101_example.py](https://github.com/sipeed/MaixPy/blob/main/examples/ext_dev/pmu/pmu_axp2101/axp2101_example.py) 初始化 `PMU` 对象，调用 `get_bat_percent()` 即可获取当前电池电量。调用 `set_bat_charging_cur()` 可以设置最大充电电流。 调用 `poweroff()` 设备将立即断电。在使用前，请确保将内存中的数据同步到磁盘。 调用 `set_vol()` 和 `get_vol()` 方法可以分别设置和读取 `DC DC` 和 `LDO` 通道的电压。当前支持对 `AXP2101` 的以下通道进行电压设置：`DCDC1~DCDC5`、`ALDO1~ALDO4` 和 `BLDO1~BLDO2`。 >! 警告 ！！！ >设置错误的电压可能会损坏 `MaixCAM Pro`。除非明确了解调整目的和后果，否则请勿修改 `DCDC2~DCDC5`、`ALDO1~ALDO4` 和 `BLDO1~BLDO2` 的电压。若需测试，请使用 `DCDC1` 通道。 有关 PMU API 的详细说明请看 [PMU API 文档](../../../api/maix/ext_dev/pmu.html)"},"/maixpy/doc/zh/modules/spilcd.html":{"title":"MaixCAM MaixPy SPI LCD 屏幕","content":" title: MaixCAM MaixPy SPI LCD 屏幕 update: date: 2024 12 02 author: 916BGAI version: 1.0.0 content: 初版文档 ## 简介 `MaixCAM` 配备三路硬件SPI接口，可以通过 SPI 接口连接并驱动 LCD 屏幕。 > 目前仅支持通过硬件 SPI 驱动 LCD 屏幕，且需要修改 Linux 内核，不支持软件 SPI。 > **注意：** 阅读本文档需要具备一定的内核编译、内核配置和内核驱动开发的知识。 ## 使用 ST7789 屏幕 这里以 `ST7789` 驱动的 LCD 屏为例。 ### 获取 LicheeRV Nano Build 源代码 `MaixCAM` 使用的基础系统为 [https://github.com/sipeed/LicheeRV Nano Build](https://github.com/sipeed/LicheeRV Nano Build)。 首先拉去最新的源码，按照 [README](https://github.com/sipeed/LicheeRV Nano Build/blob/main/README.md) 中的方法完成系统的构建。 ### 修改 linux 内核 首先修改内核配置，开启 `FB_TFT` 支持，可以在 LicheeRV Nano Build 根目录执行 `menuconfig_kernel` 后使用文本界面菜单进行配置，配置项位于: `Device Drivers > Staging drivers > Support for small TFT LCD display modules` 选择你所使用的屏幕驱动，这里选择 `ST7789` 驱动，并将其编译为内核模块： `<M> FB driver for the ST7789 LCD Controller` > 也可以直接修改配置文件 `build/boards/sg200x/sg2002_licheervnano_sd/linux/sg2002_licheervnano_sd_defconfig` 。 > 添加 `CONFIG_FB_TFT y` 和 `CONFIG_FB_TFT_ST7789 m` 即可。 ### 修改设备树 修改设备树文件 `build/boards/sg200x/sg2002_licheervnano_sd/dts_riscv/sg2002_licheervnano_sd.dts` ```c &spi2 { \tstatus \"okay\"; /delete node/ spidev@0; st7789: st7789@0{ \t\tcompatible \"sitronix,st7789\"; \t\treg <0>; \t\tstatus \"okay\"; \t\tspi max frequency <80000000>; \t\tspi cpol; \t\tspi cpha; \t\trotate <90>; \t\tfps <60>; \t\trgb; \t\tbuswidth <8>; \t\tdc <&porte 20 GPIO_ACTIVE_HIGH>; \t\treset <&porte 21 GPIO_ACTIVE_LOW>; \t\tdebug <0>; \t}; }; ``` 这里使用的是 `SPI2`，由于 Wi Fi 模块将 `SPI2` 引脚复用为 `SDIO`，因此我们需要修改引脚的复用功能，修改方法见下面的例程。修改后，Wi Fi 功能将不可用。 修改完设备树后，重新编译镜像，并根据 [为 MaixCAM 编译系统](https://wiki.sipeed.com/maixpy/doc/zh/pro/compile_os.html) 的方法生成适用于 MaixCAM 的镜像。 ### 测试屏幕 maixpy 例程: ```python from maix import pinmap, display, image, app import subprocess try: result subprocess.run(['lsmod'], capture_output True, text True, check True) if \"aic8800_bsp\" in result.stdout: subprocess.run(['rmmod', 'aic8800_fdrv'], check True) subprocess.run(['rmmod', 'aic8800_bsp'], check True) else: print(f\"aic8800 module is not currently loaded, skipping remove.\") except Exception as e: print(e) pinmap.set_pin_function(\"P18\", \"SPI2_CS\") pinmap.set_pin_function(\"P22\", \"SPI2_MOSI\") pinmap.set_pin_function(\"P23\", \"SPI2_SCK\") pinmap.set_pin_function(\"P20\", \"GPIOP20\") pinmap.set_pin_function(\"P21\", \"GPIOP21\") try: result subprocess.run(['lsmod'], capture_output True, text True, check True) if \"fb_st7789\" in result.stdout: print(f\"module is already loaded, skipping loading.\") else: subprocess.run(['insmod', '/mnt/system/ko/fb_st7789.ko'], check True) print(f\"load fb_st7789 success.\") except Exception as e: print(e) disp display.Display(device \"/dev/fb0\") print(\"display init done\") print(f\"display size: {disp.width()}x{disp.height()}\") y 0 while not app.need_exit(): img image.Image(disp.width(), disp.height(), image.Format.FMT_RGB888) img.draw_rect(0, y, image.string_size(\"Hello, MaixPy!\", scale 2).width() + 10, 80, color image.Color.from_rgb(255, 0, 0), thickness 1) img.draw_string(4, y + 4, \"Hello, MaixPy!\", color image.Color.from_rgb(255, 255, 255), scale 2) disp.show(img) y (y + 1) % disp.height() ``` 首先移除 aic8800 驱动模块防止其占用 SDIO 总线影响屏幕驱动。 修改引脚复用，将对应引脚映射为 SPI 功能，使用 `pinmap` 修改引脚复用的具体方法可以查看 [MaixPy Pinmap 使用介绍](https://wiki.sipeed.com/maixpy/doc/zh/peripheral/pinmap.html)。 然后使用 `insmod` 加载屏幕驱动模块即可，查看系统日志，可以看到驱动加载成功。在 /dev 目录下也可以找到生成的 `fb0` 设备。 ```bash [ 1029.909582] fb_st7789: module is from the staging directory, the quality is unknown, you have been warned. [ 1029.911792] fb_st7789 spi2.0: fbtft_property_value: buswidth 8 [ 1029.911814] fb_st7789 spi2.0: fbtft_property_value: debug 0 [ 1029.911828] fb_st7789 spi2.0: fbtft_property_value: rotate 90 [ 1029.911842] fb_st7789 spi2.0: fbtft_property_value: fps 60 [ 1030.753696] graphics fb0: fb_st7789 frame buffer, 320x240, 150 KiB video memory, 4 KiB buffer memory, fps 62, spi2.0 at 80 MHz ``` 接下来使用屏幕就很简单了，只需要在创建 `Display` 实例时指定对应的 `fb` 设备即可。然后就可以按照正常方法使用 `SPI` 屏幕了 （[MaixPy 屏幕使用](https://wiki.sipeed.com/maixpy/doc/zh/vision/display.html)）。 ```python disp display.Display(device \"/dev/fb0\") ``` ## 注意事项 ### 屏幕时序问题 不同屏幕的初始化时序可能有所不同。例如，`ST7789` 包括 `ST7789V1`、`ST7789V2` 等不同版本，每个版本的初始化时序可能不同，[LicheeRV Nano Build](https://github.com/sipeed/LicheeRV Nano Build) 仓库里驱动的不能保证在每个 st7789 屏幕上都能正常使用。具体屏幕的初始化时序可以联系商家获取，并修改 `LicheeRV Nano Build/linux_5.10/drivers/staging/fbtft/fb_st7789.c` 中的 `init_display` 函数。 ### 引脚复用 在使用 `pinmap` 设置引脚复用时，确保与设备树中的引脚配置一致。一般来说 SPI 屏的 `dc` 引脚和 `reset` 引脚不会和硬件绑定，可以在设备树中任意指定，选择 `MaixCAM` 中未被占用的引脚即可，然后在 `pinmap` 时将其映射为 GPIO 功能。 ### 驱动其他屏幕 目前，`fb` 设备已测试了 `st7789` 屏幕驱动。`linux_5.10/drivers/staging/fbtft` 中还有其他屏幕驱动可供测试。如遇问题，欢迎提交 `commit` 或 `PR` 做出贡献。"},"/maixpy/doc/zh/modules/rtc.html":{"title":"MaixCAM MaixPy 使用 RTC 模块","content":" title: MaixCAM MaixPy 使用 RTC 模块 MaixCAM Pro 板载了一个 RTC 模块，默认上电会自动同步系统时间，以及从网络同步时间，网络状态变化后也会自动同步。 所以一般情况不需要手动操作 RTC，直接使用系统的时间 API 获取时间即可。 如果一定要手动操作 RTC，请看[bm8653 RTC 模块使用](./bm8653.html)（手动操作前可以在系统 `/etc/init.d`目录下把 RTC 和 NTP 相关服务删掉以禁用自动同步。 > MaixCAM 无板载 RTC。"},"/maixpy/doc/zh/modules/temp_humi.html":{"title":"MaixCAM MaixPy 读取温湿度传感器","content":" title: MaixCAM MaixPy 读取温湿度传感器 ## 简介 通过给 MaixCAM 外挂一个温湿度传感器模块，可以轻松读取到环境温度和湿度，这里以 `Si7021` 这款传感器为例，通过 `I2C` 可以驱动它，其它的传感器你也可以找厂商要驱动然后使用 I2C / SPI 读取。 ![](../../assets/si7021.png) 注意供电是 3.3v，不要接错到 5v 导致烧毁。 `SCL` / `SDA` 接到 MaixCAM 的 `SCL` / `SDA` 即可，比如 `I2C5` 对应的`A15(SCL)/ A27(SDA)`。 ## 使用 完整的代码在 [MaixPy/examples/ext_dev/sensors](https://github.com/sipeed/MaixPy/blob/main/examples/ext_dev/sensors) 目录下， 找到`si7021` 的例程即可。 注意系统镜像需要 `> 2024.6.3_maixpy_v4.2.1` 版本。"},"/maixpy/doc/zh/modules/ahrs.html":{"title":"MaixCAM MaixPy 读取 IMU 加速度计和角速度计进行姿态解算","content":" title: MaixCAM MaixPy 读取 IMU 加速度计和角速度计进行姿态解算 update: date: 2025 07 08 author: neucrack version: 1.0.0 content: 增加姿态解算代码支持和文档 ## IMU 简介 IMU（Inertial Measurement Unit），即 惯性测量单元，通常由几部分组成： * 加速度计：测量线性加速度，包括重力加速度。 * 陀螺仪：测量角速度（绕轴的转动）。 * 磁力计（可选）：测量磁场方向，用于辅助航向角（Yaw）计算。 利用这几个传感器的数据，我们可以计算出设备的姿态，沿着设备三个轴旋转的角度，也叫欧拉角。 比如我们的设备如下图， `z`轴朝上， `y`轴朝前， `x`轴朝右，这是一个右手坐标系： ``` ^z / y(front) / / . ————————> x(right) ``` 这里以`x`为轴心旋转的角度就叫`俯仰角`（`pitch`）。 这里以`y`为轴心旋转的角度就叫`横滚角`（`roll`）。 这里以`z`为轴心旋转的角度就叫`偏航角`（`yaw`）。 这样一个传感器+读取+姿态解算+输出的系统我们可以称为`AHRS`(\tAttitude and Heading Reference System/ 姿态与航向参考系统)。 得到这三个角就知道了我们的设备先在是什么姿态了，就可以用在很多场景，比如： * 无人机 * 平衡车 * 机器人 * 体感控制 * 防抖 * 方向检测，震动检测 * 动作判断，手势识别，行为分析（还可以结合AI模型使用） ## 硬件支持 部分设备内置了 IMU，如下： 设备名 传感器型号 加速度计 陀螺仪 磁力计 接口 特点 MaixCAM Pro QMI8658 ✅ ✅ ❌ IIC4<br>地址 0x6B 低功耗<br>高稳定性<br>高灵敏度 MaixCAM 无板载 ❌ ❌ ❌ ❌ MaixCAM2 LSM6DSOWTR ✅ ✅ ❌ 内置驱动 低功耗<br>高稳定性<br>高灵敏度 除了使用内置的，你也可以自己外接一个 IMU 传感器，比如经典的`MPU6050/MPU9150`等，可自行查找最新和合适的传感器。 MaixPy 中姿态解算和 IMU 驱动是分开的，所以你可以自己外接传感器驱动，仍然可以调用姿态解算算法。 ## MaixPy 读取 IMU 数据 以 MaixCAM Pro 为例，使用 `maix.imu.IMU` 读取： ```python from maix.ext_dev import imu # Force calibrate first calibrate_first False # default config: acc + 2g 1KHz, gyro + 256rad/s 8KHz sensor imu.IMU(\"default\", mode imu.Mode.DUAL, acc_scale imu.AccScale.ACC_SCALE_2G, acc_odr imu.AccOdr.ACC_ODR_1000, gyro_scale imu.GyroScale.GYRO_SCALE_256DPS, gyro_odr imu.GyroOdr.GYRO_ODR_8000) # for gyro have bias, we need to calibrate first if calibrate_first or not sensor.calib_gyro_exists(): print(\"\\n\\nNeed calibrate fisrt\") print(\"now calibrate, please !! don't move !! device, wait for 10 seconds\") # calib_gyro will auto calculate and save bias, # the next time use load_calib_gyro load sensor.calib_gyro(10000) else: sensor.load_calib_gyro() while True: data sensor.read_all(calib_gryo True, radian False) msg \"acc: {:10.4f}, {:10.4f}, {:10.4f}, gyro: {:10.4f}, {:10.4f}, {:10.4f}, temp: {:4.1f}\".format( data.acc.x, data.acc.y, data.acc.z, data.gyro.x, data.gyro.y, data.gyro.z, data.temp ) print(msg) ``` 这里构造了一个`IMU`对象，然后调用`read_all`读取数据，再打印。 由于板载IMU没有 磁力计，这里没有打印。 不过这里有一点需要注意，那就是校准数据，下面进行说明。 ## 数据校准 ### 陀螺仪校准 为什么需要校准陀螺仪： 如果不校准， 设备静止时我们认为陀螺仪未转动，几 `gyro` `x, y, z` 三个轴均应该为`0`，但是实际我们会发现有误差，即使静止也会有值。这也叫`零飘`。 上面的代码可以看到，第一次需要进行一次`calib_gyro`，这是对陀螺仪数据进行一次校准，原理很简单： 所以我们连续采集多次求平均值，并记录下来（这里`calib_gyro(10000)`采集了`10s`并且将计算过后的值保存到了`/maixapp/share/misc`目录下。 下次我们用`load_calib_gyro`方法就会从这个文件加载了，而不用每次都校准。 然后在读取数据时`read_all(calib_gryo True)`，内部会读取数据后自动减去偏差值再返回，当然你也可以是设置`calib_gyro False`然后自己手动减。 ### 加速度校准 理论加速度也是需要校准的，但是影响不如陀螺仪那么大，本文不进行说明，可自行搜索学习。 ### 磁力计校准 同样，磁力计也需要校准，比如常见的椭球校准法，本文不进行说明，可自行搜索学习。 ## 姿态解算 得到传感器数值后，通过一个姿态解算算法就能得到设备的姿态角度（欧拉角）。 ### 解算原理简介 * 理论上我们用陀螺仪即可知道相对上一时刻旋转了多少度，即 `角速度 * 时间dt 旋转角度`。不过只能短时间信任，由于陀螺仪精度问题，时间长了会累积误差。 * 加速度计的原理其实是测量重力G，由于重力可以认为方向和大小恒定，当设备静止或者匀速时，通过加速度计我们可以知道设备的相对于大地坐标系的绝对旋转角度。 所以我们利用这个特性，长时间上用加速度测量的角度作为基准，短时间相信陀螺仪，他们互补。 * 但是当设备沿着垂直于重力的方向旋转，加速度计就无法检测到了，所以只能靠陀螺仪，时间长了可能就会有误差（漂移）。 * 所以一般可以利用磁力计，因为磁力计指向地球南北，刚好弥补了加速计的问题。 ### 姿态解算算法 算法有很多，MaixPy 内置了一个 **Mahony 互补滤波** 算法，精简快速， 使用方法： 完整代码在 [MaixPy/examples/ext_dev/sensors/imu/imu_ahrs_mahony.py](https://github.com/sipeed/MaixPy/tree/main/examples/ext_dev/sensors/imu) 中 ```python ''' Mahony AHRS get device euler angle demo. Full Application code see: https://github.com/sipeed/MaixPy/tree/main/projects/app_imu_ahrs ''' from maix import ahrs, app, time from maix.ext_dev import imu # P of PI controller, a larger P (proportional gain) leads to faster response, # but it increases the risk of overshoot and oscillation. kp 2 # I of PI controller, a larger I (integral gain) helps to eliminate steady state errors more quickly, # but it can accumulate error over time, potentially causing instability or slow drift. ki 0.01 # Force calibrate first calibrate_first False # default config: acc + 2g 1KHz, gyro + 256rad/s 8KHz sensor imu.IMU(\"\", mode imu.Mode.DUAL, acc_scale imu.AccScale.ACC_SCALE_2G, acc_odr imu.AccOdr.ACC_ODR_1000, gyro_scale imu.GyroScale.GYRO_SCALE_256DPS, gyro_odr imu.GyroOdr.GYRO_ODR_8000) ahrs_filter ahrs.MahonyAHRS(kp, ki) # for gyro have bias, we need to calibrate first if calibrate_first or not sensor.calib_gyro_exists(): print(\"\\n\\nNeed calibrate fisrt\") print(\"now calibrate, please !! don't move !! device, wait for 10 seconds\") # calib_gyro will auto calculate and save bias, # the next time use load_calib_gyro load sensor.calib_gyro(10000) else: sensor.load_calib_gyro() # time.sleep(3) last_time time.ticks_s() while not app.need_exit(): # get imu data data sensor.read_all(calib_gryo True, radian True) # calculate angles t time.ticks_s() dt t last_time last_time t # print(f\"{data.mag.x:8.2f}, {data.mag.y:8.2f}, {data.mag.z:8.2f}, {data.gyro.z:8.2f}\") angle ahrs_filter.get_angle(data.acc, data.gyro, data.mag, dt, radian False) # ^z / y(front) # / # / # . ————————> x(right) # this demo's axis # x axis same with camera # angle.y 90 print(f\"pitch: {angle.x:8.2f}, roll: {angle.y:8.2f}, yaw: {angle.z:8.2f}, dt: {int(dt*1000):3d}ms, temp: {data.temp:.1f}\") # time.sleep_ms(1) ``` 可以看到，通过`get_angle`函数，将原始数据传入即可得到欧拉角，磁力计没有默认全为 0 即可。 这里可能你也注意到了有一个 `PI` 控制器，用来调节灵敏度，可以自己尝试不同值看效果（可以自行学习 PID 概念和参数确定方法）： * `kp`: PI 控制器的 P。值越大响应越快，不过容易超调。 * `ki`: PI 控制器的 I。值越大响应越快，不过太大会导致不稳定和漂移。 以及初始化时其它参数，比如陀螺仪测量范围默认是`[ 256degree/s, 256degree/s]`，如果你旋转速度过大超过这个范围就会出现转了 100度但是只检测到转了 60度这种情况。 所以参数都要根据你际应用场景进行修改，另外不同参数可能灵敏度和噪声也会不同。 ## API 文档 有关 IMU API 的详细说明请看 [IMU API 文档](../../../api/maix/ext_dev/imu.html)。 有关 AHRS API 的详细说明请看 [AHRS 文档](../../../api/maix/ahrs.html)。"},"/maixpy/doc/zh/modules/bm8653.html":{"title":"MaixPy bm8653驱动说明","content":" title: MaixPy bm8653驱动说明 update: date: 2024 08 27 author: iawak9lkm version: 1.0.0 content: 初版文档 ## BM8653 简介 BM8653是一款实时时钟（RTC）芯片，广泛应用于各种电子设备中，用于提供精确的时间和日期信息。它具有低功耗、高精度的特点，能够在设备断电的情况下通过备用电池继续运行，确保时间的连续性和准确性。 ## MaixPy 中使用 BM8653 在 MaixPy 中使用 BM8653 很简单, 您只需要知道您平台上的 BM8653 挂载在哪个 I2C 总线上. MaixCAM Pro 板载的 BM8563 挂载在 I2C 4 上. 示例代码: ```python from maix import ext_dev, pinmap, err, time ### Enable I2C # ret pinmap.set_pin_function(\"PIN_NAME\", \"I2Cx_SCL\") # if ret ! err.Err.ERR_NONE: # print(\"Failed in function pinmap...\") # exit( 1) # ret pinmap.set_pin_function(\"PIN_NAME\", \"I2Cx_SDA\") # if ret ! err.Err.ERR_NONE: # print(\"Failed in function pinmap...\") # exit( 1) BM8653_I2CBUS_NUM 4 rtc ext_dev.bm8563.BM8563(BM8653_I2CBUS_NUM) ### 2020 12 31 23:59:45 t [2020, 12, 31, 23, 59, 45] # Set time rtc.datetime(t) while True: rtc_now rtc.datetime() print(f\"{rtc_now[0]} {rtc_now[1]} {rtc_now[2]} {rtc_now[3]}:{rtc_now[4]}:{rtc_now[5]}\") time.sleep(1) ``` 如果您使用的是 MaixCAM Pro 板载的 BM8653, 无需使能 I2C 4. 示例中读写 BM8653, 设置或是读取当前时间. 您也可以通过以下示例将当前 BM8653 内的时间设置为系统时间, 或是将当前系统时间设置为 BM8653 内的时间. ```python from maix import ext_dev, pinmap, err, time ### Enable I2C # ret pinmap.set_pin_function(\"PIN_NAME\", \"I2Cx_SCL\") # if ret ! err.Err.ERR_NONE: # print(\"Failed in function pinmap...\") # exit( 1) # ret pinmap.set_pin_function(\"PIN_NAME\", \"I2Cx_SDA\") # if ret ! err.Err.ERR_NONE: # print(\"Failed in function pinmap...\") # exit( 1) BM8653_I2CBUS_NUM 4 rtc ext_dev.bm8563.BM8563(BM8653_I2CBUS_NUM) ### Update RTC time from system rtc.systohc() ### Update system time from RTC # rtc.hctosys() while True: rtc_now rtc.datetime() print(f\"{rtc_now[0]} {rtc_now[1]} {rtc_now[2]} {rtc_now[3]}:{rtc_now[4]}:{rtc_now[5]}\") time.sleep(1) ``` **BM8653 的底层实现类似于单例模式, 本 API 可以保证对单个 BM8653 的读写是线程安全的. 也就意味着您可以随意的创建 BM8653 对象, 在任意地方读写 BM8653 均不会产生数据竞争.** 传给 BM8653 对象的 timetuple 遵循 (year, month, day[, hour[, minute[, second]]]), 即必须要有前三个参数, 后续参数缺失部分代表的时间不会进行修改. BM8653 保证返回的 timetuple 为空时表示错误, 不为空时必定是含有6个元素的 List[], 其内容为(year, month, day, hour, minute, second). 有关 BM8653 API 的详细说明请看 [BM8653 API 文档](../../../api/maix/ext_dev/bm8563.html)"},"/maixpy/doc/zh/modules/qmi8658.html":{"title":"MaixPy qmi8658驱动说明","content":" title: MaixPy qmi8658驱动说明 请看 [AHRS 文档](./ahrs.html)"},"/maixpy/doc/zh/modules/acc.html":{"title":"MaixCAM MaixPy 读取加速度计和姿态解算","content":" title: MaixCAM MaixPy 读取加速度计和姿态解算 请看 [AHRS 文档](./ahrs.html)"},"/maixpy/doc/zh/modules/tof.html":{"title":"","content":" titile: MaixCAM MaixPy 使用 TOF 模块测距和地形检测 ## 效果演示 单 ToF 效果图: ![](../../assets/tof003.jpg) ToF和可见光融合效果图: ![](../../assets/tof002.jpg) 该 APP 已集成到 MaixCAM Release 镜像中, 安装支持的模块, 启动 `ToF Camera` APP 即可 [APP 安装地址](https://maixhub.com/app/88) [源码地址](https://github.com/sipeed/MaixCDK/tree/main/projects/app_tof_camera) ## 适配列表 * PMOD_TOF100 [咨询购买地址](https://wiki.sipeed.com/en/store.html) ### PMOD_TOF100 ![](../../assets/tof004.jpg) PMOD_TOF100 是一个 100x100 TOF 模块, 可用于测距或者地形检测, 模块参数: 参数名称 分辨率100x100,50x50,25x25 测距范围0.2~2.5m 视角70°Hx60°V 激光发射器940nm VCSEL 帧率5~20fps 安装 PMOD_TOF100 模块后, 可以使用 MaixPy 提供的 API 获得模块测得的距离数据矩阵、伪彩图、最近一帧数据中的最小最大以及中心距离的值和对应的坐标等信息, 详情见 [模块 API 文档](../../../api/maix/ext_dev/tof100.html) 您也可以参考我们的效果演示 APP 编写您的应用代码. Sipeed 官方有另外[两款 TOF 模块](https://wiki.sipeed.com/hardware/zh/maixsense/index.html) 可以用来测距，可以购买使用串口通信使用。"},"/maixpy/doc/zh/README_no_screen.html":{"title":"MaixCAM MaixPy 无屏幕版快速开始","content":" title: MaixCAM MaixPy 无屏幕版快速开始 ## 关于本页文档 正如[快速开始所述](./index.html)，开发时**强烈推荐**购买带屏幕版本，会有更好的开发体验，包括使用内置的 APP，以及使用 MaixHub 应用商店的 APP，以及方便调试（比如常用设置可以直接触摸点击界面完成，可以实时在屏幕看到图像等）。 当然，如果你实在没有条件购买带屏幕的，或者你在量产时需要无屏幕的版本，请看本文。 ## 获得 MaixCAM 设备 * **MaixCAM**：在 [Sipeed 淘宝](https://item.taobao.com/item.htm?id 784724795837) 或者 [Sipeed 速卖通](https://www.aliexpress.com/store/911876460) 店铺购买 <a href \"https://wiki.sipeed.com/maixcam\" target \"_blank\">MaixCAM</a> 。 ## 上手配置 ### 准备 TF 镜像卡和插入到设备 如果你买的套餐里面有 TF 卡，里面已经有出厂镜像了，如果出厂时 TF 卡没有安装到设备，需要先小心打开外壳（注意里面有排线连接不要扯断了），然后插入 TF 卡。另外因为出厂的固件可能比较老旧，**务必**按照<a href \"./basic/os\" target \"_blank\">升级和烧录系统</a>先将系统升级到最新版本，否则可能会遇到某些应用 和 API 无法使用的问题。 如果没买 TF 卡，则需要将系统烧录进自备的 TF 卡中，烧录方法请看<a href \"./basic/os\" target \"_blank\">升级和烧录系统</a>，然后再安装到板子。 ### 上电开机 使用 `Type C` 数据线连接 `MaixCAM` 设备给设备供电，等待设备开机。 **首先**：保证 USB 线材质量足够好，以及电脑 USB 端口质量够好（供电 > 5v 500mA，抗干扰能力正常）。 第一次等待 20 秒左右，然后电脑会出现一个或者两个虚拟网卡设备（可以在电脑的网络管理器看到）。 如果虚拟网卡设备： * 请确认购买了配套的 TF 卡，如果确认有 TF 卡，并且已经插入到设备，可以**尝试[更新到最新的系统](./basic/os.html)**。 * 如果你没有购买 TF 卡套餐，你需要按照<a href \"./basic/os\" target \"_blank\">升级和烧录系统</a>的方法烧录最新的系统到 TF 卡。 * 请确认 USB 有没有松动，以及 USB 线材质量，可以换一根质量好点的线尝试。 * 请确认 USB 口供电足够，可以换一个 USB 口，或者有条件在其它电脑试试。 ## 准备连接电脑和设备 为了后面电脑（PC）能和 设备（MaixCAM）通信，我们要让它们在同一个局域网内，提供了两种方式，我们首先使用方法一： * **方法一**：有线连接， 设备通过 USB 线连接到电脑，设备会虚拟成一个 USB 网卡，这样和电脑就通过 USB 在同一局域网了，遇到问题也可以在 [FAQ](./faq.html) 中找常见问题。 .. details::方法二在不同电脑系统中驱动安装方法： :open: true 默认会有两种 USB 虚拟网卡驱动（NCM 和 RNDIS驱动），以满足不同系统的需求： * **Windows**: windows 所有系统会自动安装 RNDIS 驱动， 仅 Win11 会自动安装 NCM 驱动，两种驱动有**一个能用就行**（NCM 速度比 RNDIS 速度快）。 * 打开任务管理器 > 性能，可以看到一个虚拟的以太网，并且可以看到 ip 比如 `10.131.167.100` 是电脑的 ip, 设备的 ip 是最后一位改为`1` 即 `10.131.167.1`。如果是 Win11 则会看到两个虚拟网卡，随便选择一个 IP 使用即可。 * 另外也可以打开电脑的 `设备管理器`（搜索栏搜索`设备管理器`）， RNDIS 和 NCM 驱动被正确安装的效果，**一个能用就行**： ![RNDIS ok](../../static/image/rndis_windows.jpg) ![NCM ok](../../static/image/windows_ncm_ok.png) * **Linux**: 无需额外设置，插上 USB 线即可。 使用 `ifconfig` 或者 `ip addr` 查看到 `usb0` 和 `usb1` 网卡，两个 IP 都可以使用，**注意** 这里看到的 ip 比如 `10.131.167.100` 是电脑的 ip, 设备的 ip 是最后一位改为`1` 即 `10.131.167.1`。 * **MacOS**: 在`系统设置` >`网络`里面查看到 `usb` 网卡，**注意** 这里看到的 ip 比如 `10.131.167.100` 是电脑的 ip, 设备的 ip 是最后一位改为`1` 即 `10.131.167.1`。 * **方法二**：无线连接， 设备使用 WiFi 连接到电脑连接的同一个路由器或者 WiFi 热点下（WiFi 如果出现画面卡顿或者延迟高的问题可以使用有线连接。），连接无线热点方式有两种： * 修改 TF 的 boot 分区中的 `wifi.ssid` 和 `wifi.pass` 文件，重启即可连接。修改方法： * 如果你已经了解 SSH， 可以通过 ssh 连接到设备（如果有线连接可用）修改`/boot`目录下文件。 * 也可以按照前面升级系统的方式进入升级模式后电脑会出现一个 U 盘，然后修改里面的文件即可，注意修改完要先 弹出U盘 再重启。 * 也可以直接用 读卡器，电脑会出现一个U盘，修改其中的`wifi.ssid` 和 `wifi.pass`文件即可，注意修改完要先 弹出U盘 再重启。 * 如果你有线已经可以使用，按照下一步已经可以使用 MaixVision 运行代码了，可以修改例程 `tools/wifi_connect.py` 中的 SSID 和 PASSWORD 然后运行即可。 ## 开发环境准备 * 首先保证上一步电脑和设备已经在同一个局域网中了。 * 下载 [MaixVision](https://wiki.sipeed.com/maixvision) 并安装。 * 使用 Type C 连接设备和电脑，打开 MaixVision，点击左下角的`“连接”`按钮，会自动搜索设备，稍等一下就能看到设备，点击设备有点的连接按钮以连接设备。 如果**没有扫描到设备**， 也可以在 [FAQ](./faq.html) 中找到解决方法。 这里有 MaixVision 的使用示例视频: <video style \"width:100%\" controls muted preload src \"/static/video/maixvision.mp4\"></video> ### 联网 首次运行需要连接网络，以激活设备安装运行库。 如果没有路由器可以用手机开一个热点。 MaixVision 修改例程 `tools/wifi_connect.py` 中的 SSID 和 PASSWORD 然后运行即可。其它连接 WiFi 的方法看前面的介绍。 ### 升级运行库 **这一步很重要 ！！！** 这一步如果不做好，其它应用和功能可能无法运行（比如闪退等）。 * 首先保证上一步连接 WiFi 已经完成，并且获取到 IP 地址能访问公网。 * 运行 MaixVision 例程里面的 `tools/install_runtime.py` 来安装最新的运行库。 如果显示`Request failed` 或者`请求失败`，请先检查网络是否已经连接，需要能连接到互联网，如果还不行，请拍照联系客服处理即可。 ## 运行例程 点击 MaixVision 左侧的`示例代码`，选择一个例程，点击左下角`运行`按钮将代码发送到设备上运行。 比如： * `hello_maix.py`，点击`运行`按钮，就能看到 MaixVision 终端有来自设备打印的消息，以及右上角出现了图像。 * `camera_display.py`，这个例程会打开摄像头并在屏幕上显示摄像头的画面。 ```python from maix import camera, display, app disp display.Display() # 构造一个显示对象，并初始化屏幕 cam camera.Camera(640, 480) # 构造一个摄像头对象，手动设置了分辨率为 640x480, 并初始化摄像头 while not app.need_exit(): # 一直循环，直到程序退出（可以通过按下设备的功能按键退出或者 MaixVision 点击停止按钮退出） img cam.read() # 读取摄像头画面保存到 img 变量，可以通过 print(img) 来打印 img 的详情 disp.show(img) # 将 img 显示到屏幕上 ``` * `yolov5.py` 会检测摄像头画面中的物体框出来并显示到屏幕上，支持 80 种物体的检测，具体请看[YOLOv5/YOLOv8/YOLO11 物体检测](./vision/yolov5.html)。 其它例程可以自行尝试。 > 如果你使用相机例程遇到了图像显示卡顿，可能是网络不通畅，或者 USB 线质量或者主机 USB 质量太差造成，可以更换连接方式或者更换线缆、主机 USB 口或者电脑等。 ## 安装应用到设备 上面是在设备中运行代码，`MaixVision` 断开后代码就会停止运行，如果想让代码出现在开机菜单中，可以打包成应用安装到设备上。 点击 `MaixVision` 左下侧的安装应用按钮，填写应用信息，会将应用安装到设备上，然后在设备上就能看到应用了。 也可以选择打包应用，将你的应用分享到[MaixHub 应用商店](https://maixhub.com/app)。 > 默认例程没有显式编写退出功能，进入应用后按下设备的功能按键即可退出应用。（对于 MaixCAM 是 user 键） 如果想让程序开机自启动，可以修改并运行例程`tools/set_autostart.py`即可。 ## 下一步 看到这里，如果你觉得不错，**请务必来 [github](https://github.com/sipeed/MaixPy) 给 MaixPy 开源项目点一个 star（需要先登录 github）, 你的 star 和认同是我们不断维护和添加新功能的动力！** 到这里你已经体验了一遍使用和开发流程了，接下来可以学习 `MaixPy` 语法和功能相关的内容，请按照左边的目录进行学习，如果遇到 `API` 使用问题，可以在[API 文档](/api/)中查找。 学习前最好带着自己学习的目的学，比如做一个有趣的小项目，这样学习效果会更好，项目和经验都可以分享到[MaixHub 分享广场](https://maixhub.com/share)，会获得现金奖励哦！ ## 常见问题 FAQ 遇到问题可以优先在 [FAQ](./faq.html) 里面找，找不到再在下面的论坛或者群询问，或者在 [MaixPy issue](https://github.com/sipeed/MaixPy/issues) 提交源码问题。 ## 分享交流 * **[MaixHub 项目和经验分享](https://maixhub.com/share)** ：分享你的项目和经验，获得现金打赏，获得官方打赏的基本要求： * **可复现型**：较为完整的项目制作复现过程。 * **炫耀型**：无详细的项目复现过程，但是项目展示效果吸引人。 * Bug 解决经验型：解决了某个难题的过程和具体解决方法分享。 * [MaixPy 官方论坛](https://maixhub.com/discussion/maixpy)（提问和交流） * QQ 群： （建议在 QQ 群提问前先发个帖，方便群友快速了解你需要了什么问题，复现过程是怎样的） * MaixPy (v4) AI 视觉交流大群: 862340358 * Telegram: [MaixPy](https://t.me/maixpy) * MaixPy 源码问题: [MaixPy issue](https://github.com/sipeed/MaixPy/issues) * 商业合作或批量购买请联系 support@sipeed.com 。"},"/maixpy/doc/zh/projects/line_tracking_robot.html":{"title":"MaixCAM MaixPy 小车巡线","content":" title: MaixCAM MaixPy 小车巡线 update: date: 2024 05 09 author: lxowalle version: 1.0.0 content: 初版文档 阅读本文前，确保已经知晓如何开发MaixCAM，详情请阅读[快速开始](../index.html) ## 简介 本文将介绍如何使用MaixPy实现寻线小车 ## 如何使用MaixPy实现寻线小车 1. 准备MaixCAM与小车 2. 实现寻线功能 3. 实现小车控制功能 ### 准备MaixCAM与小车 TODO ### 实现寻线功能 使用`image`模块的`get_regression`可以快速寻找到直线，详情见[寻找直线](./line_tracking.html) 代码实现： ```python from maix import camera, display, image cam camera.Camera(320, 240) disp display.Display() # thresholds [[0, 80, 40, 80, 10, 80]] # red thresholds [[0, 80, 120, 10, 0, 30]] # green # thresholds [[0, 80, 30, 100, 120, 60]] # blue while 1: img cam.read() lines img.get_regression(thresholds, area_threshold 100) for a in lines: img.draw_line(a.x1(), a.y1(), a.x2(), a.y2(), image.COLOR_GREEN, 2) theta a.theta() rho a.rho() if theta > 90: theta 270 theta else: theta 90 theta img.draw_string(0, 0, \"theta: \" + str(theta) + \", rho: \" + str(rho), image.COLOR_BLUE) disp.show(img) ``` 上述代码实现了寻线功能， 上述参数中需注意： 设置合适的thresholds值来寻找到对应的直线 设置合适的area_threshold值来过滤环境干扰，可以过滤一些面积小的直线 使用`a.theta()`获取直线的角度 使用`a.rho()`获取直线与原点(原点在左上角)的距离 根据实际环境调试好寻线参数后， 就可以利用`a.theta()`和`a.rho()`控制小车方向了。 ### 实现小车控制功能 TODO"},"/maixpy/doc/zh/projects/index.html":{"title":"MaixCAM MaixPy 项目实战 介绍和汇总","content":" title: MaixCAM MaixPy 项目实战 介绍和汇总 ## 简介 这里提供： * 一些常见的项目实战示例，方便社区成员可以参考复现使用，也方便激发大家的灵感做出更多更好的应用和项目出来。 * 一些社区成员的开源项目，方便大家参考学习。 除了这里，要找到用 MaixPy 实现的相关的项目，还有有几种方式： ### MaixPy 官方文档 也就是本文档左边目录可以找到的项目实战，比如`小车巡线`。 如果你有好的项目，或者好的项目推荐，也可以点击右上角编辑文档，添加 PR（Pull Request） 添加到文档，非常欢迎。 ### MaixHub 项目分享广场 在[MaixHub 项目分享](https://maixhub.com/share?type project) 栏目可以找到项目分享。 有高质量的分享也会被链接到 MaixPy 官方文档。 你也可以分享你的项目制作方法，会获得官方（必获得）以及社区成员的现金打赏（通常高质量能解决急需需求的更容易被打赏）。 ### MaixHub 应用分享 除了项目分享以外，还可以在[MaixHub 应用商店](https://maixhub.com/app) 找到可以直接运行的应用，有部分应用可能是用 MaixPy 编写的，如果作者提供了源码或者写了详细的教程也都可以参考。 ### GitHub 搜索 在 [GitHub](https://github.com) 上搜索 `MaixPy` 或者 `MaixCAM` 也可以找到一些高质量的开源项目。 ## 开源项目汇总 通常是完整的项目，包含代码、文档、演示视频等。 ### 工具类 * [MaixPy UI Lib](https://github.com/aristorechina/MaixPy UI Lib): 一款基于 MaixPy 编写的轻量 UI 库，纯 Python 实现，支持多种控件，使用简单方便，也方便学习扩展，里面还有很多示例代码，比如 LAB/HSV 脱机阈值调试工具。 * [基于 MaixPy 实现的脱机阈值调试](https://maixhub.com/share/103)：实现了一个类封装脱机阈值调试工具，无三方依赖，直接调用即可使用。 * [maixcam 脱机使用串口屏调节阈值](https://maixhub.com/share/104)：外接一个串口屏，实现了脱机调节阈值的功能，适合需要外接屏幕的场景。 * [CAM脱机手动阈值编辑器](https://maixhub.com/share/102)： 又一个脱机手动阈值编辑器，代码简单易懂，适合学习和参考。 ### 竞赛类 * [MaixCam Tic Tac Toe 2024年全国大学生电子设计竞赛（E题 三子棋游戏装置）](https://github.com/HYK X/MaixCam_Tic_Tac_Toe_2024): 基于 Sipeed Maix 系列开发板，使用计算机视觉技术实现的三子棋（井字棋）对弈机器人项目。该项目是 2024年全国大学生电子设计竞赛（E题 三子棋游戏装置） 的一个完整解决方案。 ### 拍摄类 等你来分享。 ### 监控和智能家居类 等你来分享。 ### 自动化提高效率 等你来分享。 ### 机器人 等你来分享。 ### 更多 更多分类提交 issue 讨论添加。 ## 经验分享汇总 通常是比较简单的经验和代码片段分享，方便大家学习和参考。 ### UI 相关 * [MaixPy UI Lib](https://github.com/aristorechina/MaixPy UI Lib): 一款基于 MaixPy 编写的轻量 UI 库，纯 Python 实现，支持多种控件，使用简单方便，也方便学习扩展，里面还有很多示例代码，比如 LAB/HSV 脱机阈值调试工具。 * [基于 MaixPy 实现的脱机阈值调试](https://maixhub.com/share/103)：实现了一个类封装脱机阈值调试工具，无三方依赖，直接调用即可使用。 * [maixcam 脱机使用串口屏调节阈值](https://maixhub.com/share/104)：外接一个串口屏，实现了脱机调节阈值的功能，适合需要外接屏幕的场景。 * [CAM脱机手动阈值编辑器](https://maixhub.com/share/102)： 又一个脱机手动阈值编辑器，代码简单易懂，适合学习和参考。 ### 外设相关 * [MaixCam驱动WS2812进行补光和颜色补偿](https://maixhub.com/share/90): 使用 MaixCAM 驱动 WS2812 LED 灯（使用了硬件 SPI驱动）。 * [使用 MaixCAM Pro 捕获 PWM 的频率和占空比](https://maixhub.com/share/98): 使用 SPI 捕获 PWM 的频率和占空比，适合需要测量 PWM 信号的场景。 * [使用MaixCAM的蓝牙功能 · 硬件篇](https://maixhub.com/share/58) * [使用MaixCAM的蓝牙功能 · 软件篇](https://maixhub.com/share/62) ### 图像算法相关 * [MaixCam Tic Tac Toe 2024年全国大学生电子设计竞赛（E题 三子棋游戏装置）](https://github.com/HYK X/MaixCam_Tic_Tac_Toe_2024): 基于 Sipeed Maix 系列开发板，使用计算机视觉技术实现的三子棋（井字棋）对弈机器人项目。该项目是 2024年全国大学生电子设计竞赛（E题 三子棋游戏装置） 的一个完整解决方案。 * [开源一个很简单的通过cv2.solvePnP实现透视投影下的位姿估计](https://maixhub.com/share/93): 检测物体的3D位姿。 * [使用MaixPy生成二维码](https://maixhub.com/share/79): 使用 qrcode 库生成二维码。 ## 更多 这里收录不是很及时，更多请按照本文开头的方式寻找。"},"/maixpy/doc/zh/projects/face_tracking.html":{"title":"MaixCAM MaixPy 2轴舵机云台人脸追踪","content":" title: MaixCAM MaixPy 2轴舵机云台人脸追踪 update: date: 2024 06 11 author: iawak9lkm version: 1.0.0 content: 初版文档 阅读本文前，确保已经知晓如何开发MaixCAM，详情请阅读[快速开始](../index.html) [源码地址](https://github.com/sipeed/MaixPy/blob/main/projects/app_face_tracking) [APP下载地址](https://maixhub.com/app/31) ## 简介 基于 MaixCAM 和云台的人脸追踪程序。实际效果如下图所示： ![](../../assets/face_tracking1.jpg) ![](../../assets/face_tracking2.jpg) ## 如何使用例程 * 组装好您的云台和MaixCAM。 * 修改 `main.py` 中的参数。 修改每个舵机使用的 MaixCAM 引脚，指定的引脚必须具备 PWM 功能。`servos.Servos` 会自行将该引脚配置为 PWM 功能。 ```python ROLL_PWM_PIN_NAME \"A17\" PITCH_PWM_PIN_NAME \"A16\" ``` 修改两个舵机的初始位置。 ```python init_pitch 80 # init position, value: [0, 100], means minimum angle to maxmum angle of servo init_roll 50 # 50 means middle ``` 修改两个舵机各自的活动范围的最小最大 PWM 占空比。请注意，某些云台结构中的舵机超出物理限制的最大活动范围时可能会造成不可预期的后果，请务必保证以下设定值对应的舵机运动范围内无阻碍。 ```python PITCH_DUTY_MIN 3.5 # The minimum duty cycle corresponding to the range of motion of the y axis servo. PITCH_DUTY_MAX 9.5 # Maximum duty cycle corresponding to the y axis servo motion range. ROLL_DUTY_MIN 2.5 # Minimum duty cycle for x axis servos. ROLL_DUTY_MAX 12.5 # Maxmum duty cycle for x axis servos. ``` 选择舵机的运动方向。 ```python pitch_reverse False # reverse out value direction roll_reverse True # reverse out value direction ``` * 最后执行代码即可。 如果您是从 MaixHub 上安装的应用,在启动器中点击 face_tracking 即可执行本程序。 如果您是从 Github 上获取的源码, 您可以在 [MaixVision](https://wiki.sipeed.com/maixvision) 中导入该工程的文件夹执行整个工程即可。 MaixVision详情请参考 [MaixVision说明](https://wiki.sipeed.com/maixpy/doc/zh/basic/maixvision.html)。 当然您也可以将整个工程文件夹通过您喜欢的方式拷贝到我们的 MaixCAM 上, 然后用 python 执行。 * 想要退出程序按左上角的按钮即可。 ![](../../../../projects/app_face_tracking/assets/exit.jpg) ## 常见问题 * 人脸跟踪效果不理想。 不同的云台使用的 PID 参数不尽相同，您可以通过调节 PID 值来使得追踪效果更丝滑。 ```python pitch_pid [0.3, 0.0001, 0.0018, 0] # [P I D I_max] roll_pid [0.3, 0.0001, 0.0018, 0] # [P I D I_max] ``` * 在完成跟踪后，云台对着不动的人脸小幅度左右抖动一段时间。 通常可以通过调节 PID 来使得该影响尽可能小；但是无法避免云台物理结构带来的抖动。可以尝试调节死区来减小抖动。 ```python target_ignore_limit 0.08 # when target error < target_err_range*target_ignore_limit , set target error to 0 ``` * 显示屏显示或终端打印 `PIN: XXX does not exist`。 这是因为 MaixCAM 板子上引出的引脚中并不存在该引脚，请在 MaixCAM 上选择一个带 PWM 功能的引脚。 * 显示屏显示或终端打印 `Pin XXX doesn't have PWM function`。 这是因为 MaixCAM 板子上引出的这个引脚没有 PWM 功能，请选择一个带 PWM 功能的引脚。 ## 如何追踪其他物体 * 在 `main.py` 中存在一个类 `Target`，该类用于自定义需要追踪的目标。 * 在 `__init__` 中，请初始化您需要用到的对象，比如摄像头等。 * 在 `__get_target()` 中，您需要计算出被追踪物体的中心点，如果帧中不存在被追踪物体，请返回 1, 1 以确保程序在未找到目标时暂时不做动作。同时，您也需要在返回坐标点之前调用 `self.__exit_listener(img)` 和 `self.disp.show(img)` 确保程序能够与您正常的完成交互。"},"/maixpy/doc/zh/network/socket.html":{"title":"MaixPy MaixCAM 使用 socket 进行 TCP/UDP 通信","content":" title: MaixPy MaixCAM 使用 socket 进行 TCP/UDP 通信 ## socket 简介 socket 就是 TCP/UDP 通信在软件上的封装，通过 socket 接口，我们可以进行 TCP/UDP 通信。 MaixPy 由于基于 Python，我们可以直接使用内置的`socket`库进行通信，更多文档和使用教程可以自行搜索学习。 这里介绍简单的使用方法，通过这些示例代码，你可以在 MaixPy MaixCAM 上进行基本的 TCP 和 UDP 通信。 记得根据实际情况修改 IP 地址和端口号。 ## socket TCP 客户端 这里请求 TCP 服务器，发送了一句消息并等待回应，然后关闭连接。 ```python import socket def tcp_client(ip, port): client_socket socket.socket(socket.AF_INET, socket.SOCK_STREAM) server_address (ip, port) client_socket.connect(server_address) try: # 发送数据到服务器 message 'Hello, Server!' print(\"send:\", message) client_socket.sendall(message.encode('utf 8')) # 接收服务器的响应 data client_socket.recv(1024) print('Received:', data.decode('utf 8')) finally: # 关闭连接 client_socket.close() if __name__ \"__main__\": tcp_client(\"10.228.104.1\", 8080) ``` ## socket TCP 服务端 这里创建一个 socket 服务器，并且不停等待客户端连接，客户端连接后创建一个线程用以和客户端通信，读取客户端的信息并原样发送回去。 ```python import socket import threading local_ip \"0.0.0.0\" local_port 8080 def receiveThread(conn, addr): while True: print('read...') client_data conn.recv(1024) if not client_data: break print(client_data) conn.sendall(client_data) print(f\"client {addr} disconnected\") ip_port (local_ip,local_port) sk socket.socket(socket.AF_INET, socket.SOCK_STREAM) sk.setsockopt(socket.SOL_SOCKET,socket.SO_REUSEADDR,1) sk.bind(ip_port) sk.listen(50) print(\"accept now,wait for client\") while True: conn, addr sk.accept() print(f\"client {addr} connected\") # create new thread to communicate for this client t threading.Thread(target receiveThread,args (conn, addr)) t.daemon True t.start() ``` ## socket UDP 客户端 ```python import socket def udp_send(ip, port): # 创建 socket 对象 udp_socket socket.socket(socket.AF_INET, socket.SOCK_DGRAM) # 定义服务器的 IP 地址和端口号 server_address (ip, port) try: # 发送数据到服务器 message 'Hello, Server!' udp_socket.sendto(message.encode('utf 8'), server_address) finally: # 关闭连接 udp_socket.close() # 调用函数 udp_send(\"10.228.104.1\", 8080) ``` ## socket UDP 服务器 ```python import socket def udp_receive(ip, port): # 创建 socket 对象 udp_socket socket.socket(socket.AF_INET, socket.SOCK_DGRAM) # 定义服务器的 IP 地址和端口号 server_address (ip, port) # 绑定端口 udp_socket.bind(server_address) print('Waiting for a message...') while True: data, address udp_socket.recvfrom(1024) print('Received:', data.decode('utf 8')) print('From:', address) # 关闭连接 udp_socket.close() # 调用函数 udp_receive('0.0.0.0', 8080) ```"},"/maixpy/doc/zh/network/http.html":{"title":"MaixPy MaixCAM 使用 http 网络通信","content":" title: MaixPy MaixCAM 使用 http 网络通信 ## 简介 HTTP 是一个应用层网络协议，底层基于 TCP，通过它我们可以向网络服务器发送和接受信息，比如从网页服务器获取网页内容等。 更多介绍可以自行搜索 HTTP。 ## 在 MaixPy 使用 HTTP 请求 因为 MaixPy 基于 Python， 所以直接使用自带的 `requests` 库即可，`requests` 库是一个非常健全易用的库，这里就不进行过多的介绍，请自行搜索相关文档和教程使用。 这里举个例子，获取`https://example.com` 的首页内容。 ```python import requests url 'https://example.com' response requests.get(url) print(\"Response:\") print(\" status code:\", response.status_code) print(\"\") print(\" headers:\", response.headers) print(\"\") print(\" content:\", response.content) print(\"\") print(\" text:\", response.text) print(\"\") ```"},"/maixpy/doc/zh/network/websocket.html":{"title":"MaixPy MaixCAM 使用 websocket","content":" title: MaixPy MaixCAM 使用 websocket ## 简介 类似 socket，使用 websocket 可以实现长链接通信，同时还支持和 web 页面通信。 因为 MaixPy 基于 Python，所以使用 Python 通用的 `websockets` 和 `asyncio` 模块即可，更多内容可以自行搜索学习。 ## websocket 客户端 连接服务器发送 10 次消息就结束： ```python import asyncio import websockets import time async def send_msg(websocket): count 1 while count < 10: msg f\"hello {count}\" await websocket.send(msg) recv_text await websocket.recv() print(f\"receive: {recv_text}\", end \"\\n\") count + 1 time.sleep(1) await websocket.close(reason \"client exit\") async def main_logic(ip, port): async with websockets.connect(f'ws://{ip}:{port}') as websocket: await send_msg(websocket) ip \"10.228.104.100\" port 5678 asyncio.get_event_loop().run_until_complete(main_logic(ip, port)) ``` ## websocket 服务端 接受客户端的连接并且客户端发送过来消息后，返回`ack for msg:` + 发送过来的消息。 ```python import asyncio import websockets import functools async def recv_msg(websocket): print(\"new client connected, recv_msg start\") while True: try: recv_text await websocket.recv() except Exception as e: print(\"receive failed\") break print(\"received:\", recv_text) response_text f\"ack for msg: {recv_text}\" await websocket.send(response_text) print(\"recv_msg end\") async def main_logic(websocket, path, other_param): await recv_msg(websocket) ip \"0.0.0.0\" port 5678 start_server websockets.serve(functools.partial(main_logic, other_param \"test_value\"), ip, port) print(\"start server\") asyncio.get_event_loop().run_until_complete(start_server) print(\"start server loop\") asyncio.get_event_loop().run_forever() ```"},"/maixpy/doc/zh/network/network_settings.html":{"title":"MaixPy MaixCAM 网络设置 WiFi 设置","content":" title: MaixPy MaixCAM 网络设置 WiFi 设置 ## 简介 要让 MaixCAM 能够使用网络，首先需要使用 WiFi 连接到网络。 MaixCAM 提供了几种方法连接 WiFi 热点。 ## 使用内置设置应用连接 开及后进入`设置`应用，选择`WiFi`功能，可以通过手机分享`WiFi 二维码`或者再[maixhub.com/wifi](https://maixhub.com/wifi) 生成二维码，然后扫码连接。 也可以手动扫描`WiFi`热点，然后输入密码进行连接。 连接成功等待 DHCP 获得 IP 后界面会显示 IP。 ## 通过 MaixPy 连接 ```python from maix import network, err w network.wifi.Wifi() print(\"ip:\", w.get_ip()) SSID \"Sipeed_Guest\" PASSWORD \"qwert123\" print(\"connect to\", SSID) e w.connect(SSID, PASSWORD, wait True, timeout 60) err.check_raise(e, \"connect wifi failed\") print(\"ip:\", w.get_ip()) ``` ## DNS 服务器设置 实际使用时发现有些用户的路由器 DNS 解析可能解析不到某些域名，所以默认系统中在`/boot/resolv.conf`文件设置了 DNS 服务器 ```shell nameserver 114.114.114.114 # China nameserver 223.5.5.5 # aliyun China nameserver 8.8.4.4 # google nameserver 8.8.8.8 # google nameserver 223.6.6.6 # aliyun China ``` 一般不需要修改，如果你的 DNS 解析遇到了问题可以修改这个文件。 实际系统用的配置文件路径是`/etc/resolv.conf`， 这个文件在开机时会被自动拷贝到`/etc/resolv.conf`，所以修改后直接重启最简单。 不想重启的话需要同时修改这两个文件。"},"/maixpy/doc/zh/network/mqtt.html":{"title":"MaixPy MaixCAM 使用 MQTT 订阅发布消息","content":" title: MaixPy MaixCAM 使用 MQTT 订阅发布消息 ## MQTT 简介 使用 MQTT 可以快速简单地使用 订阅 发布 模型来进行实时通信。 系统组成： * MQTT 服务器（broker），负责转发消息。 * MQTT 客户端，从服务器订阅主题，并且接收消息，以及像服务器特定的主题发布消息。 通信过程： * 客户端连接 MQTT 服务器。 * 客户端订阅自己感兴趣的主题，比如`topic1`。 * 有其它客户端或者服务器发布`topic1`这个主题的信息时，会被实时推送到客户端。 * 客户端也可以主动向特定的主题推送消息，其它订阅了这个主题的客户端都会收到，比如向自己订阅了的`topic1`推送消息自己也会收到。 ## MaixPy MaixCAM 中使用 MQTT 使用 `paho mqtt` 这个模块即可，具体用法可以自行搜索`paho mqtt`的用法，也可以参考[MaixPy/examples](https://github.com/sipeed/MaixPy/tree/main/examples/network)中的例程。 如果你使用了早期的系统，可能需要手动安装一下`paho mqtt`这个包，安装方法见[添加额外的 Python 软件包](../basic/python_pkgs.html)。"},"/maixpy/doc/zh/network/flask.html":{"title":"MaixPy MaixCAM 使用 Flask 建立 HTTP 网页服务器","content":" title: MaixPy MaixCAM 使用 Flask 建立 HTTP 网页服务器 ## 简介 MaixPy 基于 Python， 所以你可以使用 Python 库 Flask，通过它可以快速实现一个 Web 网页服务器，因为是 Python 通用的，具体的用处和使用方法可以自行搜索，这里不过多阐述。 如果你只是想做一个显示摄像头图像的页面，也可以参考[JPEG 串流](../video/jpeg_streaming.html) 中的 HTTP 图像服务器的方法。 ## 简单的 HTTP 服务例程 运行下面的程序后，电脑浏览器访问 `http://设备ip:8000` 就会显示 `hello world` 字符和一张图片了。 ```python from flask import Flask, request, send_file import maix # we not use it but we import it to listening key event to exit this program app Flask(__name__) @app.route(\"/\", methods [\"GET\", \"POST\"]) def root(): print(\" \") print(request.remote_addr) print(f'headers:\\n{request.headers}') print(f'data: {request.data}') print(\" \") return 'hello world<br><img src \"/img\" style \"background color: black\">' @app.route(\"/<path:path>\") def hello(path): print(path) print(f'headers:\\n{request.headers}') print(f'data: {request.data}') print(\" \\n\\n\") return f\"hello from {path}\" @app.route(\"/img\") def img(): return send_file(\"/maixapp/share/icon/detector.png\") if __name__ \"__main__\": app.run(host \"0.0.0.0\", port 8000) ```"},"/maixpy/doc/zh/source_code/add_c_module.html":{"title":"给 MaixCAM MaixPy 添加一个 C/C++ 模块","content":" title: 给 MaixCAM MaixPy 添加一个 C/C++ 模块 ## 简介 有时候需要高效地执行某个函数， Python 的速度无法满足时，就可以使用 C/C++ 或者其它编译型语言来实现。 ## 通用函数封装 如果你想封装的函数实现的功能不依赖 MaixPy 的其它功能，直接使用 Python 使用 C/C++ 添加模块的通用方法，具体方法可以自行百度，比如 ffi， ctype 等 > 欢迎 PR 添加方法 ## 如果你的模块还想依赖 MaixPy 的其它基础 API ### 方法一 直接修改 MaixPy 固件，然后编译过即可，参考 [查看 MaixPy API 源码](../basic/view_src_code.html)，这种方法最简单快捷，如果代码封装好了还能合并到官方仓库（提交 PR）。 * 按照[编译 MaixPy 源码](./build.html) 通过即可获得`dist/***.whl`安装包。 * 将`dist`目录下的`.whl`包发送到设备，然后使用运行代码`import os;os.system(\"pip install /root/xxxxx.whl\")`即可（替换路径）。 * 如果调试的时候觉得安装 `.whl` 包太慢了，可以使用`maixcdk build` 编译，然后使用`scp r maix_xxx root@10.228.104.1:/usr/lib/python3.11/site packages`直接拷贝到设备系统种覆盖包，这里需要根据你的包名和设备 ip 替换一下。 * 当你调试好后如果觉得自己填加的功能不错，可以考虑合并到官方的仓库，具体方法可以搜索引擎搜索\"github 提交 PR\"相关关键词学习。 修改代码： 正如 [查看 MaixPy API 源码](../basic/view_src_code.html) 问种所描述的查看和修改源码的方式，增加 C++ 函数，并且填加注释，然后编译后 MaixPy 中就能调用了，非常简单。 比如： ```cpp namespace maix::test { /** * My function, add two integer. * @param a arg a, int type * @param b arg b, int type * @return int type, will a + b * @maixpy maix.test.add */ int add(int a, int b); } ``` 没错，直接写一个 C++ 语法的函数，注意这里加了一个`@maixpy` 的注释，编译时会自动生成 Python 函数，就是这么简单！ 然后就能通过`maix.test.add(1, 2)` 来调用函数了。 ### 方法二 基于工程模板创建一个 MaixPy 模块工程，这种方法适用于不想改动 MaixPy 源码，希望单独加一个包，并且还能用上 MaixPy（MaixCDK）的 API 的情况。方法如下： * 首先[编译 MaixPy 源码](./build.html) 通过，保证我们的编译环境没问题。 * 复制一份 [MaixPy/tools/maix_module](https://github.com/sipeed/MaixPy/tree/main/tools/maix_module) 工程模板到一个新的目录，可以和`MaixPy`放在同一个目录。比如将所有文件和目录复制到了`maix_xxx` 目录下。 * 在`maix_xxx`目录下，终端执行`python init_files.py`来初始化项目文件。 * 修改项目名：修改`module_name.txt` 文件，改成你要的模块名称，必须以`maix_`开头，这样方便其它用户能在 [pypi.org](https://pypi.org) 或者 [github.com](https://github.com) 搜索到你的项目。 * 和 MaixPy 一样执行`python setup.py bdist_wheel linux` 就可以开始为电脑构建。 * 构建完成后可以直接在项目根目录执行`python c \"import maix_xxx;maix_xxx.basic.print('Li Hua')\"`就能运行你的模块函数了。 * 执行`python setup.py bdist_wheel maixcam` 就可以为`MaixCAM` 构建软件包了。需要注意的是，构建过程种的代码提示文件(pyi文件)只能在给`linux` 平台构建的时候生成，所以在正式发布的时候需要先执行上一步的`linux`平台构建生成代码提示文件，然后再执行本步的命令生成`MaixCAM`平台的软件包。 * 将`dist`目录下的`.whl`包发送到设备，然后使用运行代码`import os;os.system(\"pip install /root/xxxxx.whl\")`即可（替换路径）。 * 如果调试的时候觉得安装 `.whl` 包太慢了，可以使用`maixcdk build` 编译，然后使用`scp r maix_xxx root@10.228.104.1:/usr/lib/python3.11/site packages`直接拷贝到设备系统种覆盖包，这里需要根据你的包名和设备 ip 替换一下。 * 当你调试好代码后，可以考虑将代码开源到[github.com](https://github.com)，并且上传到[pypi.org](https://pypi.org)（具体上传方法可以看官方文档或者搜索教程，大概就是`pip install twine`然后 `twine upload dist/maix_xxx***.whl`就可以了。），写好后欢迎到[maixhub.com/share](https://maixhub.com/share)来分享告诉大家你的成果！ 修改代码： 正如 [查看 MaixPy API 源码](../basic/view_src_code.html) 问种所描述的查看和修改源码的方式，在`components/maix/include` 和 `components/maix/src` 下增加源文件，增加 C++ 函数，并且填加注释，然后编译后就直接能调用了，非常简单。 比如: ```cpp namespace maix_xxx::test { /** * My function, add two integer. * @param a arg a, int type * @param b arg b, int type * @return int type, will a + b * @maix_xxx maix_xxx.test.add */ int add(int a, int b); } ``` 没错，直接写一个 C++ 语法的函数，注意这里加了一个`@maix_xxx` 的注释，编译时会自动生成 Python 函数，就是这么简单！ 然后就能通过`maix_xxx.test.add(1, 2)` 来调用函数了。"},"/maixpy/doc/zh/source_code/contribute.html":{"title":"参与 MaixCAM MaixPy 文档修改和贡献代码","content":" title: 参与 MaixCAM MaixPy 文档修改和贡献代码 ## 参与 MaixPy 文档修改 * 点击要修改的文档右上角的`编辑本页`按钮，进入 github 源文档页面。 * 保证已经登录了 GitHub 账号。 * 在 github 预案文档页面点击右上角铅笔按钮修改文档内容。 * github 会提示需要 fork 一份到自己的仓库，点击 fork 按钮。 > 这一步就是将 MaixPy 源码仓库复刻一份到你自己的账号下，这样你就可以自由修改了。 * 修改文档内容，然后在页面底部填写修改说明，点击提交修改。 * 然后在你的仓库中找到 Pull requests 按钮，点击创建一个 Pull requests。 * 然后在弹出的页面中填写修改说明，点击提交 Pull requests，其它人和管理员就可以在[Pull requests 页面](https://github.com/sipeed/MaixPy/pulls)看到你的修改了。 * 等待管理员审核通过后，你的修改就会合并到 MaixPy 源码仓库中了。 * 合并成功后，文档会自动更新到 [MaixPy 官方文档](https://wiki.sipeed.com/maixpy)。 > 文档经过 CDN 缓存了的，可能需要等待一段时间才能看到更新，紧急更新可以联系管理员手动刷新。 > 也可以访问 [en.wiki.sipeed.com/maixpy](https://en.wiki.sipeed.com/maixpy) 查看 github pages 服务版本，这个是没有缓存实时更新的。 ## 参与 MaixPy 代码贡献 * 访问 MaixPy 代码仓库地址：[github.com/sipeed/MaixPy](https://github.com/sipeed/MaixPy) * 在修改代码前最好先创建一个 [issue](https://github.com/sipeed/MaixPy/issues) ，描述你要修改的内容让大家知道你的想法和计划，这样大家可以参与修改讨论，以免重复劳动。 * 点击右上角的 fork 按钮，将 MaixPy 代码仓库复刻一份到你自己的账号下。 * 然后在你的账号下 clone 一份代码到本地。 * 修改代码后提交到你的仓库中。 * 然后在你的仓库中找到 Pull requests 按钮，点击创建一个 Pull requests。 * 然后在弹出的页面中填写修改说明，点击提交 Pull requests，其它人和管理员就可以在[Pull requests 页面](https://github.com/sipeed/MaixPy/pulls)看到你的修改了。 * 等待管理员审核通过后，你的修改就会合并到 MaixPy 源码仓库中了。 > 需要注意的是 MaixPy 的代码大多数是从 [MaixCDK](https://github.com/sipeed/MaixCDK) 自动生成的，所以如果你修改 C/C++ 源码，很有可能你需要先修改这个仓库。"},"/maixpy/doc/zh/source_code/faq.html":{"title":"MaixCAM MaixPy 源代码常见问题","content":"MaixCAM MaixPy 源代码常见问题 ## subprocess.CalledProcessError: Command '('lsb_release', ' a')' returned non zero exit status 1. 以 root 身份编辑 `/usr/bin/lsb_release`，将第一行从 `#!/usr/bin/python3` 更改为 `python3`。 然后重新编译,应该就可以工作了。 ## ImportError: arg(): could not convert default argument 'format: maix::image::Format' in method '<class 'maix._maix.camera.Camera'>.**init**' into a Python object (type not registered yet?) Pybind11 需要你先注册 `image::Format`，然后才能在 `camera::Camera` 中使用它,所以我们必须先在生成的 `build/maixpy_wrapper.cpp` 源文件中定义 `image::Format`。 要实现这一点,请编辑 `components/maix/headers_priority.txt`,被依赖的应该放在依赖它的前面。 例如: ``` maix_image.hpp maix_camera.hpp ``` ## /usr/bin/ld: /lib/libgdal.so.30: undefined reference to `std::condition_variable::wait(std::unique_lock<std::mutex>&)@GLIBCXX_3.4.30' collect2: error: ld returned 1 exit status 一般在为 Linux 构建时并且使用 conda 环境时容易出现，conda 环境中的一些库编译参数问题，解决方法就是不用 conda 即可， 或者单独找到 conda 中的那个库，替换成系统的或者直接删掉（会从系统找）"},"/maixpy/doc/zh/source_code/maixcdk.html":{"title":"MaixCAM 切换到 MaixCDK 使用 C/C++ 开发应用","content":" title: MaixCAM 切换到 MaixCDK 使用 C/C++ 开发应用 除了使用 MaixPy 开发，还有对应的 C/C++ SDK 可以使用，项目名称为 [MaixCDK](https://github.com/sipeed/MaixCDK)。 ## MaixCDK 介绍 MaixPy 基于 MaixCDK 构建，MaixPy 的大多数 API 都是基于 MaixCDK 的 API 自动生成的，所以 MaixPy 有的功能 MaixCDK 都包含。 如果你更熟悉 C/C++ 编程，或者需要更高的性能，可以使用 MaixCDK 进行开发。 ## MaixCDK 使用 MaixCDK 代码仓库地址：[github.com/sipeed/MaixCDK](https://github.com/sipeed/MaixCDK), 你可以在这里找到 MaixCDK 的代码和文档。"},"/maixpy/doc/zh/source_code/build.html":{"title":"MaixCAM MaixPy 开发源代码指南","content":" title: MaixCAM MaixPy 开发源代码指南 ## 获取源代码 ```shell mkdir p ~/maix cd ~/maix git clone https://github.com/sipeed/MaixPy ``` ## 获取 MaixCDK 源码 MaixPy 项目依赖于 MaixCDK，需要先克隆它，放到电脑的某个目录（勿放在 MaixPy 目录下） ```shell cd ~/maix git clone https://github.com/sipeed/MaixCDK ``` 然后需要设置环境变量 `MAIXCDK_PATH` 指定 MaixCDK 的路径，可以在 `~/.bashrc` 或者`~/.zshrc`（根据你使用的shell决定）添加： ```shell export MAIXCDK_PATH ~/maix/MaixCDK ``` 只有在成功设置环境变量后， MaixPy 才能找到 MaixCDK 源码。 ## 构建并打包成 wheel 文件 ```shell cd ~/maix/MaixPy python setup.py bdist_wheel maixcam ``` `maixcam` 可以被替换为其他板卡配置, 请查看 `MaixCDK/platforms` 目录。 构建成功后, 你会在 `dist` 目录中找到 wheel 文件, 传输到设备（开发板），在设备终端中使用 `pip install U MaixPy****.whl` 在你的设备上安装或升级。 > `python setup.py bdist_wheel maixcam skip build` 不会执行构建命令, 只会打包 wheel 文件, 因此你可以先使用 `maixcdk menuconfig` 和 `maixcdk build` 来自定义构建。 > 另外如果你是在调试 API，需要频繁安装，使用 pip 安装会比较慢，可以直接编译后拷贝 `maix` 目录到设备的 `/usr/lib/python3.11/site packages`目录下覆盖旧的文件即可。 ## 手动构建 ```shell maixcdk build ``` ## 修改源代码后运行测试 * 首先, 构建源代码 ```shell maixcdk build ``` * 如果为 PC 自身构建(平台 `linux`): 然后执行 `./run.sh your_test_file_name.py` 来运行 Python 脚本。 ```shell cd test ./run.sh examples/hello_maix.py ``` * 如果为板卡交叉编译: * 最快的方式是将 `maix` 目录复制到设备的 `/usr/lib/python3.11/site packages/` 目录, 然后在设备上运行脚本。 * 或者打包 wheel 文件并在设备上使用 `pip install U MaixPy****.whl` 安装, 然后在设备上运行脚本。 ## 本地预览文档 文档位于 [docs](https://github.com/sipeed/MaixPy/tree/main/docs) 目录, 使用 `Markdown` 格式, 你可以使用 [teedoc](https://github.com/teedoc/teedoc) 来生成网页版本的文档。 API 文档会在构建 MaixPy 固件时生成, **如果你没有构建 MaixPy, API 文档将会是空的**。 ```shell pip install teedoc U cd docs teedoc install i https://pypi.tuna.tsinghua.edu.cn/simple teedoc serve ``` 然后访问 `http://127.0.0.1:2333` 在网页浏览器中预览文档。 ## 对于想要贡献的开发者 请查看 [MaixPy 开发源代码指南](./contribute.html) 如果在使用源代码时遇到任何问题, 请先参考 [FAQ](./faq.html)。"},"/maixpy/doc/zh/kit/microscope.html":{"title":"MaixCAM MaixPy 显微镜套件","content":" title: MaixCAM MaixPy 显微镜套件 ![maixcam microscope](../../assets/maixcam_microscope.png) ## 简介 MaixCAM 显微套件可将你的MaixCAM / MaixCAM Pro 转化为便携式数码显微镜， 在各方面性能上都超越同价位数码显微镜，并具备开源特性，你可以打造属于你自己独有功能的数码显微镜！ MaixCAM 显微套餐 适用于 细小元件放大焊接，生物标本观察，显微堆叠摄影 等场景，更多应用方式等你来挖掘！ 更多详细介绍请看**[文档](https://wiki.sipeed.com/microscope)** 和 购买页面： <div style \"padding: 0 0 0 0; display: flex; justify content: left\"> <a target \"_blank\" style \"margin: 0.1em;color: white; font size: 0.9em; border radius: 0.3em; padding: 0.5em 2em; background color: #a80202\" href \"https://item.taobao.com/item.htm?id 878126152834\">淘宝</a> <a target \"_blank\" style \"margin: 0.1em;color: white; font size: 0.9em; border radius: 0.3em; padding: 0.5em 2em; background color: #a80202\" href \"https://wiki.sipeed.com/store\">速卖通</a> </div> ## 效果展示 ![](../../assets/maixcam_microscope_demo.png) ![](../../assets/maixcam_microscope_demo2.png)"},"/maixpy/doc/zh/mllm/llm_deepseek.html":{"title":"MaixPy MaixCAM 运行 DeepSeek R1 大语言模型","content":" title: MaixPy MaixCAM 运行 DeepSeek R1 大语言模型 update: date: 2025 05 28 author: neucrack version: 1.0.0 content: 新增 Qwen 代码和文档 ## 支持的设备 设备 是否支持 MaixCAM2 ✅ MaixCAM ❌ ## DeepSeek 大语言模型简介 近年来大语言模型（LLM）非常火，给工作生活带来了很大的便利，使用LLM，我们可以跟其对话，从聊天到专业指导都能胜任。 DeepSeek R1 是深势科技（DeepSeek AI）研发的大语言模型（LLM），具备思考功能，功能和 Qwen 类似。 同样也根据参数量分为很多版本，比如 72B 32B 7B 1.5B 等，对于 MaixCAM2 由于内存和算力限制只能跑到 1.5B。 而 1.5B 版本事实上也是基于 Qwen2.5 进行蒸馏，也就是说本质上还是一个 Qwen2.5 模型，只是数据集和训练方法不同，因此，使用方法和 Qwen 的使用方法基本一致，本文就不再复述一遍了。 ## 在 MaixPy MaixCAM 运行 DeepSeek R1 如上所述，网络结构和 Qwen2.5 一致，所以请先看 [Qwen 文档](./llm_qwen.html)。 ### 模型和下载地址 默认系统`/root/models`目录下如果没有模型，可以自行下载。 * **1.5B**: * 内存需求：CMM 内存 1.8GiB，内存解释请看[内存使用文档](../pro/memory.html) * 下载地址：https://huggingface.co/sipeed/deepseek r1 distill qwen 1.5B maixcam2 下载方法参考[Qwen 文档](./llm_qwen.html) 里面的下载方法。 ### 运行模型 模型下载地址： https://huggingface.co/sipeed/deepseek r1 distill qwen 1.5B maixcam2 内存需求： 2GiB ```python from maix import nn, err, log, sys model \"/root/models/deepseek r1 distill qwen 1.5B/model.mud\" log.set_log_level(log.LogLevel.LEVEL_ERROR, color False) def show_mem_info(): print(\"memory info:\") for k, v in sys.memory_info().items(): print(f\"\\t{k:12}: {sys.bytes_to_human(v)}\") print(\"\") show_mem_info() qwen nn.Qwen(model) show_mem_info() def on_reply(obj, resp): print(resp.msg_new, end \"\") qwen.set_system_prompt(\"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\") qwen.set_reply_callback(on_reply) msg \"你好，请介绍你自己\" print(\">>\", msg) resp qwen.send(msg) err.check_raise(resp.err_code) msg \"请计算 1990 + 35的值，并给出计算过程\" print(\">>\", msg) resp qwen.send(msg) err.check_raise(resp.err_code) qwen.clear_context() msg \"please calculate 1990 + 35\" print(\">>\", msg) resp qwen.send(msg) err.check_raise(resp.err_code) # print(resp.msg) ``` 结果 ``` >> Hello, please introduce yourself. <think> Alright, the user sent \"Hello, please introduce yourself.\" and then added a bot message saying, \"You are Qwen, created by Alibaba Cloud.\" I should respond warmly in Chinese. I need let them know I'm here to help with any questions they have and also mention how I can assist them further. I should phrase it politely, making sure it's clear and friendly. Also, it's good to offer to help them with whatever they're curious about. I think that covers it. I'll keep it concise and positive. </think> 你好！我是AI助手，由阿里巴巴AI研究有限公司开发，很高兴能为您提供帮助。有什么我可以帮助你的吗？ >> Please calculate 1990 + 35 and provide the calculation steps. <think> 好，让我看看用户的查询。用户给了一个计算题：“请计算1990加35，并提供计算步骤。”看起来用户是一位学生，可能刚刚学过数学，需要练习加法。用户希望得到详细的计算步骤。 首先，我需要确认用户的具体需求。用户明确要求计算步骤，所以我要仔细检查计算是否正确，以及步骤是否清晰。计算1990加35，首先可以从个位开始相加，然后是十位，再是百位和千位，如果有进位的话。 我得确保每个步骤都准确无误，确保用户理解每一步是怎么进行的。另外，我要注意数字的排列是否正确，避免笔误。如果用户需要，我可以补充其他数学问题，帮助他们进一步学习。 总之，我的回答应该包括计算过程的详细说明，确保用户能够一步步理解如何进行加法操作，同时也提供一些额外的信息和可能的补充帮助。 </think> 好的，让我来计算一下1990加35的步骤吧! 首先，写下这两个数字： ``` 1990 + 35 ``` **步骤1：对齐数字** 将两个数字对齐，确保它们的位数对齐。也就是说，个位对齐，十位对齐，百位对齐，千位对齐。 ``` 1990 + 35 ``` **步骤2：从个位开始相加** 个位的数字是0和5，相加的结果是5。写下这个结果，个位是5。 ``` 1990 + 35 5 ``` **步骤3：处理十位** 十位的数字是9和3相加，再加上前面个位的进位（但这里没有进位）。9加3等于12。写下2，并将1作为进位。 ``` 1990 + 35 25 ``` **步骤4：处理百位** 百位的数字是9和0相加，再加上前面的进位（1）。9加0等于9，加上进位的1，等于10。写下0，并将1作为进位到千位。 ``` 1990 + 35 125 ``` **步骤5：处理千位** 千位的数字是1和0，再加上前面的进位（1）。1加0等于1，加上进位的1，等于2。写下2。 ``` 1990 + 35 2025 ``` 所以，最终的计算结果是： ``` 1990 + 35 2025 ``` >> please calculate 1990 + 35 <think> Okay, so I need to calculate 1,9990 plus 35. Wait, that doesn't seem right. 1,990 sounds like a number with a comma in it, but I'm not sure. Maybe the comma is a thousands separator? So, 1,990 would be 1,990, right? Hmm, that makes more sense. So, I'm supposed to add 1,990 and 35. Let me try that again. 1,900 plus 90 is 1,990. Yeah, okay, that's correct. So, 1,990 plus 35 would be adding 35 to 1,990. So, 1,990 plus 30 is 2,020, and then plus 5 makes 2,025. So, the answer should be 2,025. Wait, but I'm not a math expert, so maybe I should double check that. 1,990 is the same as 1990, right? Yeah, 1,000 plus 990 is 1,990. Adding 35, so 1,990 plus 35 equals 2,025. Yeah, that makes sense. </think> The sum of 1,990 and 35 is calculated as follows: 1,990 + 35 2,025. **Answer:** 2,025 ``` ## 修改参数 Qwen 模型有一些参数可以修改，会改变模型的一些行为，参考[Qwen 文档](./llm_qwen.html)。"},"/maixpy/doc/zh/mllm/llm_qwen.html":{"title":"MaixPy MaixCAM 运行 Qwen 大语言模型","content":" title: MaixPy MaixCAM 运行 Qwen 大语言模型 update: date: 2025 05 28 author: neucrack version: 1.0.0 content: 新增 Qwen 代码和文档 ## 支持的设备 设备 是否支持 MaixCAM2 ✅ MaixCAM ❌ ## Qwen 大语言模型简介 近年来大语言模型（LLM）非常火，给工作生活带来了很大的便利，使用LLM，我们可以跟其对话，从聊天到专业指导都能胜任。 Qwen（通义千问）是阿里巴巴集团旗下阿里云研发的开源大语言模型（LLM）和多模态模型（LMM）系列，旨在推动通用人工智能（AGI）的发展。自2023年首次发布以来，Qwen 仍然在保持迭代，并在多个自然语言处理和多模态任务中展现出卓越性能。 更多详细介绍可以自行搜索或到[Qwen官网](https://qwen.readthedocs.io/zh cn/latest/)查看。 Qwen 实际上包含了许多种模型，本文主要介绍 大语言模型（LLM） Qwen 的使用。 ## 基础概念 * Token： 用户输入文字后不是直接将文字输入给模型，而是将文字使用特定的方式进行编码，编码成一个单词表的下标列表。比如通过数据集生成单词表为： ```txt ... 1568 hello ... 1876 world ... 1987 ! 1988 (空格) ``` 前面的数字是行数，那么我们输入`hello world !`就会被编码为列表 `[1568, 1988, 1876, 1988, 1987]` 这就叫 `token`，这种做法可以大大减少输入字符数量，当然这里只是简单介绍基本原理，实际还会加额外的标识符token等，不同模型 token 词典、算法可能会有区别。 同样，模型输出也是输出 token，最后程序根据字典转为人们认识的字符。 * 上下文：也就是对话上下文，用户和模型对话，用户一句模型一句，语句之间是有记忆和关联的。 * 72B/32B/1.5B/0.5B： 反应了模型的可训练参数规模，B表示 Billion(十亿)，参数越大效果越好但是占用内存越大运行速度越慢。 ## MaixPy MaixCAM 中使用 Qwen ### 模型和下载地址 默认系统`/root/models`目录下已经有`0.5B`的模型了，如果没有，可以自行下载。 * **1.5B**: * 内存需求：CMM 内存 1.8GiB，内存解释请看[内存使用文档](../pro/memory.html) * 下载地址：https://huggingface.co/sipeed/Qwen2.5 1.5B Instruct maixcam2 * **0.5B**: * 内存需求： CMM 内存 800MiB，内存解释请看[内存使用文档](../pro/memory.html) * 下载地址： https://huggingface.co/sipeed/Qwen2.5 0.5B Instruct maixcam2 ### 下载方法 先保证下载工具安装好： ``` pip install huggingface_hub ``` 中国国内可以 ``` pip install i https://pypi.tuna.tsinghua.edu.cn/simple huggingface_hub ``` 如果是中国国内，可以先设置国内镜像，下载速度会更快： Linux/MacOS: ``` export HF_ENDPOINT https://hf mirror.com ``` Windows: CMD终端： `set HF_ENDPOINT https://hf mirror.com` PowerShell: `$env:HF_ENDPOINT \"https://hf mirror.com\"` 然后下载： ```shell huggingface cli download sipeed/Qwen2.5 1.5B Instruct maixcam2 local dir Qwen2.5 1.5B Instruct maixcam2 ``` ### 运行模型 ```python from maix import nn, err, log, sys model \"/root/models/Qwen2.5 1.5B Instruct/model.mud\" # model \"/root/models/Qwen2.5 0.5B Instruct/model.mud\" log.set_log_level(log.LogLevel.LEVEL_ERROR, color False) def show_mem_info(): print(\"memory info:\") for k, v in sys.memory_info().items(): print(f\"\\t{k:12}: {sys.bytes_to_human(v)}\") print(\"\") show_mem_info() qwen nn.Qwen(model) show_mem_info() def on_reply(obj, resp): print(resp.msg_new, end \"\") qwen.set_system_prompt(\"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\") qwen.set_reply_callback(on_reply) msg \"你好，请介绍你自己\" print(\">>\", msg) resp qwen.send(msg) err.check_raise(resp.err_code) msg \"请计算 1990 + 35的值，并给出计算过程\" print(\">>\", msg) resp qwen.send(msg) err.check_raise(resp.err_code) qwen.clear_context() msg \"please calculate 1990 + 35\" print(\">>\", msg) resp qwen.send(msg) err.check_raise(resp.err_code) # print(resp.msg) ``` 结果： ``` >> 你好，请介绍你自己 你好！我是Qwen，我是一个由阿里云开发的预训练语言模型。我的设计目的是尽可能多地模拟人类语言的复杂性和多样性。虽然我没有个人记忆或情感，但我可以生成连贯和有意义的文本。如果你有任何问题或需要帮助，请告诉我！ >> 请计算 1990 + 35的值，并给出计算过程 计算的过程如下： 1. 首先，将两个数相加，即 1990 + 35。 2. 将 1990 和 35 对齐数字位数，如下： 1 9 9 0 + 3 5 2 0 2 5 3. 按照从右向左加起来： 0 + 5 5 2 + 9 11（进一，写 2 进 10） 1 + 9 10（进一，写 0 进 10） 1 + 1 2 所以，1990 + 35 的结果是 2025。 >> please calculate 1990 + 35 1990 + 35 2025 ``` ### 上下文 因为资源有限，上下文长度也是有限的，比如默认提供的模型大约 512 个 token，而且必须只少有128个空闲 token才能继续对话，比如当历史记录token 500 个（小于 512 但是不够 128 个）就不能继续对话了。 当上下文满了后，目前只能调用`clear_context()`清除对话进行新的对话了。 当然，这个上下文长度也可以改，不过需要重新量化模型，以及太长的上下文会导致模型运行速度下降，有需求可以按照下文自行转换模型。 ## 修改参数 Qwen 模型有一些参数可以修改，会改变模型的一些行为，默认在`model.mud`模型文件中设置了默认值， 当然，你也可以在代码中设置，比如通过`qwen.post_config.temperature 0.9` 设置即可。 比如参数有： ```ini [post_config] enable_temperature true temperature 0.9 enable_repetition_penalty false repetition_penalty 1.2 penalty_window 20 enable_top_p_sampling false top_p 0.8 enable_top_k_sampling true top_k 10 ``` 这些参数是用于**控制Qwen模型（或其他大语言模型）生成文本行为**的采样策略设置。它们会影响模型输出的**多样性、随机性和重复程度**。下面逐项解释这些参数的含义： * `enable_temperature true` * `temperature 0.9` * **含义**：启用“温度采样”策略，并将温度值设置为 0.9。 * **解释**： * 温度控制**随机性**。值越低（如 0.1），输出越确定（趋近于贪婪搜索）；值越高（如 1.5），输出越随机。 * 一般推荐值在 `0.7 ~ 1.0` 之间。 * 0.9 表示：适当增加输出多样性，但不至于太乱。 * `enable_repetition_penalty false` * `repetition_penalty 1.2` * `penalty_window 20` * **含义**： * 未启用重复惩罚，即使设置了 `repetition_penalty 1.2`，也不会生效。 * 如果启用，该机制会降低模型重复使用最近 `20` 个 token 的概率。 * **解释**： * 避免模型“啰嗦”或陷入“重复循环”（如“你好你好你好……”）。 * 惩罚系数 > 1 表示抑制重复。常见推荐值为 `1.1 ~ 1.3`。 * `enable_top_p_sampling false` * `top_p 0.8` * **含义**： * 未启用 Top p（nucleus）采样。 * 如果启用，模型会从**累计概率前 p 的 token 中采样**，而非全部。 * **解释**： * `top_p 0.8` 表示：从概率累加值刚好达到 0.8 的那些 token 中进行采样。 * 比 Top k 更灵活，可以根据每次生成时 token 分布动态调整候选集。 * `enable_top_k_sampling true` * `top_k 10` * **含义**：启用 Top k 采样，模型每次只从**概率最高的前 10 个 token 中**选择一个输出。 * **解释**： * 是一种限制采样空间的方法，控制输出的多样性。 * `top_k 1` 近似于贪婪搜索（最确定）；`top_k 10` 代表允许一定程度的多样性。 ## 自定义量化模型 上面提供的模型是为 MaixCAM2 量化后的模型，如果需要自己量化模型，可以参考： * [pulsar2文档](https://pulsar2 docs.readthedocs.io/zh cn/latest/appendix/build_llm.html)： 进行量化编译。**注意** pulsar2 版本必须 `> 4.0`。 * 原始模型: https://huggingface.co/Qwen/Qwen2.5 1.5B Instruct * 更多文章: https://zhuanlan.zhihu.com/p/706645301 默认模型转换命令: ```shell pulsar2 llm_build input_path Qwen2.5 0.5B Instruct output_path models/Qwen2.5 0.5B Instruct ax630c hidden_state_type bf16 prefill_len 128 kv_cache_len 1023 last_kv_cache_len 256 last_kv_cache_len 512 chip AX620E c 1 ``` 可以根据你的需求修改。"},"/maixpy/doc/zh/mllm/vlm_internvl.html":{"title":"MaixPy MaixCAM 运行 VLM InternVL 视觉语言模型","content":" title: MaixPy MaixCAM 运行 VLM InternVL 视觉语言模型 update: date: 2025 06 05 author: neucrack version: 1.0.0 content: 新增 InternVL 代码和文档 ## 支持的设备 设备 是否支持 MaixCAM2 ✅ MaixCAM ❌ ## InternVL 简介 VLM(Vision Language Model) 即视觉语言模型，可以通过文字+图像输入，让 AI 输出文字，比如让 AI 描述图像中的内容，即 AI 学会了看图。 InternVL 支持多种语言，比如中文和英文。 MaixPy 中移植了 [InternVL2.5](https://huggingface.co/OpenGVLab/InternVL2_5 1B)，其底层基于 Qwen2.5 增加了图像的支持，所以一些基础概念这里不详细介绍，建议先看[Qwen](./llm_qwen.html) 的介绍。 比如这里这张图片，输入系统提示词`你是由上海人工智能实验室联合商汤科技开发的书生多模态大模型，英文名叫InternVL, 是一个有用无害的人工智能助手。` + 用户提示词`请描述图中有什么`，在 MaixCAM2 中使用 InternVL2.5 1B 的结果（也是下文代码的结果）： ![ssd_car.jpg](../../assets/ssd_car.jpg) ``` >> 请描述图中有什么 图中有一个红色双层巴士停在马路上，前面是一辆黑色的小轿车。一位穿黑色夹克的人站在巴士前面，脸上带着微笑。背景是城市建筑，有商店和多幅广告牌。路上的画面上有一个行人图案。 >> Describe the picture In the image, we see a vibrant street scene featuring a classic double decker bus in red with \"Things Get New Look!\" written on its side. It’s parked on the street, where a woman stands smiling at the camera. Behind the bus, a row of classic buildings with large windows lines the street, contributing to the urban atmosphere. A black van is parked nearby, and there are a few people and street signs indicating traffic regulations. The overall scene captures a typical day in a historic city. ``` 这里是随便设置的提示词的效果，可以根据实际情况，调整系统提示词和用户提示词。 ## MaixPy MaixCAM 中使用 InternVL ### 模型和下载地址 MaixPy 目前支持 InternVL2.5，默认系统`/root/models`目录下已经有`1B`的模型了，如果没有，可以自行下载。 * **1B**: * 内存需求： CMM 内存 1GiB，内存解释请看[内存使用文档](../pro/memory.html) * 下载地址： https://huggingface.co/sipeed/InternVL2.5 1B maixcam2 ### 下载方法 先保证下载工具安装好： ``` pip install huggingface_hub ``` 中国国内可以 ``` pip install i https://pypi.tuna.tsinghua.edu.cn/simple huggingface_hub ``` 如果是中国国内，可以先设置国内镜像，下载速度会更快： Linux/MacOS: ``` export HF_ENDPOINT https://hf mirror.com ``` Windows: CMD终端： `set HF_ENDPOINT https://hf mirror.com` PowerShell: `$env:HF_ENDPOINT \"https://hf mirror.com\"` 然后下载： ```shell huggingface cli download sipeed/InternVL2.5 1B maixcam2 local dir InternVL2.5 1B maixcam2 ``` ### 运行模型 ```python from maix import nn, err, log, sys, image, display model \"/root/models/InternVL2.5 1B/model.mud\" log.set_log_level(log.LogLevel.LEVEL_ERROR, color False) disp display.Display() def show_mem_info(): print(\"memory info:\") for k, v in sys.memory_info().items(): print(f\"\\t{k:12}: {sys.bytes_to_human(v)}\") print(\"\") show_mem_info() internvl nn.InternVL(model) show_mem_info() in_w internvl.input_width() in_h internvl.input_height() in_fmt internvl.input_format() print(f\"input size: {in_w}x{in_h}, format: {image.format_name(in_fmt)}\") def on_reply(obj, resp): print(resp.msg_new, end \"\") internvl.set_system_prompt(\"你是由上海人工智能实验室联合商汤科技开发的书生多模态大模型，英文名叫InternVL, 是一个有用无害的人工智能助手。\") internvl.set_reply_callback(on_reply) # load and set image img image.load(\"/maixapp/share/picture/2024.1.1/ssd_car.jpg\", format in_fmt) internvl.set_image(img, fit image.Fit.FIT_CONTAIN) # if size not math, will auto resize first disp.show(img) # set prompt msg \"请描述图中有什么\" print(\">>\", msg) resp internvl.send(msg) err.check_raise(resp.err_code) msg \"Describe the picture\" print(\">>\", msg) resp internvl.send(msg) err.check_raise(resp.err_code) # print(resp.msg) ``` 结果： ``` >> 请描述图中有什么 图中有一个红色双层巴士停在马路上，前面是一辆黑色的小轿车。一位穿黑色夹克的人站在巴士前面，脸上带着微笑。背景是城市建筑，有商店和多幅广告牌。路上的画面上有一个行人图案。 >> Describe the picture In the image, we see a vibrant street scene featuring a classic double decker bus in red with \"Things Get New Look!\" written on its side. It’s parked on the street, where a woman stands smiling at the camera. Behind the bus, a row of classic buildings with large windows lines the street, contributing to the urban atmosphere. A black van is parked nearby, and there are a few people and street signs indicating traffic regulations. The overall scene captures a typical day in a historic city. ``` 这里从系统加载了一张图片，并且让它描述图中有什么，注意这个模型是**不支持上下文**的，也就是说每次调用`send`函数都是全新的对话，不会记住之前`send`的内容。 另外，默认模型支持`364 x 364`的图片输入分辨率，所以调用`set_image`时，如果分辨率不是这个分辨率，会自动调用`img.resize`方法进行缩放，缩放方法为`fit`指定的方法，比如`image.Fit.FIT_CONTAIN`就是当输入图片分辨率和期望的分辨率比例不一致时采用保持原比例缩放，周围空白填充黑色。 `set_system_prompt` 是系统提示语句，可以适当进行修改来提高你的应用场景的准确率。 注意发送的文字编码成 token 后的长度是有限制的，比如默认提供的 1B 模型 是 256 个 token，以及发送+回复最多 1023 个 token。 ### 修改参数 模型有一些参数可以修改，参考[Qwen 文档](./llm_qwen.html)。 ## 自定义量化模型 上面提供的模型是为 MaixCAM2 量化后的模型，如果需要自己量化模型，可以参考： * [pulsar2文档](https://pulsar2 docs.readthedocs.io/zh cn/latest/appendix/build_llm.html) * 原始模型： https://huggingface.co/OpenGVLab/InternVL2_5 1B * 更多文章： https://zhuanlan.zhihu.com/p/4118849355"},"/maixpy/doc/zh/comm/modbus.html":{"title":"MaixCAM MaixPy 使用 Modbus 协议","content":" title: MaixCAM MaixPy 使用 Modbus 协议 ## Modbus 简介 Modbus 是一个应用层总线协议，传输层基于 UART 或者 TCP。 使用它可以实现一个总线上挂多个设备，实现一对多通信。 ## Modbus 和 Maix 应用通信协议的区别 * **Maix 应用通信协议**： * **通信方式**：一对一通信。 * **通信模式**：全双工通信，双方都可以主动发送消息，实现更加实时的交互。 * **数据灵活性**：数据长度和类型没有限制，灵活支持多种数据结构。 * **MaixPy内置**： MaixCAM MaixPy 内置了这个协议，部分应用默认数据输出用这个协议，在 MaixPy 生态中使用相同的协议有利于应用生态繁荣。 * **应用场景**：适用于一对一实时性要求高、需要双向数据传输的场景，比如 AI 推理结果传输和控制命令反馈，以及 Maix 应用信息读取和控制。 * **Modbus**： * **通信方式**：总线协议，支持一对多通信。 * **通信模式**：只能由主机主动发起读写操作，从机的数据更新需要主机轮询获取，从机本质上可以看作具有多组寄存器的传感器。 * **数据类型**：数据以寄存器为单位，从机通过多个可读写或只读的寄存器实现数据交换。 * **应用场景**：适用于工业自动化中传感器或设备的数据采集与监控，尤其是在需要主从结构的情况下。 ## MaixCAM MaixPy 使用 Modbus MaixPy 适配了 modbus 协议, 主机和从机模式均支持，RTU（UART）和 TCP 模式均支持，底层使用了开源项目 [libmodbus](https://libmodbus.org/)， ## MaixCAM MaixPy 作为 Modbus 从机 作为从机时，可以将 MaixCAM 看作是一个有几组可读写寄存器的模块。 包含了几组寄存器，它们的区别就是值类型不同，以及有的能读写，有的只能读，寄存器组包括： * `coils`寄存器组： 布尔值，可读写。 * `discrete input`：布尔值，可读不可写。 * `input registers`：16bit int 值，可读不可写。 * `holding registers` 16bit int 值，可读可写. 每组寄存器的地址和长度在从机初始化时自由指定，根据你的应用需求设置即可。 以下是例程，更多代码请看源码例程(`examples/protocol/comm_modbus_xxx.py`): RTU（UART）： ```python from maix.comm import modbus from maix import app, err slave modbus.Slave( modbus.Mode.RTU, # modbus 模式选择为 rtu \"/dev/ttyS0\", # 选择与主机通信的串口 0x00, 10, # coils 开始地址以及该组寄存器数量 0x00, 10, # discrete input 开始地址以及该组寄存器数量 0x00, 10, # input registers 开始地址以及该组寄存器数量 0x00, 10, # holding registers 开始地址以及该组寄存器数量 115200, 1, # 115200波特率, 默认为 8N1, 后面的 1 代表 rtu 的从机地址 0, False # tcp 端口号, 我们使用的是 rtu, 随便填写即可, 后者为 是否打印 debug 信息 ) \"\"\" 以 coils 寄存器组为例, 起始地址为 0x00, 数量为 10, 代表该从机 coils 寄存器组的地址范围为 0x00~0x09 共 10 个寄存器, 每个寄存器存储一个布尔值. \"\"\" # 读取当前 input registers 寄存器组里的所有值 # 寄存器内初始值均为 0 old_ir slave.input_registers() print(\"old ir: \", old_ir) # 将列表内的值从引索2开始更新到 input registers 中 # 寄存器组内数值将变成 [0x00 0x00 0x22 0x33 0x44 0x00 0x00 0x00 0x00 0x00] data : list[int] [0x22, 0x33, 0x44] slave.input_registers(data, 2) # 读取, 打印验证 new_ir slave.input_registers() print(\"new ir:\", new_ir) while not app.need_exit(): # 等待主机的读写操作 if err.Err.ERR_NONE ! slave.receive(2000): #timeout 2000ms continue # 获取主机的操作类型 rtype slave.request_type() # 如果主机想要读取 holding registers if rtype modbus.RequestType.READ_HOLDING_REGISTERS: # 准备数据 # 获取并查看当前 holding registers 内数据 print(\"master read hr\") hr slave.holding_registers() print(\"now hr: \", hr) # 更新 holding registers 内所有数据 hr [x+1 for x in hr] print(\"now we make hr+1: \", hr) print(\"update hr\") slave.holding_registers(hr) # else ... 处理其他操作 # 自动处理主机请求, 自动更新寄存器值 slave.reply() ``` TCP： ```python from maix.comm import modbus from maix import app, err slave modbus.Slave( modbus.Mode.TCP, # 模式: TCP \"\", # 保持空即可 0x00, 10, 0x00, 10, 0x00, 10, 0x00, 10, 0, 1, # 我们使用的是 TCP 模式, 忽略波特率和rtu地址即可 502, False # TCP 端口号, 后者为 是否打印 debug 信息 ) ### 以下代码与 RTU 部分一致 old_ir slave.input_registers() print(\"old ir: \", old_ir) data : list[int] [0x22, 0x33, 0x44] slave.input_registers(data, 3) new_ir slave.input_registers() print(\"new ir:\", new_ir) while not app.need_exit(): if err.Err.ERR_NONE ! slave.receive(2000): #timeout 2000ms continue rtype slave.request_type() if rtype modbus.RequestType.READ_HOLDING_REGISTERS: print(\"master read hr\") hr slave.holding_registers() print(\"now hr: \", hr) hr [x+1 for x in hr] print(\"now we make hr+1: \", hr) print(\"update hr\") slave.holding_registers(hr) slave.reply() ``` 可以看到这里接收到来自主机的读取请求后调用`slave.reply()`就会自动回复主机要读取的数据了，以及这里展示了更改本身的寄存器值。 有关 Modbus API 的详细说明请看 [Modbus API 文档](../../../api/maix/comm/modbus.html). ## MaixCAM MaixPy 作为 Modbus 主机 主机则可以主动读写从机的数据，例程(以源码例程`examples/protocol/comm_modbus_xxx.py`为准)： ```python from maix import pinmap, app, err, time, thread from maix.comm import modbus REGISTERS_START_ADDRESS 0x00 REGISTERS_NUMBER 10 RTU_SLAVE_ID 1 RTU_BAUDRATE 115200 def master_thread(*args): if pinmap.set_pin_function(\"A19\", \"UART1_TX\") ! err.Err.ERR_NONE: print(\"init uart1 failed!\") exit( 1) if pinmap.set_pin_function(\"A18\", \"UART1_RX\") ! err.Err.ERR_NONE: print(\"init uart1 failed!\") exit( 1) # modbus.set_master_debug(True) master modbus.MasterRTU( \"/dev/ttyS1\", RTU_BAUDRATE ) while not app.need_exit(): hr master.read_holding_registers( RTU_SLAVE_ID, REGISTERS_START_ADDRESS, REGISTERS_NUMBER, 2000 ) if len(hr) 0: continue print(\"Master read hr: \", hr) time.sleep(1) master_thread(None) ``` 可以看到这里用 串口1 作为主机从从机读取寄存器值。"},"/maixpy/doc/zh/comm/maix_protocol.html":{"title":"MaixCAM MaixPy Maix 应用通信协议","content":" title: MaixCAM MaixPy Maix 应用通信协议 ## 通信协议简介 为了让两个设备能够实现稳定通信，简单地说，一般从底往上有几个层次： * 硬件层：比如 `UART` 使用 `TX` `RX` `GND` 三根线，也有可能是无线的，比如 WiFi。 * 传输层：使用传输控制协议来实现数据的稳定传输，比如 `UART` 协议规定了波特率、停止位、校验位来保证数据正确传输，比如 `TCP` 协议也类似。 * 应用层：从传输层获得的数据是流式数据（简单理解成一长串没有标点符号的数据），为了让应用理解哪些数据是什么含义，一般应用会自己定义一份应用层通信协议来规范传输的内容（简单理解成给传输的数据中间加标点符号方便接收方知道断句）。 举个例子： 应用层协议规定：一包数据以 `$`开头 A 发送两包数据给 B: `$12345$67890`，B收到后就知道 A 发送了两包数据，分别是`12345`和`67890`，如果没有这个协议，那 A 发送`12345` 然后发送 `67890`， 由于是流式传输 B 收到的数据可能是`1234567890`， 我们就不知道是发了一次还是发了两次了。 ## 字符协议和二进制协议 **字符协议**： 前面举了简单的例子给没一包加`$`符号来区别每一包的开头，如果想发送数值`123`，直接发送`$123`字符串，即人类都可以直接看懂的，接收方需要将`123`字符串转换为 `int` 类型，比如 C 语言中可以 ```c int value; sscanf(buff, \"$%d\", &value); ``` **二进制协议**： 可以看到字符协议为了发送`123`这个数值，用了`4`个字节，而且接收方还要做解析将字符串转为 int 类型，用二进制协议则可以减少传输的字节数量而且接收方也更好处理。 我们发送`0x24 0x7B` 即可， `0x24` 即 `$` 的十六进制表示（查 ASCII 码表）， `0x7B` 即 十进制`123`的十六进制表示，可以看到这里只发送了两个字节就完成了字符协议 4 个字节完成的工作，同时接收放直接读取第二个字节`0x7B` 就能使用这个值，比如 C 语言中直接`uint8_t value buff[1]`; 当然这里只是简单说明让你理解两者，实际还需要根据不同使用场景两者各有优势，以及还会加其它考虑比如校验值等，这里就不多说了，可以自行思考和学习以及在下面的 Maix 通信协议实践。 ## Maix 应用通信协议 Maix 应用通信协议是一个应用层通信协议，传输层基于 UART 或者 TCP。 包括了：规定通信双方的以什么样的格式来传输内容，方便双方解析识别信息，是一个二进制协议，包括帧头、数据内容、校验等。 完整的协议定义在 [Maix 应用通信协议标准](https://wiki.sipeed.com/maixcdk/doc/zh/convention/protocol.html)。 （写到 MaixCDK 文档中是因为 MaixCDK 也同样使用这份协议） 没有接触过通信协议可能看起来有点困难，结合下面的例子多看几遍就能理解了。 在 `MaixPy` 这边已经封装好了`API`，可以很简单地使用，在其它单片机或者芯片上可能需要实现一下协议，可以在[Maix 应用通信协议标准](https://wiki.sipeed.com/maixcdk/doc/zh/convention/protocol.html) 附录找找有没有对应的实现。 比如我们现在有一个物体检测，我们想检测到物体后通过串口发送给其它设备（比如 STM32 单片机或者 Arduino 单片机），告诉其我们检测到了什么物体，坐标是多少。 完整的例程：[MaixPy/examples/protocol/comm_protocol_yolov5.py](https://github.com/sipeed/MaixPy/tree/main/examples/protocol/comm_protocol_yolov5.py) 首先我们需要检测到物体，参考 `yolov5` 检测物体的例程即可，这里我们就省略其它细节，来看检测到的结果是什么样 ```python while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.5, iou_th 0.45) for obj in objs: img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) msg f'{detector.labels[obj.class_id]}: {obj.score:.2f}' img.draw_string(obj.x, obj.y, msg, color image.COLOR_RED) disp.show(img) ``` 可以看到`objs`是多个检测结果，这里在屏幕上进行画框了，我们也可以在这里想办法把结果通过串口发送出去。 这里我们不需要手动初始化串口，直接使用内置的`maix.comm, maix.protocol`模块，调用`comm.CommProtoco`会自动初始化串口，默认波特率是`115200`，串口协议的相关可以在设备`系统设置 >通信协议`里面设置。 系统设置里面可能还有其它通信方式比如`tcp`，默认是`uart`，你也可以通过`maix.app.get_sys_config_kv(\"comm\", \"method\")`来获取到当前设置的是不是`uart`。 ```python from maix import comm, protocol, app from maix.err import Err import struct def encode_objs(objs): ''' encode objs info to bytes body for protocol 2B x(LE) + 2B y(LE) + 2B w(LE) + 2B h(LE) + 2B idx ... ''' body b\"\" for obj in objs: body + struct.pack(\"<hhHHH\", obj.x, obj.y, obj.w, obj.h, obj.class_id) return body APP_CMD_ECHO 0x01 # 自定义命令 1, 测试用，这里没用到，保留 APP_CMD_DETECT_RES 0x02 # 自定义命令 2, 发送检测到的物体信息 # 可以根据自己的应用自定义更多的命令 p comm.CommProtocol(buff_size 1024) while not app.need_exit(): # ... objs detector.detect(img, conf_th 0.5, iou_th 0.45) if len(objs) > 0: body encode_objs(objs) p.report(APP_CMD_DETECT_RES, body) # ... ``` 这里通过`encode_objs`函数将所有检测到的物体信息打包成`bytes`类型的数据，然后用`p.report`函数将结果发送出去。 这里我们对`body`内容进行了一个简单的定义，即`2B x(LE) + 2B y(LE) + 2B w(LE) + 2B h(LE) + 2B idx ...`， 含义是： * 这张图中检测到多个物体，在`body`中按顺序排列，每个目标占用 `2+2+2+2+2 10` 个字节的长度，一共有`body_len / 10`个物体。 * 第1、2个字节代表识别到的物体的左上角的 `x` 坐标，单位是像素，因为 yolov5 的结果这个坐标值有可能为负数，所以我们用一个`short`类型的值来表示，这里使用了小端编码（LE）。 > 这里小端即数值的低字节在前，比如坐标 `x` 为 `100`, 十六进制为 `0x64`，我们用两个字节的`short`来表示就是`0x0064`，这里小端编码成 `bytes` 就是`0x64`在前， 结果就是`b'\\x64\\x00'`。 * 同理，将后面的数据都依次编码，一个物体得到一个`10`字节长的`bytes`类型数据。 * 循环将所有物体信息编码并拼接成一个`bytes`。 在调用`report`函数时，底层会自动按照协议拼接上协议头、校验和等等，这是在另一端就能收到一帧完整的数据了。 在另一端收到信息后也要按照协议进行解码，如果接收端也是用 MaixPy 可以直接： ```python while not app.need_exit(): msg p.get_msg() if msg and msg.is_report and msg.cmd APP_CMD_DETECT_RES: print(\"receive objs:\", decode_objs(msg.get_body())) p.resp_ok(msg.cmd, b'1') ``` 如果是其它设备比如`STM32`或者`Arduino`则可以参考 [Maix 应用通信协议标准](https://wiki.sipeed.com/maixcdk/doc/zh/convention/protocol.html) 附录中的 C 语言函数进行编解码。"},"/maixpy/doc/zh/basic/auto_start.html":{"title":"MaixCAM MaixPy 应用开机自启","content":" title: MaixCAM MaixPy 应用开机自启 打包安装好的应用可以设置开机自动启动，这样开机就不会显示应用菜单，直接进入指定的应用。 ## 设置应用开机自启方法一 先打包安装好应用，然后在设备`设置 > 开机自启` 设置中选择需要自动启动的应用即可，取消开机自启也是在这里设置。 ## 设置应用开机自启方法二 运行 Python 脚本设置，修改脚本中的`new_autostart_app_id` 变量为你想设置的 `app_id`， 所有已经安装了的`app_id`会在执行脚本时打印出来，可以先执行一遍找到你想设置的`app_id`，修改变量再执行一遍即可，取消自动启动设置为`None`即可。 此脚本也可以在`MaixPy`的`examples/tools`中找到`set_autostart.py`： ```python import configparser, os def parse_apps_info(): info_path \"/maixapp/apps/app.info\" conf configparser.ConfigParser() conf.read(info_path) version conf[\"basic\"][\"version\"] apps {} for id in list(conf.keys()): if id in [\"basic\", \"DEFAULT\"]: continue apps[id] conf[id] return apps def list_apps(): apps parse_apps_info() print(f\"APP num: {len(apps)}\") for i, (id, info) in enumerate(apps.items()): name_zh info.get(\"name[zh]\", \"\") print(f\"{i + 1}. [{info['name']}] {name_zh}:\") print(f\" id: {id}\") print(f\" exec: {info['exec']}\") print(f\" author: {info['author']}\") print(f\" desc: {info['desc']}\") print(f\" desc_zh: {info.get('desc', 'None')}\") print(\"\") def get_curr_autostart_app(): path \"/maixapp/auto_start.txt\" if os.path.exists(path): with open(path, \"r\") as f: app_id f.readline().strip() return app_id return None def set_autostart_app(app_id): path \"/maixapp/auto_start.txt\" if not app_id: if os.path.exists(path): os.remove(path) return with open(path, \"w\") as f: f.write(app_id) if __name__ \"__main__\": # new_autostart_app_id \"settings\" # change to app_id you want to set new_autostart_app_id None # remove autostart list_apps() print(\"Before set autostart appid:\", get_curr_autostart_app()) set_autostart_app(new_autostart_app_id) print(\"Current autostart appid:\", get_curr_autostart_app()) ``` ## 设置应用开机自启方法三 你也可以通过修改设备中的 `/maixapp/auto_start.txt` 文件来设置，和传输文件的方法请看前面的文档。 * 首先知道你需要设置的应用的 `id` 是什么。在你打包应用的时候设置的；如果不是你自己打包的应用，可以先安装到设备，查看设备`/maixapp/apps/` 目录下的文件夹名就是应用名，（也可以下载查看设备的`/maixapp/apps/app.info` 文件，`[]`中括号部分就是应用`id`）。 * 然后写入 `id` 到 `/maixapp/auto_start.txt` 文件即可。（可以在电脑本地创建文件，然后 `MaixVision` 传输到设备。） * 如果要取消，删除设备上的 `/maixapp/auto_start.txt` 文件即可。 ## 其它方法 因为 MaixCAM 底层是 Linux， 如果你熟悉 Linux，还可以直接编辑系统启动脚本： * 对于 MaixCAM/MaixCAM Pro, 编辑`/etc/rc.local` 或者 `/etc/init.d` 下的启动脚本。 * 对于 MaixCAM2，基于 systemd 的启动管理方式，在`/etc/systemd/system`下面添加启动项，然后`systemctl enable xxxx.service`即可使能开机启动，可以参考`launcher.service`即开机起动器程序。 但是需要注意的是，这种方式会让 MaixVision 在连接的时候无法停止这个应用，从而造成资源占用（比如屏幕和摄像头） MaixVision 可能无法正常跑程序，而前两种方法 MaixVision 连接设备时是可以正常让程序退出以供 MaixVsion 跑程序的。 所以这种方法比较适合开机跑一些不会占用屏幕和摄像头等资源的后台进程，一般情况下如果你不熟悉 Linux 不建议这样操作，不然很容易导致屏幕和摄像头资源互相占用出问题。"},"/maixpy/doc/zh/basic/maixvision.html":{"title":"MaixVision -- MaixCAM MaixPy 编程 IDE + 图形化积木编程","content":" title: MaixVision MaixCAM MaixPy 编程 IDE + 图形化积木编程 ## 简介 [MaixVision](https://wiki.sipeed.com/maixvision) 是专为 Maix 生态打造的一款开发者编程工具，支持 MaixPy 编程和图形化积木编程，同时支持在线运行和调试，以及实时预览图像，可以同步设备显示屏的图像，方便调试和开发。 以及支持打包应用和安装应用到设备，方便用户一键生成、安装应用。 同时还集成一些方便开发的小工具，比如文件管理，阈值编辑器，二维码生成等等。 ## 下载 访问 [MaixVision 主页](https://wiki.sipeed.com/maixvision) 下载。 ## 使用 MaixPy 编程和在线运行 按照[快速开始](../index.html)的步骤连接设备，我们可以很方便地使用 MaixPy 编程和在线运行。 ## 实时预览图像 MaixPy 提供`display`模块，可以将图像显示到屏幕上，同时，在调用`display`模块的`show`方法时，会将图像发送到 MaixVision 显示，比如代码： ```python from maix import display, camera cam camera.Camera(640, 480) disp display.Display() while 1: disp.show(cam.read()) ``` 这里我们用摄像头读取了图像，然后通过`disp.show()`方法将图像显示到屏幕上，同时也会发送到 MaixVision 显示。 当我们点击了右上角的`暂停`按钮，就会停止发送图像到 MaixVision 显示。 ## 代码自动补全 代码提示依赖电脑本地的 Python 包，为了实现代码提示，我们需要在电脑中安装 Python，并且安装需要提示的 Python 包。 > 不安装则会显示红色下划波浪线错误提示，代码仍然能在设备正常运行，只是编辑器没有代码补全提示。 * 安装 Python 请访问 [Python 官网](https://python.org/)安装。 * 安装需要提示的包，比如对于 MaixPy， 你需要在电脑也安装一份 MaixPy 包，在电脑使用`pip install MaixPy`即可安装好，如果`MaixPy`更新了，你也需要在电脑和设备更新到`MaixPy`，电脑手动在终端执行`pip install MaixPy U`即可，设备更新直接在`设置`应用中更新即可。 > 中国国内用户可以使用国内镜像`pip install i https://pypi.tuna.tsinghua.edu.cn/simple MaixPy`。 * 重启 MaixVision 就能够看到代码提示了。 > 如果仍然不能提示，可以手动在设置中设置 python 可执行文件的路径后重启。 >! 注意在电脑安装 Python 包这里只是为了用作代码提示，实际代码运行还是在设备（开发板）上，设备上也要有对应的包才能正常运行。 > 另外，虽然你在电脑上安装了 MaixPy 包，但是由于我们精力有限，我们不确保你能直接在电脑的 Python 导入 maix 包进行使用，请在支持的设备上运行。 另外，除了 MaixPy 软件包，其它的代码提示，比如 `numpy/opencv` 都同样的需要在电脑也安装一份来实现代码提示。 ## 运行单文件 在编写代码时，一般两种模式，执行单个文件，或者执行一个完成项目（包含多个 py 文件或者其它资源文件比如图片/模型等）。 对于简单的代码，我们**一个文件就能包含所有代码**，直接创建或者打开一个 `.py`格式的文件，编辑后点击左下角运行即可执行代码。 ## 创建项目（多个 py 文件项目/模块化） 对于稍微复杂一点的程序，比如代码多了，需要模块化，或者需要在应用里包含一些资源文件比如图片/模型等，就需要建立项目了。 * 在系统文件管理器创建一个空文件夹，MaixVision 点击`打开文件夹/项目`打开这个空文件夹。或者直接点击新建项目（如果新版本有这个功能）。 * 创建一个`main.py`的主程序入口（名字必须是`main.py`），如果`main.py`想引用其它`.py`文件，在项目文件夹下建立一个`.py`文件比如`a.py` ```python def say_hello(): print(\"hello from module a\") ``` * 在 `main.py` 中引用 ```python from a import say_hello say_hello() ``` * 运行项目，点击左下角`运行项目`按钮将整个项目文件夹所有文件自动打包发送到设备中运行。 * 如果你打开了一个文件夹/项目，仍想单独运行某个文件，可以打开想要运行的文件，然后点击左下角`运行当前文件`只发送当前文件到设备运行，注意不会发送其它文件到设备，所以不要引用其它`.py`文件。 ## 计算图像的直方图 在上一步中我们可以在 MaixVision 中实时看到图像，我们用鼠标框选一个区域，图像下方就能看到这个区域的直方图了，选择不同的颜色表示方法，可以看到不同的颜色通道的直方图。 这个功能方便我们在做某些图像处理算法时找到一些合适的参数。 ## 区分`设备文件系统`和`电脑文件系统` 这里我们有一个比较重要的概念需要掌握：**分清楚`设备文件系统`和`电脑文件系统`**。 * **电脑文件系统**：运行在电脑上，在 MaixVision 中打开文件或者工程都是打开的电脑里面的文件（比如 C 盘 D 盘等），保存也是自动保存到电脑的文件系统。 * **设备文件系统**：程序运行时会将程序发送到设备上运行，所以代码里面读取的文件都是从设备文件系统读取。 所以常见的问题是有同学在电脑上保存了文件`D:\\data\\a.jpg`，然后在设备上使用这个文件`img image.load(\"D:\\data\\a.jpg\")`，这样当然是找不到文件的，因为设备上没有`D:\\data\\a.jpg`这个文件。 正确的方法是： * 用`MaixVision`的文件管理器将这个文件从电脑上传到设备的`/root/`目录下。参考后文。 * 代码加载设备文件系统内的文件`img image.load(\"/root/a.jpg\")`。 ## 传输文件到设备 先连接设备，然后点击浏览设备文件系统的按钮，有两个入口，如下图，然后就能上传文件到设备，或者从设备下载文件到电脑了。 ![maixvision_browser2](../../assets/maixvision_browser2.jpg) ![maixvision_browser](../../assets/maixvision_browser.jpg) .. details::也可以用其它工具代替，点击展开 先知道设备的 ip 地址或者设备名称，MaixVision 就可以搜索到, 或者在设备`设置 >系统信息`中看到，比如类似 `maixcam xxxx.local` 或者 `192.168.0.123`。 用户名和密码都是 `root`, 使用 `SFTP` 协议传输文件，端口号是 `22`。 然后不同系统下都有很多好用的软件： ### Windows 下 使用 [WinSCP](https://winscp.net/eng/index.php) 或者 [FileZilla](https://filezilla project.org/) 等工具连接设备，将文件传输到设备上，选择 `SFTP` 协议填写设备和账号信息连接即可。 具体不懂的可以自行搜索。 ### Linux 下 终端使用 `scp` 命令传输文件到设备上，比如： ```bash scp /path/to/your/file.py root@maixcam xxxx.local:/root ``` ### Mac 下 * **方法一**：终端使用 `scp` 命令传输文件到设备上，比如： ```bash scp /path/to/your/file.py root@maixcam xxxx.local:/root ``` * **方法二**：使用 [FileZilla](https://filezilla project.org/) 等工具连接设备，将文件传输到设备上，选择 `SFTP` 协议填写设备和账号信息连接即可。 ## 打包应用和安装应用到设备 使用 MaixPy + MaixVison 可以方便地开发、打包、安装应用，方便离线运行： * 在 MaixVision 中使用 MaixPy 开发应用程序，可以是单个文件，也可以是一个工程目录。 * 连接设备。 * 点点击 MaixVision 左下角的 安装 按钮，会弹出一个界面填写应用的基本信息，id 是用来判别应用的 id，一个设备不能同时安装相同 id 的不同应用，所以 id 应该与 MaixHub 上面已经有的应用 id 不同，应用名字可以重复。以及图标等。 * 点击打包应用，会将应用打包成一个安装包，如果你要上传到 [MaixHub 应用商店](https://maixhub./com/app)，用这个打包好的文件即可。 * 点击 安装应用，这会将打包好的应用安装到设备。 * 断开与设备的连接，就能看到设备功能选择界面多了一个你的应用，直接点进去就能运行。 > 如果你用 MaixCDK 开发，使用 `maixcdk relrease` 就能打包出来一个应用，具体看 MaixCDK 的文档。 ## 终端使用 MaixVision 支持直接操作设备的终端，点击右侧`设备终端`按钮即可打开。 当然你也可以使用第三方的 shell 工具，比如系统自带的终端使用`ssh`工具连接。 ## 使用图形化积木编程 开发中，敬请期待。"},"/maixpy/doc/zh/basic/python_pkgs.html":{"title":"MaixCAM MaixPy 添加额外的 Python 软件包","content":" title: MaixCAM MaixPy 添加额外的 Python 软件包 ## 简介 MaixPy 基于 Python 语言，提供了大量方便嵌入式应用开发的功能和 API，除此之外，你也可以使用其它的 Python 包来扩展功能。 ## 安装额外的 Python 包 > 注意由于 MaixCAM 是 RISC V 而且定制工具链， 可能不是所有 Python 包都支持，一般只支持纯 Python 包，不支持 C 扩展包， C 扩展包可能需要你手动在电脑交叉编译（比较复杂，这里就不介绍了）。 > 对于 MaixCAM2，是 AARCH64, 而且内置了 GCC，所以可以认为能安装所有包。 ### 方法一： 使用 Python 代码来安装 在 MaixVision 中使用 Python 代码来安装你需要的包，比如： ```python import os os.system(\"pip install 包名\") ``` 要更新一个包，可以使用： ```python import os os.system(\"pip install upgrade 包名\") ``` ### 方法二： 终端使用 pip 命令安装 使用[Linux 基础](./linux_basic.html)中介绍的终端使用方法，使用 `pip install 包名` 安装你需要的包。 ## pip换源 在使用 pip 下载 Python 软件包时，默认会从 [PyPI](https://pypi.org/) 下载。PyPI 是 Python 官方的软件包储存库，对于中国用户来说下载速度会很慢。 中国国内有许多 PyPI 的镜像源，从镜像源下载可以提升下载速度。 在终端中输入以下命令，可以从清华源更新 pip ： ``` python m pip install i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple upgrade pip ``` 用以下命令将下载源设为清华源： ``` pip config set global.index url https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple ``` 恢复默认源： ``` pip config unset global.index url ``` 参考：[清华大学开源软件镜像站 PyPI软件仓库](https://mirrors.tuna.tsinghua.edu.cn/help/pypi/)。 你也可以自己寻找其他好用的镜像源。 ## pip 无法直接安装的包 主要是 MaixCAM/MaixCAM Pro 会有这个问题，MaixCAM2 一般不存在这个问题。 设备内 pip 能安装纯 Python 编写的程序，对于底层使用了其它语言比如 C++ 编写的库由于 MaixCAM RISC V 的特殊性，一般没有直接可以用的编译好的包。 解决方法： * 方法一： 找到对应的包源码，在电脑上交叉编译成 whl 安装包，然后复制到设备里面使用`pip install xxxx.whl`安装。编译的工具链和[MaixCDK 使用的工具链相同](https://github.com/sipeed/MaixCDK/blob/main/platforms/maixcam.yaml)。 * 方法二： 根据[编译系统](../pro/compile_os.html)中描述编译系统，编译前可以到`buildroot`目录下执行`make menuconfig`找找 Python 解释器 额外包中有没有你想要的软件包，勾选上再编译就能将改包编译进系统镜像。 > 如果你通过方法二成功编译测试过了某个包并且觉得它十分有必要集成到系统中，欢迎通过[issues](https://github.com/sipeed/maixpy/issues) 提意见。"},"/maixpy/doc/zh/basic/os.html":{"title":"MaixCAM MaixPy 升级和烧录系统","content":" title: MaixCAM MaixPy 升级和烧录系统 layout: redirect redirect_url: ./upgrade.html "},"/maixpy/doc/zh/basic/view_src_code.html":{"title":"MaixCAM MaixPy 如何找到 MaixPy API 对应的源码","content":" title: MaixCAM MaixPy 如何找到 MaixPy API 对应的源码 ## 简介 MaixPy 是基于 Python 实现，有部分函数是用 Python 编写，大多数底层代码都是使用 C/C++ 编写，这样可以保证运行效率。 如果我们在使用一个函数遇到疑问，我们可以查询本文档，以及 API 文档。 如果仍然不能解决你的疑惑，那么可以直接按照本文的方法找到底层实现的源码找出答案，**也欢迎一起贡献文档或代码，成为 MaixPy 开发者的一员**！ ## 先看文档 一定要先看文档： [https://wiki.sipeed.com/maixpy/](https://wiki.sipeed.com/maixpy/), 然后看 API 文档：[https://wiki.sipeed.com/maixpy/api/index.html](https://wiki.sipeed.com/maixpy/api/index.html) API 文档只有英文，原因是 API 文档是从代码的注释生成而来，代码中一律使用英文，看不懂英文可以使用翻译。 ## 如何找到 API 对应的源码 首先有两个开源仓库，分别是 [MaixPy](https://github.com/sipeed/MaixPy) 和 [MaixCDK](https://github.com/sipeed/MaixCDK)。 MaixPy 是工程仓库，里面包含了 MaixPy 的部分源码，所有文档、例程；MaixCDK 包含了大多数 MaixPy API 的底层 C/C++ 实现。 我们可以把这两份代码下载下来，也可以直接在网页查看。 **顺便记得给它们点一个 star 让更多人看到哦～** ### 找到 C/C++ 编写的 API 现在假设我们要找到 `maix.image.Image.find_blobs` 函数为例， 首先我们尝试手动去找： * 因为这是属于视觉相关的 API， 我们在 [MaixCDK](https://github.com/sipeed/MaixCDK) 的`components/vision/include` 下面可以看到有一个 `maix_image.hpp`的头文件，猜测大概在这里面。 * 在`maix_image.hpp` 搜索 `find_blobs`，马上就发现了函数声明： ```c++ std::vector<image::Blob> find_blobs(std::vector<std::vector<int>> thresholds std::vector<std::vector<int>>(), bool invert false, std::vector<int> roi std::vector<int>(), int x_stride 2, int y_stride 1, int area_threshold 10, int pixels_threshold 10, bool merge false, int margin 0, int x_hist_bins_max 0, int y_hist_bins_max 0); ``` * 同时我们发现函数声明前面有注释，API 文档即从这份注释自动生成而来，如果你仔细对比 API 文档和这个注释会发现他们一模一样的，改动这个注释编译后会产生 API 文档。 * 这只是函数声明，我们找到`components/vision/src/maix_image.cpp`，发现里面没有这个函数，仔细一看有个`components/vision/src/maix_image_find_blobs.cpp`，原来是将函数单独写了一个`cpp`，在里面我们就能看到函数的源代码了。 ### 找到使用 Pybind11 编写的 API 如果 MaixCDK 里面找不到，那就可以到 [MaixPy/components](https://github.com/sipeed/MaixPy/tree/main/components)里面寻找。 > 上面的代码你会发现，我们在使用`find_blobs`时第一个参数是`[[...]]`这样的参数即`list`类型，C/C++ 定义第一个参数是`std::vector<std::vector<int>>`类型，原因是我们使用了`pybind11`自动将 `std::vector` 类型转换为了`list`类型。 而有一些类型在`MaixCDK`里面不方便定义，比如`numpy`的`array`类型，但是`pybind11`里面有相关的定义方便我们直接使用，但是又不想 MaixCDK 里面有 pybind11 相关的代码，所以我们在[MaixPy/components](https://github.com/sipeed/MaixPy/tree/main/components) 里面来写使用了 `pybind11` 相关的代码，比如`maix.image.image2cv`方法。 ## 如何修改代码 在找到代码后，直接修改，然后按照[编译文档](../source_code/build.html)编译出固件即可。 ## 如何增加代码 照抄其它 API，写一个函数，然后添加完整的注释，注释中额外添加一个`@maixpy maix.xxx.xxx`，这里`xxx`即你想添加到的模块和`API`名，然后编译出固件即可。 可以参考[MaixCDK/components/basic/includemaix_api_example.hpp](https://github.com/sipeed/MaixCDK/blob/master/components/basic/include/maix_api_example.hpp)。 API 参数和返回值用基础的`C++` 类型会自动转换为`Python`的类型，是不是十分简单. 具体的类型转换参考[pybind11 类型自动转换列表](https://pybind11.readthedocs.io/en/stable/advanced/cast/overview.html#conversion table) 比如我们希望增加一个`maix.my_module.my_func`，在`MaixCDK`中合适的地方（最好符合现在的文件夹分类）创建一个头文件，然后添加代码： ```cpp namespace maix::my_module { /** * My function, add two integer. * @param a arg a, int type * @param b arg b, int type * @return int type, will a + b * @maixpy maix.my_module.my_func */ int my_func(int a, int b); } ``` 然后增加一个`cpp`文件： ```cpp int my_func(int a, int b) { return a + b; } ``` 然后编译 MaixPy 生成`whl`文件，安装到设备即可使用`maix.my_module.my_func`函数。 ## 如何贡献代码 如果你发现 MaixPy 有未完成的 API， 或者有 bug， 欢迎修改后提交 PR（Pull Request）到 MaixPy 仓库，具体提交方法看 [贡献文档和代码](../source_code/contribute.html)"},"/maixpy/doc/zh/basic/python.html":{"title":"Python 基础知识","content":" title: Python 基础知识 MaixPy 的教程文档里面就不涉及具体的 Python 语法教程了，因为 Python 的教程实在是太多了，都做得很好，这里只介绍需要学什么，方向和线路指导即可。 ## Python 简介 Python 是一门解释性、面向对象、动态类型的高级编程语言。 * 解释性：不需要编译，直接运行，优点是开发快速，缺点是因为每次运行都要解释一遍代码，运行速度慢一点点，但是往往瓶颈还是开发者写的代码而不是语言本身。 * 面向对象：支持面向对象编程，可以定义类和对象，相比面向过程语言，更容易组织代码。更多自行搜索。 * 动态类型：变量不需要声明类型，可以直接赋值，类型会根据赋值自动确定，这样可以减少代码量，但是也容易出现类型错误，需要开发者自己注意。 总之，对于没有接触过 Python 的开发者来说，Python 非常容易上手，有大量现成的库，开发者群体巨大，开发应用周期短，非常值得学习！ ## Python 环境安装 你可以按照你学习的 Python 教程在电脑上安装 Python； 也可以在 MaixVisioin 上连接设备后使用 MaixVision 编程然后在开发板运行。 ## 使用 MaixPy 需要的 Python 基础有哪些？ * Python 的基本概念。 * 面向对象编程的基本概念。 * Python 的基本语法，包括： * tab 缩进对齐语法 * 变量、函数、类、对象、注释等 * 控制语句比如 if、for、while 等等 * 模块和导入模块 * 基本数据类型比如 int、float、str、list、dict、tuple 等等 * bytes 和 str 的区别和转换 * 异常处理，try except * 常用的内置函数，比如 print、open、len、range 等等 * 常用的内置模块，比如 os、sys、time、random、math 等等 掌握以上的基础知识就可以顺畅使用 MaixPy 编程了，配合后面的教程和例程，在不懂的时候查询搜索引擎或者官方文档，或者问 ChatGPT 就能顺利完成开发。 ## 对于已经有一门面向对象编程语言经验的开发者 如果你已经会一门面向对象语言比如 C++/Java/C# 等等，那只需要快速浏览一下 Python 的语法，就可以开始使用了。 比如 [菜鸟教程](https://www.runoob.com/python3/python3 tutorial.html) 或者 [Python 官方教程](https://docs.python.org/3/tutorial/index.html)。 或者个人开发者的博客，比如 [哇！是 Python](https://neucrack.com/p/59)。 ## 对于没有面向对象编程经验但是有 C 语言经验的开发者 如果只学了 C，缺乏对面向对象的理解，那么可以先学习一下面向对象的概念，然后再学习 Python，也是比较快的，可以自行搜索视频教程入门。 跟着视频教程入门之后可以看看文档教程，比如 [菜鸟教程](https://www.runoob.com/python3/python3 tutorial.html) 或者 [Python 官方教程](https://docs.python.org/3/tutorial/index.html) 就可以开动了！ 在学了入门知识后，就可以按照 MaixPy 的文档和例程开始使用 MaixPy 编程了。 ## 对于编程新手 如果你从未接触过编程，那么你需要重头开始学习 Python，Python 作为入门语言也是比较合适的，具体可以搜一搜视频教程。 在学会了基础语法后，就能按照例程使用 MaixPy 编程了。 ## 使用内置的软件包 Python 已经内置了很多常用的软件包和 API，所以遇到什么问题可以搜索`“Python 使用 xxxx\"`说不定就能直接能用。 比如常见的 文件、多线程、多进程、网络、系统、算法等等。 举个例子： 对于没有接触过 Python， 只涉略过初级的单片机开发的同学来说，可能会有些疑问为什么文档没有读写 SD/TF 卡的例程： 因为默认就有文件系统跑在 SD/TF 卡上的，只要用 Python 的文件操作 API 就能读写 SD 卡中的文件： ```python with open(\"/root/a.txt\", \"r\") as f: content f.read() print(content) ```"},"/maixpy/doc/zh/basic/linux_basic.html":{"title":"Linux 基础知识","content":" title: Linux 基础知识 update: date: 2024 03 19 author: neucrack version: 1.0.0 content: 填加文档 date: 2024 10 26 author: YWJ version: 2.0.0 content: 增加常用命令文档 ## 简介 本章内容对于刚入门的同学来说，可以先跳过此章节，在学会 MaixPy 基础开发后再来学习也是可以的。 最新的 MaixPy 支持的 MaixCAM 硬件支持跑 Linux 系统，所以 MaixPy 底层都是基于 Linux 系统进行开发的。 虽然 Sipeed 开发的 MaixPy 已经为开发者们做了很多工作，即使不知道 Linux 系统知识也能愉快使用，但是以防在某些情况下需要一些底层操作，以及方便未接触过 Linux 的开发者学习，这里写一些 Linux 基础知识。 ## 为什么需要 Linux 系统 Linux 的介绍请大家自行查阅了解，这里用通俗的看起来不太专业的话语简单举几个例子方便初学者理解： * 在单片机中，我们的程序是一个死循环程序，用上 Linux 后我们可以同时跑很多程序，每个程序看起来都独立在同时运行，每个程序具体怎么执行的由操作系统实现。 * 基于 Linux 的开发者众多，需要功能和驱动可以很方便地找到，不需要自己再实现一遍。 * 基于 Linux 配套的软件工具丰富，可以很方便地进行开发和调试，比如在本教程没有提到的一些 Linux 通用工具理论上也是可以使用的。 ## Linux 系统大家族 Linux 是一个开源操作系统内核，提供了操作系统基本的内容，使用其本身并不能像 Windows 一样普通用户能开箱即用，所以开源社区基于 Linux 内核发展出了很多版本（发行版），比如 `Ubuntu` 应该是用户量最大的发行版，使用人数较多，资料多，入门建议选择，其它的还有 `Arch` `CentOS` 等等非常多，全部都是基于 Linux 内核，所以大家日常都称为 Linux。 这众多系统的不同就是 界面、用户交互体验、驱动、预装软件、软件管理器（包管理器）等等，新手可以选择`Ubuntu`再探索其它系统。 对于 MaixCAM，理论上也可以安装`Ubuntu`等系统，不过由于 MaixCAM 的内存只有 256MB，比较有限，而且 ubuntu 有很多臃肿的软件实际部署用不到， MaixCAM 使用了基于`Linux`内核+`buildroot`文件系统构建的系统，代码开源在[github.com/sipeed/LicheeRV Nano Build](https://github.com/sipeed/LicheeRV Nano Build)。有兴趣的可以搜索相关词汇了解。 ## 文件系统 什么是文件系统？ * 就像电脑的文件系统一样，Linux 上会将硬件磁盘用文件系统进行管理，这样我们可以很方便地向磁盘读写数据。 * 对于学过单片机没有接触过文件系统开发的同学来讲，可以理解为我们有一个 Flash 或者 TF 卡，我们可以通过 API 读写 Flash 存取数据，断电后也能保存数据，但是 Flash 具有读写寿命，我们往往需要写一套程序去保证 Flash 读写寿命，而文件系统就可以理解成这样一套成熟的程序，文件系统帮我们完成了具体如何管理 Flash 空间和读写，我们只需调用文件系统的 API 即可，大大减少了我们的开发工作量并且用成熟的程序保证了稳定性和安全性。 ## 在电脑和设备（开发板）之间传输文件 既然设备有 Linux 和文件系统，那我们怎么发送文件到设备呢？ 对于 MaixPy 我们配套了 MaixVision， 在后面的版本也会支持文件管理功能，在此之前可以用下面的方法： 这里我们主要介绍通过网络传输的方式，其它方式可自行探索`传输文件到 Linux`： * 确保设备和电脑连接到了同一个局域网，比如： * MaixCAM 的 USB 口连接到电脑会创建一个虚拟网卡，在电脑端的设备管理器就能看到，设备的 IP 可以在设备的`设置 >设备信息`中看到设备名和 IP。 * 也可以在设备`设置 >WiFi`中连接到和电脑相同的局域网。 * 电脑使用 SCP 或者 SFTP 协议传输文件到设备，具体的软件有很多，具体的软件和使用方法可以自行搜索，比如： * 在 Windows 上可以使用 WinSCP 或者 FileZilla，或者 scp 命令等。 * 在 Linux 上可以使用 FileZilla 或者 scp 命令 等。 * 在 Mac 上可以使用 FileZilla 或者 scp 命令 等。 ## 终端和命令行 终端就是通过`终端`这个软件与 Linux 系统进行通信和操作的工具，类似于 Windows 的`cmd`或者`PowerShell`。 比如我们可以在电脑的 Window 系统中的 powershell 或者 Linux系统中的 终端 工具中输入`ssh root@maixcam xxxx.local` 这里具体的名字在设备的`设置 >设备信息`中可以看到，这样我们就可以通过终端连接到设备了(用户名和密码都是`root`)。 然后我们通过输入命令来操作设备，比如`ls`命令可以列出设备文件系统中当前目录下的文件, `cd` 用来切换当前所在的目录（就像电脑文件管理中点击文件夹切换目录一样）， ```shell cd / # 切换到根目录 ls # 显示当前目录（根目录）下的所有文件 ``` 然后会显示类似下面的内容： ```shell bin lib media root tmp boot lib64 mnt run usr dev linuxrc opt sbin var etc lost+found proc sys ``` 更多命令学习请自行搜索`Linux 命令行使用教程`，这里只是为了让初学者知道基本概念，这样有开发者提到时可以知道是什么意思。 ## MaixCAM 执行 shell 终端命令 对于 `MaixCAM` 有几种方法可以和其系统`shell`进行交互： * 在电脑终端通过`ssh root@192.168.0.123` 来连接 `MaixCAM`，默认密码是`root`。 * 通过 `MaixVision` 的`终端`功能来连接（MaixVision 版本 > 1.2.0）。 * 通过 Python 脚本来执行，最简单的就是使用`os.system()`函数，比如 ```python import os os.system(\"echo hello\") ``` 另外`Python`还有其它模块可以执行 shell 命令，比如`subprocess` 模块： ```python import subprocess # 要执行的命令 command [\"echo\", \"Hello, World!\"] # 使用 Popen 执行命令 process subprocess.Popen(command, stdout subprocess.PIPE, stderr subprocess.PIPE) # 获取输出和错误 stdout, stderr process.communicate() # 打印输出 print(\"标准输出:\", stdout.decode()) print(\"标准错误:\", stderr.decode()) ``` ## Linux 常用命令参考 这里列一些常见的 Linux 命令操作，方便查阅。 注意以下为社区成员贡献文档，只做参考，以及并不是所有命令是适用于 MaixCAM 的系统。 ### 文件和目录操作 **ls**：列出目录内容。 ```bash ls l # 详细列表 ls a # 显示隐藏文件 ``` **cd**：改变当前目录。 ```bash cd /home/user # 进入/home/user目录 cd .. # 返回上一级目录 cd ~ # 返回用户主目录 ``` **pwd**：显示当前工作目录。 ```bash pwd ``` **mkdir**：创建新目录。 ```bash mkdir new_directory mkdir p parent_directory/child_directory # 递归创建目录 ``` **rmdir**：删除空目录。 ```bash rmdir empty_directory ``` **rm**：删除文件或目录。 ```bash rm file.txt # 删除文件 rm r directory # 递归删除目录及其内容 ``` **cp**：复制文件或目录。 ```bash cp source_file destination_file # 复制文件 cp r source_directory destination_directory # 递归复制目录 ``` **mv**：移动或重命名文件或目录。 ```bash mv old_name new_name # 重命名文件或目录 mv file.txt /new_directory/ # 移动文件到新目录 ``` **touch**：创建空文件或更新文件的时间戳。 ```bash touch new_file.txt ``` **cat**：连接文件并打印到标准输出。 ```bash cat file.txt # 显示文件内容 ``` **more**：分页显示文件内容。 ```bash more file.txt ``` **less**：类似more，但更强大。 ```bash less file.txt ``` **head**：显示文件的前几行。 ```bash head n 10 file.txt # 显示文件的前10行 ``` **tail**：显示文件的后几行。 ```bash tail n 10 file.txt # 显示文件的后10行 ``` ### 文件权限管理 **chmod**：改变文件或目录的权限。 ```bash chmod 755 file.txt # 设置文件权限为rwxr xr x chmod u+x file.txt # 给文件所有者添加执行权限 ``` **chown**：改变文件或目录的所有者。 ```bash chown user:group file.txt # 改变文件的所有者和所属组 ``` **chgrp**：改变文件或目录的所属组。 ```bash chgrp group file.txt # 改变文件的所属组 ``` ### 系统管理 **ps**：显示当前进程的状态。 ```bash ps ef # 显示所有进程 ``` **top**：实时显示系统中各个进程的资源使用情况。 ```bash top ``` ```bash htop ``` **kill**：终止进程。 ```bash kill 2 PID # 向进程发送 Ctrl+C 信号 kill 9 PID # 强制终止进程 ``` **df**：显示文件系统的磁盘空间使用情况。 ```bash df h # 以人类可读的格式显示 ``` **du**：显示目录或文件的磁盘使用情况。 ```bash du sh directory # 显示目录的总大小 ``` **free**：显示系统的内存使用情况。 ```bash free h # 以人类可读的格式显示 ``` **ifconfig**：显示或配置网络接口。 ```bash ifconfig # 显示网络接口信息 ``` **ping**：测试网络连通性。 ```bash ping www.example.com # 测试与www.example.com的连通性 ``` **netstat**：显示网络连接、路由表、接口状态等。 ```bash netstat an # 显示所有网络连接 ``` **shutdown**：关闭或重启系统。 ```bash shutdown # 立即关机 shutdown h now # 立即关机 shutdown r now # 立即重启 ``` **reboot**：重启系统。 ```bash reboot ``` ### 软件包管理 **apt get**（适用于Debian系，如Ubuntu） ```bash sudo apt get update # 更新软件包列表 sudo apt get upgrade # 升级所有已安装的软件包 sudo apt get install package_name # 安装软件包 sudo apt get remove package_name # 删除软件包 sudo apt get autoremove # 删除不再需要的包 ``` **yum**（适用于Red Hat系，如CentOS） ```bash sudo yum update # 更新所有包 sudo yum install package_name # 安装软件包 sudo yum remove package_name # 删除软件包 sudo yum clean all # 清理缓存 ``` ### 用户和组管理 **useradd**：添加新用户。 ```bash sudo useradd m new_user # 创建新用户并创建主目录 sudo passwd new_user # 设置新用户的密码 ``` **usermod**：修改用户信息。 ```bash sudo usermod aG group_name user_name # 将用户添加到组 ``` **userdel**：删除用户。 ```bash sudo userdel r user_name # 删除用户及其主目录 ``` **groupadd**：添加新组。 ```bash sudo groupadd new_group ``` **groupdel**：删除组。 ```bash sudo groupdel group_name ``` ### Shell脚本 Shell脚本是Linux系统管理和自动化任务的重要工具。以下是一个简单的Shell脚本示例： ```bash #!/bin/bash # 打印当前日期和时间 echo \"Current date and time: $(date)\" # 创建一个目录 mkdir p /tmp/my_directory # 进入目录 cd /tmp/my_directory # 创建一个文件 touch my_file.txt # 写入内容到文件 echo \"Hello, World!\" > my_file.txt # 显示文件内容 cat my_file.txt ``` 保存上述内容为`script.sh`，然后通过以下命令执行： ```bash chmod +x script.sh # 赋予执行权限 ./script.sh # 执行脚本 ``` ### Linux 的网络配置 #### 配置静态IP地址 编辑网络配置文件（例如在CentOS上）： ```bash sudo vi /etc/sysconfig/network scripts/ifcfg eth0 ``` 添加或修改以下内容： ```bash BOOTPROTO static ONBOOT yes IPADDR 192.168.1.100 NETMASK 255.255.255.0 GATEWAY 192.168.1.1 DNS1 8.8.8.8 DNS2 8.8.4.4 ``` 重启网络服务： ```bash sudo systemctl restart network ``` #### 配置 DNS 编辑`/etc/resolv.conf`文件： ```bash sudo vi /etc/resolv.conf ``` 添加以下内容： ```bash nameserver 8.8.8.8 nameserver 8.8.4.4 ``` #### 防火墙管理 在CentOS上使用`firewalld`： ```bash sudo systemctl start firewalld # 启动防火墙 sudo systemctl enable firewalld # 开机启动防火墙 sudo firewall cmd list all # 查看防火墙规则 sudo firewall cmd add port 80/tcp permanent # 添加规则 sudo firewall cmd reload # 重载防火墙规则 ``` ### Linux 的日志管理 Linux系统日志通常保存在`/var/log`目录下。常见的日志文件包括： **/var/log/messages**：系统消息。 **/var/log/syslog**：系统日志。 **/var/log/dmesg**：内核消息。 **/var/log/boot.log**：启动日志。 查看日志内容： ```bash cat /var/log/messages ``` 使用`grep`搜索特定内容： ```bash grep \"error\" /var/log/messages ``` ### Linux的性能监控 #### top 实时显示系统中各个进程的资源使用情况。 ```bash top ``` 或者 ```bash htop ``` #### vmstat 报告虚拟内存、进程、I/O等信息。 ```bash vmstat 1 # 每秒更新一次 ``` ####iostat 监控系统输入/输出设备。 ```bash iostat 1 # 每秒更新一次 ``` #### mpstat 监控CPU统计信息。 ```bash mpstat P ALL 1 # 监控所有CPU，每秒更新一次 ``` #### netstat 监控网络连接和流量。 ```bash netstat an ``` ### Linux 的安全性 #### SELinux SELinux（Security Enhanced Linux）是一个强制访问控制系统，提供了更细粒度的安全控制。 查看SELinux状态： ```bash sestatus ``` #### AppArmor AppArmor是另一种Linux安全模块，提供了基于路径的访问控制。 #### 权限管理 合理设置文件和目录的权限，避免使用root用户进行日常操作。 #### 防火墙 配置iptables或firewalld防火墙规则，限制不必要的网络访问。 #### 定期更新 定期更新系统和软件包，修复安全漏洞。 ### Linux 的备份与恢复 #### tar 打包和压缩文件。 ```bash tar czvf archive_name.tar.gz /path/to/directory ``` #### rsync 同步文件和目录。 ```bash rsync avz /source/directory user@remote_host:/destination/directory ``` #### dump 备份文件系统。 ```bash dump 0 /path/to/directory ``` #### restore 恢复文件系统。 ```bash restore rf /dev/fd0 ``` ### Linux 的故障排除 #### 检查磁盘空间 ```bash df h ``` #### 检查磁盘健康 使用`smartctl`检查磁盘SMART状态。 ```bash smartctl a /dev/sda ``` #### 检查日志文件 查看`/var/log`目录下的日志文件，查找错误信息。 #### 网络诊断 使用`ping`、`traceroute`等工具诊断网络问题。 ```bash ping www.example.com traceroute www.example.com ``` #### 系统监控 使用`top`、`vmstat`等工具监控系统性能。 ### Linux的编程开发 #### gcc/g++ 编译C/C++程序。 ```bash gcc o program program.c g++ o program program.cpp ``` #### make 自动化编译和链接。 ```bash make f Makefile ``` #### gdb 调试C/C++程序。 ```bash gdb program ``` #### vim/emacs 强大的文本编辑器。 #### git 版本控制。 ```bash git clone https://github.com/user/repo.git git add . git commit m \"message\" git push origin master ``` #### Python Python编程。 ```bash python3 script.py ``` #### Perl Perl编程。 ```bash perl script.pl ``` ### Linux 的容器技术 #### Docker Docker是一个开源的容器化平台，允许开发者打包应用以及应用的依赖包到一个可移植的容器中，然后发布到任何流行的Linux机器上，也可以实现虚拟化。 拉取和运行Docker镜像： ```bash docker pull ubuntu docker run it ubuntu /bin/bash ``` 管理Docker容器： ```bash docker ps # 查看运行中的容器 docker stop container_id # 停止容器 docker rm container_id # 删除容器 ``` #### Kubernetes Kubernetes是一个开源的容器编排系统，用于自动化部署、扩展和管理容器化应用程序。 ```bash kubectl run my pod image ubuntu command /bin/bash ``` ### Linux 的虚拟化技术 #### KVM KVM（Kernel based Virtual Machine）是一个基于Linux内核的虚拟化技术。 #### Xen Xen是一个开源的虚拟化平台，支持多种操作系统。 #### VirtualBox VirtualBox是一个开源的虚拟化软件，可以在多种操作系统上运行。"},"/maixpy/doc/zh/basic/maixpy_upgrade.html":{"title":"MaixCAM 更新 MaixPy","content":" title: MaixCAM 更新 MaixPy layout: redirect redirect_url: ./upgrade.html "},"/maixpy/doc/zh/basic/upgrade.html":{"title":"MaixCAM MaixPy 升级和烧录系统","content":" title: MaixCAM MaixPy 升级和烧录系统 ## 系统和 MaixPy 介绍 首先需要区分一下 `系统` 和 `MaixPy`: * **系统**： 运行所有软件的基础，包含了操作系统和驱动等，所有软件运行的基石。 * **MaixPy**: 软件包，依赖系统的驱动运行。 ## 获得最新系统 在 [MaixPy 发布页面](https://github.com/sipeed/MaixPy/releases) 找到最新的系统镜像文件，比如: * `maixcam_os_20240401_maixpy_v4.1.0.xz`: MaixCAM 系统镜像，包含了 MaixPy v4.1.0。 * `maixcam pro_os_20240401_maixpy_v4.1.0.xz`： MaixCAM Pro 系统镜像，包含了 MaixPy v4.1.0。 * `maixcam2_os_20250801_maixpy_v4.11.0.xz`： MaixCAM2 系统镜像，包含了 MaixPy v4.11.0。 <span style \"color: #e91e63; font weight: 800\">注意一定要下载对应型号的系统镜像</span>，下载错误可能导致设备损坏。 > 中国国内用户下载速度慢可以用迅雷下载，速度可能会快一些。 > 或者使用例如 [github.abskoop.workers.dev](https://github.abskoop.workers.dev/) 这种代理网站下载。 备用地址：[Sourceforge](https://sourceforge.net/projects/maixpy/files/) （同步可能不及时，建议优先上面的方式） ## 备份数据 **更新（烧录）系统会抹掉所有数据**。 如果你已经在系统里面存了重要数据，请先将数据拷贝到电脑备份。 备份方法： * 连接 MaixVision， 使用文件管理功能下载你的重要数据文件到电脑本地，一般来说`/maixapp` 和 `/root` 目录下的文件需要多注意保存。 * 使用 `scp` 命令进行拷贝。 * 使用其它文件管理软件，比如 `WinSCP` 或者 `FileZilla` 等进行传输。 * 直接用读卡器插到电脑拷贝。注意根目录是`ext4`格式，`Windows`默认不支持（可以用三方软件比如diskgenius 读取）。 ## 烧录系统到硬件 项目 MaixCAM / MaixCAM Pro MaixCAM2 烧录文档 [MaixCAM 系统烧录](https://wiki.sipeed.com/hardware/zh/maixcam/os.html) [MaixCAM2 系统烧录](https://wiki.sipeed.com/hardware/zh/maixcam/os_maixcam2.html) 系统存放位置 TF 卡 内置EMMC(/TF卡) 必须 TF 卡 是 否 烧录方式 USB 烧录 或 读卡器烧录 USB 烧录 或 读卡器烧录 推荐烧录方式 USB 烧录 USB 烧录 救砖烧录方式 读卡器烧录 USB烧录/读卡器烧录 ## 什么时候需要更新系统，什么时候可以只更新 MaixPy 为了简单并且不出问题，升级 `MaixPy` 一律**推荐直接更新系统**。 以下情况出现**之一**就**必须**更新系统： 1. TF 卡为新卡，则必须使用 TF 读卡器升级系统。 2. 想升级 MaixPy， [MaixPy 发布页面](https://github.com/sipeed/MaixPy/releases) 显示自旧版本到新版本所有版本中，只要**有一个版本**系统有更新，则**必须更新系统**才能正常使用对应版本的`MaixPy`。 > 比如设备现在运行的`maixcam_os_20240401_maixpy_v4.1.0`，想要升级到`4.7.8`，如果`4.1.0`到 `4.7.8`中间任意一个版本系统有更新则必须更新系统，否则可能导致`MaixPy`无法正常使用。 以下情况**强烈推荐**更新： 1. 第一次拿到手，出厂烧录的系统版本可能比较老旧，升级到最新以保持和文档同步。 以下情况不推荐轻易更新： 1. 功能满足要求，并且在重要场合（比如比赛中、 产品部署中）运行稳定，无需更新。 2. 升级会带来新特性，但由于是开发套件，理论上存在轻微代码不兼容或新引入bug，请在做好开发调试准备的情况下升级。 ## 单独升级 MaixPy 仔细阅读上述注意点后，如果你确定你需要只升级 MaixPy，三种方法： 1. MaixVision 中使用`ssh终端`功能，执行`pip install U MaixPy`，中国可以使用`pip install U MaixPy i https://pypi.mirrors.ustc.edu.cn/simple` 下载速度更快。 2. MaixVision 中执行`examples/tools/install_maixpy.py` 脚本来升级。 3. 手动下载[MaixPy x.x.x py3 none any.whl](https://github.com/sipeed/MaixPy/releases)传输到设备，使用`ssh终端`运行`pip install xxx.whl`或者执行代码`import os;os.system(\"xxx.whl\")` 来安装文件。 时间比较长，需要耐心等待。"},"/maixpy/doc/zh/basic/app.html":{"title":"MaixCAM MaixPy 应用开发和应用商店","content":" title: MaixCAM MaixPy 应用开发和应用商店 ## 哪里找应用 开机后会自动进入应用选择界面，内置各种应用均发布在 [MaixHub 应用商店](https://maixhub.com/app)， 可以在这里找到对应应用的介绍和使用说明。 ## 哪里找源码 源码可以在应用商店应用页面看到源码链接（如果有）。 官方集成的应用源码都在 [MaixPy/projects](https://github.com/sipeed/MaixPy/tree/main/projects) 目录 或者 [MaixCDK/projects](https://github.com/sipeed/MaixCDK/tree/main/projects) 。 ## 安装应用 有几种方法： ### 在线扫码安装 可以先设置语言 `设置 > 语言`， 以及 `设置 > WiFi`。 [应用商店](https://maixhub.com/app)可以用来升级和安装应用，连接上可以连接互联网的 WiFi 后即可在[MaixHub 应用商店](https://maixhub.com/app)扫码安装应用。 ### 本地安装 上传应用安装包到设备，然后命令行使用`app_store_cli install 安装包路径`命令安装应用。 或者执行脚本 [MaixPy/examples/tools/install_app.py](https://github.com/sipeed/MaixPy) 来安装应用, 注意修改`pkg_path`变量的路径。 ### 本地扫码安装电脑上的安装包 * 可以在电脑利用 `maixtool deploy pkg 安装包路径` 起一个服务，然后在设备端的`应用商店`应用中扫码即可实现安装电脑上的安装包。 > 需要电脑先`pip install maixtool` 安装 `maixtool` 工具。 * 如果是使用`MaixPy`开发的应用，在项目根目录（包含`app.yaml`和`main.py`）执行`maixtool deploy`会弹出一个二维码，保持设备和电脑在同一局域网，设备使用应用商店扫描对应的局域网地址二维码就能在线安装。 * 如果是使用`MaixCDK`开发的应用，在项目根目录执行`maixcdk deploy`也会出现二维码，保持设备和电脑在同一局域网，设备使用应用商店扫描对应的局域网地址二维码就能在线安装。 ## 卸载应用 在设备端`应用商店`应用中，选择`卸载应用`功能即可。 另外也可以执行脚本[MaixPy/examples/tools/uninstall_app.py](https://github.com/sipeed/MaixPy)，设置`app_id`变量为要卸载的应用 ID。 `app_id`可以执行`MaixPy/examples/tools/list_app.py`脚本来查看已安装应用的 ID。 ## 应用生态简介 为了让开发板做到开箱即用，以及方便用户无门槛地使用，以及方便开发者分享自己的有趣应用，并且能有有效的渠道获取到反馈甚至是收益，我们推出了一个简易的应用框架，包括： * **[应用商店](https://maixhub.com/app)**： 开发者上传分享应用，用户无需开发直接下载使用，开发者可以获取到一定的现金收益（来自 MaixHub 官方以及用户打赏）。 * **出厂内置大量应用**： 官方提供了一些常用的应用，比如找色块、AI 物体检测追踪、找二维码、人脸识别等等，用户可以直接使用，也可以作为串口模块直接使用。 * **MaixPy + MaixCDK** 软件开发包：使用 [MaixPy](https://github.com/sipeed/maixpy) 或者 [MaixCDK](https://github.com/sipeed/MaixCDK) 可以用 Python 或者 C/C++ 语言快速开发嵌入式 AI 视觉听觉应用，超高效率实现你的有趣想法。 * **MaixVision** 配套电脑端开发工具: 全新的电脑端代码开发工具，快速上手、调试、运行、上传代码、安装应用到设备，一键式开发，甚至支持图像化积木式编程，小学生也能轻松上手。 大家可以多多关注应用商店，也可以在应用商店中分享自己的应用，大家一起共建活跃的社区。 ## 打包应用 * **MaixVision 打包**：参考[MaixVision 使用文档](./maixvision.html) 打包应用部分。 * **手动打包**：你也可以在项目根目录手动添加`app.yaml`文件，参考 [Maix APP 规范](https://wiki.sipeed.com/maixcdk/doc/zh/convention/app.html)， 然后执行`maixtool release`(MaixPy 项目) 或者 `maixcdk release`(MaixCDK 项目) 来打包应用。 ## 退出应用 如果你只是写了比较简单的应用，没有做界面和返回按钮，默认可以按设备上的功能按键（一般是 USER 或者 FUNC 或者 OK 按钮）或者返回按钮（如果有这个按键，MaixCAM 默认没有这个按键）来退出应用。 ## 应用开发基本准则 * 因为默认都配了触摸屏幕，推荐都写一个简单的界面显示，最好有触摸交互。实现方法可以在例子里面找找参考。 * 界面和按钮不要太小，因为 MaixCAM 默认的屏幕是 2.3寸 552x368分辨率，PPI 比较高屏幕比较小，要让手指能很容易戳到并且不会点错。 * 每个应用实现的主要功能实现一个简单的串口交互，基于[串口协议](https://github.com/sipeed/MaixCDK/blob/master/docs/doc/convention/protocol.md) （[例程](https://github.com/sipeed/MaixPy/tree/main/examples/communication/protocol)）,这样用户可以直接当成串口模块使用，比如人脸检测应用，可以在检测到人脸后通过串口输出坐标。 ## 设置应用开机自动启动 参考 [应用开机自启](./auto_start.html) ## 系统设置 系统设置应用里面有一些设置项，比如语言、屏幕亮度等，我们可以通过`maix.app.get_sys_config_kv(item, key)`来获取这些设置项的值。 比如获取语言设置项： ```python from maix import app locale app.get_sys_config_kv(\"language\", \"locale\") print(\"locale:\", locale) backlight app.get_sys_config_kv(\"backlight\", \"value\") print(\"backlight:\", backlight, \", type:\", type(backlight)) ``` 这里**注意**，所有设置项的**值都是字符串**类型，使用时需要注意。 系统设置的配置被保存在`/boot/configs` 文件，你也可以在未开机情况下修改，不过要小心格式。 格式遵循`maix_<item>_<key> value`，变量要让`shell`能使用，所以注意等号两边不要有空格。 文件内容示例（注意不是所有配置，具体以 `/boot/configs` 为准）： ```ini # All configs user can edit easily # Format: maix_<item>_<key> value # all key charactors should be lowercase # Full supported items see documentation of maixpy at: # https://wiki.sipeed.com/maixpy/doc/zh/basic/app.html ### [language] maix_language_locale en ### [wifi] # can be \"ap\" or \"sta\" or \"off\" maix_wifi_mode sta maix_wifi_ssid Sipeed_Guest maix_wifi_passwd qwert123 # encrypt default auto detect, you can also set it manually: # can be \"NONE\", \"WPA PSK\", \"WPA EAP\", \"SAE\" # maix_wifi_encrypt \"WPA PSK\" ### [comm] Maix comm protocol # can be \"uart\" or \"none\" maix_comm_method uart ## [backlight] Screeen backlight, from 0 to 100 maix_backlight_value 50 ### [npu] # for maixcam2, enable AI ISP(1) or not(0), # enalbe AI ISP will get better camera quality and occupy half of NPU. maix_npu_ai_isp 0 ```"},"/maixpy/doc/zh/basic/app_usage.html":{"title":"MaixCAM MaixPy 应用使用说明","content":" title: MaixCAM MaixPy 应用使用说明 layout: redirect redirect_url: ./app.html "},"/maixpy/doc/zh/vision/image_ops.html":{"title":"MaixCAM MaixPy 图像基础操作","content":" title: MaixCAM MaixPy 图像基础操作 update: date: 2024 04 03 author: neucrack version: 1.0.0 content: 初版文档 date: 2024 07 08 author: neucrack version: 1.1.0 content: 优化 cv 和 image 转换文档 ## 简介 视觉应用中图像占据非常重要的位置，不管是图片还是视频，因为视频本质上就是一帧帧的图像，所以图像处理是视觉应用的基础。 ## API 文档 本文介绍常用方法， 更多 API 参考 [maix.image](/api/maix/image.html) 模块的文档。 ## 图像格式 MaixPy 提供基础图像模块`image`，里面最重要的就是`image.Image`类，用于图像的创建以及各种图像基础操作，以及图像加载和保存等。 图像格式有很多，一般我们用`image.Format.FMT_RGB888` 或者 `image.Format.FMT_RGBA8888` 或者 `image.Format.FMT_GRAYSCALE`或者`image.Format.FMT_BGR888`等。 大家知道 `RGB` 三色可以合成任意颜色，所以一般情况下我们使用 `image.Format.FMT_RGB888`就足够， `RGB888` 在内存中是 `RGB packed` 排列，即在内存中的排列： `像素1_红色, 像素1_绿色, 像素1_蓝色, 像素2_红色, 像素2_绿色, 像素2_蓝色, ...` 依次排列。 ## 创建图像 创建图像很简单，只需要指定图像的宽度和高度以及图像格式即可： ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) print(img) print(img.width(), img.height(), img.format()) ``` `320` 是图像的宽度，`240` 是图像的高度，`image.Format.FMT_RGB888` 是图像的格式，格式参数可以省略，默认是`image.Format.FMT_RGB888`。 这里通过`img.width()`、`img.height()`、`img.format()`可以获取图像的宽度、高度和格式。 ## 显示到屏幕 MaixPy 提供了`maix.display.Display`类，可以方便的显示图像： ```python from maix import image, display disp display.Display() img image.Image(320, 240, image.Format.FMT_RGB888) disp.show(img) ``` 注意这里因为没有图像数据，所以显示的是黑色的图像，修改画面看后文。 ## 从文件系统读取图像 MaixPy 提供了`maix.image.load`方法，可以从文件系统读取图像： ```python from maix import image img image.load(\"/root/image.jpg\") if img is None: raise Exception(f\"load image failed\") print(img) ``` 注意这里`/root/image.jpg` 是提前传输到了板子上的，方法可以看前面的教程。 可以支持 `jpg` 和 `png` 格式的图像。 ## 保存图像到文件系统 MaixPy 的`maix.image.Image`提供了`save`方法，可以保存图像到文件系统： ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) # do something with img img.save(\"/root/image.jpg\") ``` ## 画框 `image.Image`提供了`draw_rect`方法，可以在图像上画框： ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img.draw_rect(10, 10, 100, 100, image.Color.from_rgb(255, 0, 0)) ``` 这里的参数依次是：`x`, `y`, `w`, `h`, `color`，`x` 和 `y` 是框的左上角坐标，`w` 和 `h` 是框的宽度和高度，`color` 是框的颜色，可以使用`image.Color.from_rgb`方法创建颜色。 可以用`thickness`指定框的线宽，默认是`1`， 也可以画实心框，传参 `thickness 1` 即可： ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img.draw_rect(10, 10, 100, 100, (255, 0, 0), thickness 1) ``` ## 写字符串 `image.Image`提供了`draw_string`方法，可以在图像上写字： ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img.draw_string(10, 10, \"Hello MaixPy\", image.Color.from_rgb(255, 0, 0)) ``` 这里的参数依次是：`x`, `y`, `text`, `color`，`x` 和 `y` 是文字的左上角坐标，`text` 是要写的文字，`color` 是文字的颜色，可以使用`image.Color.from_rgb`方法创建颜色。 还可以放大字体，传参 `scale` 即可： ```python img.draw_string(10, 10, \"Hello MaixPy\", image.Color.from_rgb(255, 0, 0), scale 2) ``` 获取字体的宽度和高度： ```python w, h image.string_size(\"Hello MaixPy\", scale 2) print(w, h) ``` **注意**这里`scale`是放大倍数，默认是`1`，和`draw_string`应该保持一致。 ## 中文支持和自定义字体 `image` 模块支持加载`ttf/otf`字体，默认字体只支持英文，如果要显示中文或者自定义字体可以先下载字体文件到设备上，然后加载字体。 系统也内置了几个字体，在`/maixapp/share/font`目录下面，代码示例： ```python from maix import image, display, app, time image.load_font(\"sourcehansans\", \"/maixapp/share/font/SourceHanSansCN Regular.otf\", size 32) print(\"fonts:\", image.fonts()) image.set_default_font(\"sourcehansans\") disp display.Display() img image.Image(disp.width(), disp.height()) img.draw_string(2, 2, \"你好！Hello, world!\", image.Color.from_rgba(255, 0, 0, 0.8)) disp.show(img) while not app.need_exit(): time.sleep(1) ``` 加载字体文件，然后设置默认的字体，也可以不设置默认的字体，在写字的函数参数设置: ```python img.draw_string(2, 2, \"你好！Hello, world!\", image.Color.from_rgba(255, 0, 0, 0.8), font \"sourcehansans\") ``` 注意 `string_size`方法也会使用设置的默认字体计算大小，也可以通过`font`参数单独设置要计算大小的字体。 ## 画线 `image.Image`提供了`draw_line`方法，可以在图像上画线： ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img.draw_line(10, 10, 100, 100, image.Color.from_rgb(255, 0, 0)) ``` 这里的参数依次是：`x1`, `y1`, `x2`, `y2`, `color`，`x1` 和 `y1` 是线的起点坐标，`x2` 和 `y2` 是线的终点坐标，`color` 是线的颜色，可以使用`image.Color.from_rgb`方法创建颜色。 ## 画圆 `image.Image`提供了`draw_circle`方法，可以在图像上画圆： ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img.draw_circle(100, 100, 50, image.Color.from_rgb(255, 0, 0)) ``` 这里的参数依次是：`x`, `y`, `r`, `color`，`x` 和 `y` 是圆心坐标，`r` 是半径，`color` 是圆的颜色，可以使用`image.Color.from_rgb`方法创建颜色。 ## 缩放图像 `image.Image`提供了`resize`方法，可以缩放图像： ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img_new img.resize(160, 120) print(img, img_new) ``` 注意这里`resize`方法返回一个新的图像对象，原图像不变。 ## 剪裁图像 `image.Image`提供了`crop`方法，可以剪裁图像： ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img_new img.crop(10, 10, 100, 100) print(img, img_new) ``` 注意这里`crop`方法返回一个新的图像对象，原图像不变。 ## 旋转图像 `image.Image`提供了`rotate`方法，可以旋转图像： ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img_new img.rotate(90) print(img, img_new) ``` 注意这里`rotate`方法返回一个新的图像对象，原图像不变。 ## 拷贝图像 `image.Image`提供了`copy`方法，可以拷贝一份独立的图像： ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img_new img.copy() print(img, img_new) ``` ## 仿射变换 `image.Image`提供了`affine`方法，可以进行仿射变换，即提供当前图中三个及以上的点坐标，以及目标图中对应的点坐标，可以自动进行图像的旋转、缩放、平移等操作变换到目标图像： ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img_new img.affine([(10, 10), (100, 10), (10, 100)], [(10, 10), (100, 20), (20, 100)]) print(img, img_new) ``` 更多参数和用法请参考 API 文档。 ## 画关键点 `image.Image`提供了`draw_keypoints`方法，可以在图像上画关键点： ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) keypoints [10, 10, 100, 10, 10, 100] img.draw_keypoints(keypoints, image.Color.from_rgb(255, 0, 0), size 10, thickness 1, fill False) ``` 在坐标`(10, 10)`、`(100, 10)`、`(10, 100)`画三个红色的关键点，关键点的大小是`10`，线宽是`1`，不填充。 ## 画十字 `image.Image`提供了`draw_cross`方法，可以在图像上画十字： ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img.draw_cross(100, 100, image.Color.from_rgb(255, 0, 0), size 5, thickness 1) ``` 在坐标`(100, 100)`画一个红色的十字，十字的延长大小是`5`，所以线段长度为`2 * size + thickness`, 线宽是`1`。 ## 画箭头 `image.Image`提供了`draw_arrow`方法，可以在图像上画箭头： ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img.draw_arrow(10, 10, 100, 100, image.Color.from_rgb(255, 0, 0), thickness 1) ``` 在坐标`(10, 10)`画一个红色的箭头，箭头的终点是`(100, 100)`，线宽是`1`。 ## 画图 `image.Image`提供了`draw_image`方法，可以在图像上画图： ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img2 image.Image(100, 100, image.Format.FMT_RGB888) img2.draw_rect(10, 10, 90, 90, image.Color.from_rgb(255, 0, 0)) img.draw_image(10, 10, img2) ``` ## 转换格式 `image.Image`提供了`to_format`方法，可以转换图像格式： ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) img_new img.to_format(image.Format.FMT_BGR888) print(img, img_new) img_jpg img.to_format(image.Format.FMT_JPEG) print(img, img_new) ``` 注意这里`to_format`方法返回一个新的图像对象，原图像不变。 ## maix.image.Image 对象和 Numpy/OpenCV 格式互相转换 见[MaixPy 使用 OpenCV 文档](./opencv.html) ## 和 bytes 数据互相转换 `image.Image`提供了`to_bytes`方法，可以转换图像为`bytes`数据： ```python from maix import image img image.Image(320, 240, image.Format.FMT_RGB888) data img.to_bytes() print(type(data), len(data), img.data_size()) img_jpeg image.from_bytes(320, 240, image.Format.FMT_RGB888, data) print(img_jpeg) img img_jpeg.to_format(image.Format.FMT_RGB888) print(img) ``` 这里`to_bytes`获得一个新的`bytes`对象，是独立的内存，不会影响原图。 `image.Image`构造函数中传入`data`参数可以直接从`bytes`数据构造图像对象，注意新的图像也是独立的内存，不会影响到`data`。 因为涉及到内存拷贝，所以这个方法比较耗时，不建议频繁使用。 > 如果你想用不拷贝的方式优化程序（不建议轻易使用，写不好代码会导致程序容易崩溃，），请看 API 文档。 ## 更多基础 API 使用方法 更多 API 使用方法请参考 [maix.image](/api/maix/image.html) 模块的文档。"},"/maixpy/doc/zh/vision/self_learn_detector.html":{"title":"MaixCAM MaixPy 自学习检测跟踪器","content":" title: MaixCAM MaixPy 自学习检测跟踪器 update: date: 2024 04 03 author: neucrack version: 1.0.0 content: 初版文档 update: date: 2025 09 03 author: neucrack version: 1.1.0 content: 增加 MixFormerV2 支持 ## MaixPy 自学习检测跟踪器 和自学习分类器类似，不需要训练，直接框选目标物体即可实现检测并且跟踪物体，在简单检测场景下十分好用。 和自学习分类器不同的是因为是检测器，会有物体的坐标和大小。 另外也有其它的名字，比如 SOT(单目标追踪) 和 MOT(多目标追踪)，我们将其都归类到 自学习检测追踪器 里面了，目前 MaixPy 支持了两种 SOT 算法，当然你也可以自行移植或创造更多算法，希望能抛砖引玉。 <video playsinline controls autoplay loop muted preload src \"/static/video/self_learn_tracker.mp4\" style \"width: 100%; min height: 20em;\"></video> ## MaixPy 中使用自学习检测跟踪器 在 MaixPy 目前提供了一种单目标学习检测跟踪算法，即开始框选目标物体，后面会一直跟踪这个物体。 这里使用的算法是[NanoTrack](https://github.com/HonglinChu/SiamTrackers/tree/master/NanoTrack) 和 [MixFormerV2](https://github.com/MCG NJU/MixFormerV2)，有兴趣了解原理的可以自行学习。 可以烧录最新的系统镜像后直接使用内置的自学习跟踪应用看效果。 不同设备支持的模型不太样，以及不同算法各有特点，如下表： 模型 NanoTrack MixFormerV2 特点 轻量，运行速度快 比 NaonoTrack 速度稍慢，支持在线更新，识别效果更好 子分类 SOT SOT MaixCAM / MaixCAM Pro ✅<br> ❌ MaixCAM2 ❌ ✅<br>模型运行 38fps<br>全流程 640x480 33fps ### NanoTrack 使用`maix.nn.NanoTrack`类即可，初始化对象后，先调用`init`方法指定要检测的目标，然后调用`track`方法连续跟踪目标，以下为简化的代码： ```python from maix import nn model_path \"/root/models/nanotrack.mud\" tracker nn.NanoTrack(model_path) tracker.init(img, x, y, w, h) pos tracker.track(img, threshold 0.9) ``` 这里先从一张图中指定`x,y,w,h` 目标位置学习目标特征，然后调用`tack`函数从新的图像中追踪目标获取到目标的位置。 具体详细代码请看[MaixPy/examples/vision/ai_vision/nn_self_learn_tracker.py](https://github.com/sipeed/MaixPy/blob/main/examples/vision/ai_vision/nn_self_learn_tracker.py) > 注意这里使用了内置的模型，在系统`/root/models`下已经内置了，你也可以在[MaixHub 模型库](https://maixhub.com/model/zoo/437)下载到模型。 ### MixFormerV2 使用`maix.nn.MixFormerV2`类即可，初始化对象后，先调用`init`方法指定要检测的目标，然后调用`track`方法连续跟踪目标，以下为简化的代码： ```python from maix import nn model_path \"/root/models/nanotrack.mud\" tracker nn.MixFormerV2(model_path, update_interval 200, int lost_find_interval 60) tracker.init(img, x, y, w, h) pos tracker.track(img, threshold 0.5) ``` 和`NanoTrack`类似，这里先从一张图中指定`x,y,w,h` 目标位置学习目标特征，然后调用`tack`函数从新的图像中追踪目标获取到目标的位置。 不同的是，这里多提供了两个参数： * **update_interval**: 每隔`update_interval`帧图更新一次目标，同时初始目标也会保留，更新后的目标和初始目标一起输入得到结果。这样就算目标有变化也能及时学习到，比如角度变化。 * **lost_find_interval**: 这是内置的一个简单的丢失找回算法，即超过`lost_find_interval`帧没找到数据后，会自动改变搜索区域尝试搜索。 具体详细代码请看[MaixPy/examples/vision/ai_vision/nn_self_learn_tracker.py](https://github.com/sipeed/MaixPy/blob/main/examples/vision/ai_vision/nn_self_learn_tracker.py) ## 丢失找回 对于 `NanoTrack` `MixFormerV2`，两者都是基于搜索区域的识别，比如一张图 1920x1080，初始目标只有 100x50 像素，实际检测不会检测整张1920x1080的图，会从目标附近按照一定比例扩大后裁切一部分作为识别区域进行识别。在上面的视频中也可以看到目标外围画出了搜索区域框。 所以问题是，当目标被遮挡或者消失一段时间后再从搜索区域外出现，就无法检测到目标，目标虽然在画面中，但是算法找不到，这个时候就需要一个找回算法，对于 `NanoTrack` `MixFormerV2` 算法官方没有提供找回，MaixPy 中`MixFormerV2`的实现提供了一个简单的找回算法，只要设置`lost_find_interval`参数就能在丢失目标后自动尝试全局搜索。 ## 其它自学习跟踪算法和算法优化 本文抛砖引玉，提供了几个算法，如果有更好的算法和优化，可以自行参考已有的 NanoTrack / MixFormerV2 实现方式进行实现，也欢迎讨论或者提交代码PR。"},"/maixpy/doc/zh/vision/ai.html":{"title":"MaixCAM MaixPy AI 视觉基本知识","content":" title: MaixCAM MaixPy AI 视觉基本知识 update: date: 2024 04 03 author: neucrack version: 1.0.0 content: 初版文档 ## 简介 如果没有 AI 基础，在学习 AI 前可以先看[什么是人工智能(AI)和机器学习](https://wiki.sipeed.com/ai/zh/basic/what_is_ai.html) 了解一下 AI 的基本概念。 然后我们使用的视觉 AI 一般都是基于`深度神经网络学习`这个方法，有兴趣可以看看[深度神经网络（DNN）基础知识](https://wiki.sipeed.com/ai/zh/basic/dnn_basic.html) ## MaixPy 中使用视觉 AI 在 MaixPy 中使用视觉 AI 很简单，默认提供了常用的 AI 模型，不需要自己训练模型就可以直接使用，在[MaixHub 模型库](https://maixhub.com/model/zoo) 中选择`maixcam` 就可以找到。 并且在底层已经封装好的 API，只需要简单的调用就可以实现。 如果你想训练自己的模型，也可以先从[MaixHub 在线训练](https://maixhub.com/model/training/project) 开始，在线平台只需要点点点就能训练出模型，不需要购买昂贵的机器，不需要搭建复杂的开发环境，也不需要写代码，非常适合入门，也适合懒得翻代码的老手。 一般训练得到了模型文件，直接传输到设备上，调用 MaixPy 的 API 就可以使用了，具体的调用方法看后文。"},"/maixpy/doc/zh/vision/hand_gesture_classification.html":{"title":"MaixCAM MaixPy 基于手部关键点检测结果进行进行手势分类","content":" title: MaixCAM MaixPy 基于手部关键点检测结果进行进行手势分类 ## 简介 由`MaixCAM MaixPy 基于手部关键点检测结果进行进行手势分类`可分类手势。 通过前置 [AI 模型估计手部关键点](./hand_landmarks.html)获取特征，再由 LinearSVC (支持向量机线性分类算法) 提供了自训练分类各种手势的能力。详情位于 `MaixPy/projects/app_hand_gesture_classifier/LinearSVC.py`，使用案例见 app 实现，其位于 `MaixPy/projects/app_hand_gesture_classifier/main.py`。 **用户可自行添加其他任意可区分手势进行训练。** ## 使用 ### 预处理 以下是对 AI 模型估计手部关键点 的原始输出 hand_landmarks 数据结构进行预处理得到待使用特征： ```python def preprocess(hand_landmarks, is_left False, boundary (1,1,1)): hand_landmarks np.array(hand_landmarks).reshape((21, 1)) vector hand_landmarks[:,:2] vector vector[1:] vector[0] vector vector.astype('float64') / boundary[:vector.shape[1]] if not is_left: # mirror vector[:,0] * 1 return vector ``` ### 导入模块 也可直接前往该目录 `target_dir` 拷贝 `LinearSVC.py` 实现 ```python # 为了导入 LinearSVC target_dir '/maixapp/apps/hand_gesture_classifier/' import sys if target_dir not in sys.path: sys.path.insert(0, target_dir) from LinearSVC import LinearSVC, LinearSVCManager ``` ### 分类器（LinearSVC） 介绍分类器（LinearSVC）的各项功能和使用方法。 #### 初始化，加载和导出 ```python # 初始化 clf LinearSVC(C 1.0, learning_rate 0.01, max_iter 500) # 加载 clf LinearSVC.load(\"/maixapp/apps/hand_gesture_classifier/clf_dump.npz\") # 导出 clf.save(\"my_clf_dump.npz\") ``` *初始化方法参数* 1. C 1.0（正则化参数） 控制支持向量机（SVM）的正则化强度。 C 值越大，对误分类的惩罚越高，模型会尝试严格分类每个样本，可能会导致过拟合。 C 值越小，允许一定程度的误分类，提高泛化能力，可能会导致欠拟合。 默认值：1.0，适中的正则化，平衡准确性和泛化能力。 2. learning_rate 0.01（学习率） 控制权重更新的步长大小，即每次梯度下降优化时，参数调整的速度。 学习率过大，可能会导致优化过程无法收敛，甚至发散。 学习率过小，优化过程收敛速度过慢，训练时间较长。 默认值：0.01，通常为适中的学习率，确保模型逐步逼近最优解。 3. max_iter 500（最大迭代次数） 控制训练过程中执行的最大优化轮数。 迭代次数越多，模型有更多机会找到最优解，但过多的迭代可能会导致训练时间过长或过拟合。 如果 max_iter 过小，可能在尚未收敛时就提前停止，导致欠拟合。 默认值：1000，允许模型有足够的训练轮次来收敛。 *加载和导出方法参数* 1. filename: str 目标文件路径，支持相对和绝对路径 必须提供 默认值：无 #### 训练和预测（分类） 分类器初始化后需要进行有效训练才能完成后续分类任务。 若是直接加载先前的训练器备份，即可直接用于分类。 **每次训练都是全量训练，即会丢失先前训练结果。建议：有需要请及时导出当前分类器备份。** ```python npzfile np.load(\"/maixapp/apps/hand_gesture_classifier/trainSets.npz\") # 预加载特征和ID（name_classes 索引） X_train npzfile[\"X\"] # 原始特征 y_train npzfile[\"y\"] # 标签id clf.fit(clf.scaler.fit_transform(X_train), y_train) # 标准化特征后训练SVM # 回归 y_pred clf.predict(clf.scaler.transform(X_train)) # 标准化特征后预测类别 recall_count len(y_train) right_count np.sum(y_pred y_train) print(f\"right/recall {right_count}/{recall_count}, acc: {right_count/recall_count}\") # 预测 X_test X_train[:5] feature_test clf.scaler.transform(X_test) # 标准化特征 # y_pred clf.predict(feature_test) # 预测类别 y_pred, y_conf clf.predict_with_confidence(feature_test) # 预测类别 print(f\"pred: {y_pred}, conf: {y_conf}\") # 对应的类别名 name_classes (\"one\", \"five\", \"fist\", \"ok\", \"heartSingle\", \"yearh\", \"three\", \"four\", \"six\", \"Iloveyou\", \"gun\", \"thumbUp\", \"nine\", \"pink\") ``` 由于每次都是是全量训练，直接使用分类器时，还需要手动维护先前训练的特征和对应标签的存储，才能实现动态增删改分类类别。 为了简化使用并降低额外负担，现封装了 `分类器管理器（LinearSVCManager）`，见下节。 ### 分类器管理器（LinearSVCManager） 介绍分类器管理器（LinearSVCManager）的各项功能和使用方法。 #### 初始化，加载和导出 无论 `初始化` 或 `加载` 都必须提供有效 X，Y（对应特征和标签）输入。 且保证长度相等，元素一一对应，否则会报错。 ```python # 初始化，加载 def __init__(self, clf: LinearSVC LinearSVC(), X None, Y None, pretrained False) # 使用默认参数的 LinearSVC 进行初始化 clfm LinearSVCManager(X X_train, Y y_train) # 使用特定参数的 LinearSVC 进行初始化 clfm LinearSVCManager(LinearSVC(C 1.0, learning_rate 0.01, max_iter 100), X_train, y_train) # 加载必须使用加载的 LinearSVC 并且指定 pretrained True 避免无意义的当场二次训练 # 且需要保证 X_train, y_train 确实是先前用来训练 LinearSVC 的 clfm LinearSVCManager(LinearSVC.load(\"/maixapp/apps/hand_gesture_classifier/clf_dump.npz\"), X_train, y_train, pretrained True) # 导出参数请使用 LinearSVC (clfm.clf) 的 save clfm.clf.save(\"my_clf_dump.npz\") # 导出用于训练的特征和标签 np.savez(\"trainSets.npz\", X X_train, y y_train, ) ``` #### 访问已用于训练的数据 clfm.samples 为一个 python 二元组： 1. clfm.samples[0] 为 `X` 2. clfm.samples[1] 为 `Y` **请不要直接修改，仅供只读访问。否则需手动调用 `clfm.train()` 重新训练。** #### 添加或移除 **添加请确保 X_new 和 y_new 长度相等，且形状对应先前的 X_train 和 y_train。** 皆为 numpy 数组，可自行通过 shape 字段确认。 ```python # 添加 clfm.add(X_new, y_new) # 移除 mask_ge_4 clfm.samples[1] > 4 # 大于等于 4 的掩码 indices_ge_4 np.where(mask_ge_4)[0] clfm.rm(indices_ge_4) ``` 以上操作主要处理 `clfm.samples`，但每次会在结尾调用 `clfm.train()` 再训练。 因此，根据待训练数据规模，等待些许时间后，便可直接应用。 #### 预测 ```python y_pred, y_conf clfm.test(X_test) # 预测类别 ``` 等价于 ```python clf clfm.clf feature_test clf.scaler.transform(X_test) # 标准化特征 y_pred, y_conf clf.predict_with_confidence(feature_test) # 预测类别 ``` #### 示例（效果视频简化版本） 注意： 缺失 preprocess 实现，请从 `预处理` 拷贝过来 缺失 LinearSVC 模块，请从 `导入模块` 拷贝过来 分类预测部分如下，可单文件运行： ```python from maix import camera, display, image, nn, app import numpy as np # 添加在我下面 name_classes (\"one\", \"five\", \"fist\", \"ok\", \"heartSingle\", \"yearh\", \"three\", \"four\", \"six\", \"Iloveyou\", \"gun\", \"thumbUp\", \"nine\", \"pink\") # , \"class N\", \"class N+1\", ...) # 易于理解的标签名 npzfile np.load(\"/maixapp/apps/hand_gesture_classifier/trainSets.npz\") # 预加载特征和ID（name_classes 索引） X_train npzfile[\"X\"] y_train npzfile[\"y\"] clfm LinearSVCManager(LinearSVC.load(\"/maixapp/apps/hand_gesture_classifier/clf_dump.npz\"), X_train, y_train, pretrained True) # 使用预加载分类器初始化 LinearSVCManager detector nn.HandLandmarks(model \"/root/models/hand_landmarks.mud\") cam camera.Camera(320, 224, detector.input_format()) disp display.Display() # Loading screen img cam.read() img.draw_string(100, 112, \"Loading...\\nwait up to 10s\", color image.COLOR_GREEN) disp.show(img) while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.7, iou_th 0.45, conf_th2 0.8) for obj in objs: hand_landmarks preprocess(obj.points[8:8+21*3], obj.class_id 0, (img.width(), img.height(), 1)) # 预处理 features np.array([hand_landmarks.flatten()]) class_idx, pred_conf clfm.test(features) # 获取预测类别 class_idx, pred_conf class_idx[0], pred_conf[0] # 复数输入，复数返回，取第一单元 msg f'{detector.labels[obj.class_id]}: {obj.score:.2f}\\n{name_classes[class_idx]}({class_idx}) {pred_conf*100:.2f}%' img.draw_string(obj.points[0], obj.points[1], msg, color image.COLOR_RED if obj.class_id 0 else image.COLOR_GREEN, scale 1.4, thickness 2) detector.draw_hand(img, obj.class_id, obj.points, 4, 10, box True) disp.show(img) ``` 目前使用的 `X_train` 基于的原始数据集为`14 类静态手势数据集`，[数据集下载地址(百度网盘 Password: 6urr )](https://pan.baidu.com/s/1Sd Ad88Wzp0qjGH6Ngah0g)，其中数据集共 2850 个样本，分为 14 类。   ![](../../assets/handposex_14class.jpg) ## 效果视频 该 app 实现位于 `MaixPy/projects/app_hand_gesture_classifier/main.py`，主要逻辑是 1. 加载 `14 类静态手势数据集` 经 `手部关键点检测` 处理后的 `20` 个相对手腕的坐标偏移 2. 初始训练前 `4` 个分类 **或直接加载预训练的 `14` 分类器参数(源码可切换)**，以支持手势识别 3. 加载 `手部关键点检测` 模型处理摄像头并通过该分类器将结果可视化在屏幕上 4. 点击右上角 `class14` 可增添剩余分类样本再训练以达到 `14` 分类手势 5. 点击右下角 `class4` 可移除上一步添加的分类样本再训练以达到 `4` 分类手势 6. 点击按钮之间的小块区域，可在顶部显示分类器上一次训练的时长 7. 点击其余大块区域，可在左侧显示当前支持的分类类别，绿色表示支持，黄色表示不支持 <video playsinline controls autoplay loop muted preload src \"/static/video/hand_gesture_demo.mp4\" type \"video/mp4\"> Classifier Result video </video> 1. 视频演示内容为执行了上述第 `4` 步 **或第 `2` 步加粗部分**后的 `14` 分类模式，可识别手势 `1 10` （默认对应其他英文释义），ok，大拇指点赞，比心（需要手背，拍摄时不好演示，可自行验证），小拇指伸展 一共 `14` 种手势。 2. 紧接着执行第 `5` 步，回退到 `4` 分类模式，仅可识别 1，5，10（握拳）和 ok，其余的手势都无法识别到正常结果。期间也有执行 第 `7` 步展示了当前是 `4` 分类模式，因为除了前 4 种手势为绿，后 10 种全部为黄色显示。 3. 再就是执行第 `4` 步，恢复到 `14` 分类模式，`4` 分类模式无法识别的手势现在也恢复正确识别了。 4. 末尾展示了双手的识别，实测可同时正确识别两只手的手势。 ## 其它 **效果视频为捕获的 maixvision 右上的屏幕预览窗口而来，和屏幕实际显示内容一致。** **更详细使用方法或二次开发请参考上述分析阅读源码，内附有注释。** 如仍有疑惑或需要协助，可于 `maixhub` 上发帖留言或发 `e mail` 到公司邮箱 `support@sipeed.com`，**标题请使用`[help][MaixPy] guesture classification: xxx`**。"},"/maixpy/doc/zh/vision/classify.html":{"title":"MaixCAM MaixPy 使用 AI 模型进行物体分类","content":" title: MaixCAM MaixPy 使用 AI 模型进行物体分类 ## 物体分类概念 比如眼前有两张图片，一张图里面是苹果，另一张是飞机，物体分类的任务就是把两张图分别依次输入给 AI 模型，模型会依次输出两个结果，一个是苹果，一个是飞机。 ## MaixPy 中使用物体分类 MaixPy 默认提供了 `imagenet` 数据集训练得到的 `1000`分类模型，可以直接使用： ```python from maix import camera, display, image, nn classifier nn.Classifier(model \"/root/models/mobilenetv2.mud\", dual_buff True) cam camera.Camera(classifier.input_width(), classifier.input_height(), classifier.input_format()) disp display.Display() while 1: img cam.read() res classifier.classify(img) max_idx, max_prob res[0] msg f\"{max_prob:5.2f}: {classifier.labels[max_idx]}\" img.draw_string(10, 10, msg, image.COLOR_RED) disp.show(img) ``` 效果视频: <video playsinline controls autoplay loop muted preload src \"/static/video/classifier.mp4\" type \"video/mp4\"> Classifier Result video </video> 这里使用了摄像头拍摄图像，然后传给 `classifier`进行识别，得出结果后，将结果显示在屏幕上。 更多 API 使用参考 [maix.nn](/api/maix/nn.html) 模块的文档。 ## dual_buff 双缓冲区加速 你可能注意到这里模型初始化使用了`dual_buff`（默认值就是 `True`），使能 `dual_buff` 参数可以加快运行效率，提高帧率，具体原理和使用注意点见 [dual_buff 介绍](./dual_buff.html)。 ## 使用 MaixHub 训练自己的分类模型 如果你想训练特定图像的分类模型，请到[MaixHub](https://maixhub.com) 学习并训练分类模型，创建项目时选择`分类模型`，然后上传图片训练即可，无需搭建训练环境也无需花钱购买昂贵的GPU，快速一键训练。 ## 离线训练自己的分类模型 离线训练需要自己搭建环境，请自行搜索 `PyTorch 分类模型训练` `Mobilenet`等相关关键字进行参考。 训练好模型后导出 onnx 格式的模型，然后参考 [MaixCAM 模型转换文档](../ai_model_converter/maixcam.html) 转换为 MaixCAM 支持的模型格式，最后使用上面的`nn.Classifier`类加载模型即可。 这里分类模型可以是 mobilenet 也可以是 其它模型比如 Resnet 等，模型转换时最好提取 `softmax`前一层作为最后的输出层，因为`classifier.classify(img, softmax True)` 识别函数的`softmax`参数默认为`True`，即会对结果计算一次`softmax`，所以模型就不用`softmax`这一层了，当然如果模型包含了`softmax`层，也可以指定不再执行一遍`softmax`： `classifier.classify(img, softmax False)`。"},"/maixpy/doc/zh/vision/find_blobs.html":{"title":"MaixCAM MaixPy 寻找色块","content":" title: MaixCAM MaixPy 寻找色块 update: date: 2024 04 03 author: neucrack version: 1.0.0 content: 初版文档 date: 2024 04 03 author: lxowalle version: 1.0.1 content: 添加寻找色块的详细用法 阅读本文前，确保已经知晓如何开发MaixCAM，详情请阅读[快速开始](../index.html) ## 简介 本文将介绍如何使用MaixPy来寻找色块，以及如何使用MaixCam的默认应用程序寻找色块。 在视觉应用中，寻找色块是一个非常常见的需求，比如机器人找色块，自动化生产线找色块等等，即需要识别画面中的特定的颜色区域，获取这个区域的位置和大小等信息。 ## 使用 MaixPy 寻找色块 MaixPy的 `maix.image.Image`中提供了`find_blobs`方法，可以方便的找色块。 ### 如何寻找色块 一个简单的示例，实现寻找色块并画框 ```python from maix import image, camera, display cam camera.Camera(320, 240) disp display.Display() # 根据色块颜色选择对应配置 thresholds [[0, 80, 40, 80, 10, 80]] # red # thresholds [[0, 80, 120, 10, 0, 30]] # green # thresholds [[0, 80, 30, 100, 120, 60]] # blue while 1: img cam.read() blobs img.find_blobs(thresholds, pixels_threshold 500) for blob in blobs: img.draw_rect(blob[0], blob[1], blob[2], blob[3], image.COLOR_GREEN) disp.show(img) ``` 步骤： 1. 导入image、camera、display模块 ```python from maix import image, camera, display ``` 2. 初始化摄像头和显示 ```python cam camera.Camera(320, 240)\t# 初始化摄像头，输出分辨率320x240 RGB格式 disp display.Display() ``` 3. 从摄像头获取图片并显示 ```python while 1: img cam.read() disp.show(img) ``` 4. 调用`find_blobs`方法寻找摄像头图片中的色块，并画到屏幕上 ```python blobs img.find_blobs(thresholds, pixels_threshold 500) for blob in blobs: img.draw_rect(blob[0], blob[1], blob[2], blob[3], image.COLOR_GREEN) ``` `img`是通过`cam.read()`读取到的摄像头图像，当初始化的方式为`cam camera.Camera(320, 240)`时，`img`对象是一张分辨率为320x240的RGB图。 `img.find_blobs`用来寻找色块， `thresholds` 是一个颜色阈值列表，每个元素是一个颜色阈值，同时找到多个阈值就传入多个，每个颜色阈值的格式为 `[L_MIN, L_MAX, A_MIN, A_MAX, B_MIN, B_MAX]`，这里的 `L`、`A`、`B` 是`LAB`颜色空间的三个通道，`L` 通道是亮度，`A` 通道是红绿通道，`B` 通道是蓝黄通道。`pixels_threshold`是一个像素点数量的阈值，用来过滤一些不需要的小色块。 `img.draw_rect`用来画色块框，`blob[0]`、`blob[1]`、`blob[2]`、`blob[3]`分别代表色块左上角坐标x，色块左上角坐标y，色块宽度w和色块高度h ### 常用参数说明 列举常用参数说明，如果没有找到可以实现应用的参数，则需要考虑是否使用其他算法实现，或者基于目前算法的结果扩展所需的功能 参数 说明 示例 thresholds 基于lab颜色空间的阈值，threshold [[l_min, l_max, a_min, a_max, b_min, b_max]]，分别表示：<br />亮度范围为[l_min, l_max]\\<br />绿色到红色的分量范围为[a_min, a_max]<br />蓝色到黄色的分量范围为[b_min, b_max]<br />可同时设置多个阈值 设置两个阈值来检测红色和绿色<br />```img.find_blobs(threshold [[0, 80, 40, 80, 10, 80], [0, 80, 120, 10, 0, 30]])```<br />红色阈值为[0, 80, 40, 80, 10, 80]<br />绿色阈值为[0, 80, 120, 10, 0, 30] invert 使能阈值反转，使能后传入阈值与实际阈值相反，默认为False 使能阈值反转<br />```img.find_blobs(invert True)``` roi 设置算法计算的矩形区域，roi [x, y, w, h]，x，y表示矩形区域左上角坐标，w，h表示矩形区域的宽度和高度，默认为整张图片 计算坐标为(50,50)，宽和高为100的区域<br />```img.find_blobs(roi [50, 50, 100, 100])``` area_threshold 过滤像素面积小于area_threshold的色块，单位为像素点，默认为10。该参数可用于过滤一些无用的小色块 过滤面积小于1000的色块<br />```img.find_blobs(area_threshold 1000)``` pixels_threshold 过滤有效像素点小于pixels_threshold的色块，默认为10。该参数可用于过滤一些无用的小色块 过滤有效像素点小于1000的色块<br />```img.find_blobs(pixels_threshold 1000)``` 本文介绍常用方法，更多 API 请看 API 文档的 [image](../../../api/maix/image.html) 部分。 ## 离线设置阈值 为了快速验证寻找色块的功能，可以先使用MaixCam提供的寻找色块应用程序来体验寻找色块的效果。 ### 演示 打开设备，选择`找色块`应用，然后在下方选择要识别的颜色，或者自定义颜色，即可以识别到对应的颜色了，在下方`设置栏`会显示当前设置的`阈值范围`，同时串口也会输出识别到的坐标和颜色信息。 <video src \"/static/video/find_blobs.mp4\" controls \"controls\" width \"100%\" height \"auto\"></video> [源码地址](https://github.com/sipeed/MaixCDK/tree/main/projects/app_find_blobs) ### 快速使用 #### 使用默认阈值 寻找色块APP提供了`red`、`green`、`blue`、`user`四种配置，其中`red`、`green`和`blue`用来寻找`红色`、`绿色`和`蓝色`的色块，`user`自定义的阈值在程序退出时会保存下来，下次打开应用时会加载上一次调试的阈值。快速体验时通过`点击`界面下方`按钮`即可切换到对应配置，APP界面参考如下： ![](../../../static/image/find_blobs_app.jpg) #### 快速调试阈值 操作方法： 1. 将`摄像头对准`需要`寻找的物体`，`点击`屏幕上的`目标物体`，此时`左侧`会显示该物体对应颜色的`矩形框`，并显示该物体颜色的LAB值。 2. 点击出现的`矩形框`，系统将会`自动设置`LAB阈值，此时画面将会画出该物体边缘。 这个方法优点是方便，快捷，可以很快的设置阈值并找到对应的色块。缺点是还不够精确，可以在下一步中手动微调。 #### 手动微调阈值 操作方法： 1. `点击`左下角`选项图标`，进入配置模式 2. 将`摄像头对准`需要`寻找的物体`，`点击`屏幕上的`目标物体`，此时`左侧`会显示该物体对应颜色的`矩形框`，并显示该物体颜色的`LAB值`。 3. 点击下方选项`L Min，L Max，A Min，A Max，B Min，B Max`，点击后右侧会出现滑动条来设置该选项值。这些值分别对应LAB颜色格式的L通道、A通道和B通道的最小值和最大值 4. 参考步骤2计算的物体颜色的`LAB值`，将`L Min，L Max，A Min，A Max，B Min，B Max`调整到合适的值，即可识别到对应的色块。 例如`LAB (20, 50, 80)`，由于`L 20`，为了适配一定范围让`L Min 10`，`L Max 30`;同理，由于`A 50`，让`A Min 40`，`A Max 60`; 由于`B 80`，让`B Min 70`，`B Max 90`。 这个方法可以更精确的找到合适的阈值，搭配`快速调试阈值`的方法，轻松找到想要的阈值。 #### 通过串口协议获取识别结果 寻找色块APP支持通过串口（默认波特率为115200）上报检测到的色块信息。 由于上报信息只有一条，这里直接用示例来说明上报信息的内容。 例如上报信息为： ```shell AA CA AC BB 14 00 00 00 E1 08 EE 00 37 00 15 01 F7 FF 4E 01 19 00 27 01 5A 00 A7 20 ``` `AA CA AC BB`：协议头部，内容固定 `14 00 00 00`：数据长度，除了协议头部和数据长度外的总长度 `E1`：标志位，用来标识串口消息标志 `08`：命令类型，对于寻找色块APP应用该值固定为0x08 `EE 00 37 00 15 01 F7 FF 4E 01 19 00 27 01 5A 00`：已找到色块的四个顶点坐标，每个值用小端格式的2字节表示。`EE 00`和`37 00`表示第一个顶点坐标为(238, 55)，`15 01`和`F7 FF`表示第二个顶点坐标为(277, 9)，`4E 01`和`19 00`表示第三个顶点坐标为(334, 25)，`27 01`和`5A 00`表示第四个顶点坐标为(295, 90)。 `A7 20`：CRC 校验值，用以校验帧数据在传输过程中是否出错 ## 关于LAB颜色空间 LAB颜色空间和RGB颜色空间一样是一种表示颜色的方法，LAB可以表示人眼能看到的所有颜色。如果需要了解LAB可以去网络上搜索相关文章，那样更详细，而对于你应该只需要了解为什么选用LAB对于MaixPy的优势。 LAB对于MaixPy的优势： 1. LAB颜色空间的色域比RGB都要大，因此完全可以替换RGB。 2. LAB颜色空间下，由于L通道是亮度通道，我们常常设置到较大的范围即可（常用[0,80]），而编写代码时主要关注是A通道和B通道，这样可以减少大量的时间在纠结颜色阈值如何选择的问题上。 3. LAB颜色空间的颜色感知更均匀，更容易用代码调试。例如，对于只需要寻找红色色块，可以固定L通道和B通道值，只需要调整A通道的值即可（这是在颜色精度要求不高的情况下）;如果是RGB通道则基本需要R、G、B三个通道同时变动才能找到合适的阈值。"},"/maixpy/doc/zh/vision/depth_anything.html":{"title":"MaixCAM2 MaixPy 使用 Depth-Anything 单目估计深度距离","content":" title: MaixCAM2 MaixPy 使用 Depth Anything 单目估计深度距离 update: date: 2025 06 09 version: v1.0 author: neucrack content: 增加 Depth Anything V2 代码和文档支持 ## 简介 [Depth Anything V2](https://github.com/DepthAnything/Depth Anything V2) 可以将普通图片估计得到深度图，而且相较于 Depth Anything V1 在细节方面有所提升，以及一些材质上的优化比如玻璃，具体介绍可以看[官方开源仓库](https://github.com/DepthAnything/Depth Anything V2)或者[Web主页](https://depth anything v2.github.io/)。 <video playsinline controls autoplay loop muted preload src \"../../assets/depth_anything_v2.mp4\" type \"video/mp4\" style \"min height:0\"> depth_anything_v2.mp4 </video> ## 支持的设备 设备 是否支持 MaixCAM2 ✅ MaixCAM ❌ ## 在 MaixCAM2 MaixPy 上使用 Depth Anything MaixPy 支持 Depth Anything V2，注意 MaixCAM 一代硬件不支持。 默认系统已经内置了模型，直接运行代码即可： ```python from maix import camera, display, image, nn, app cmap image.CMap.TURBO model nn.DepthAnything(model \"/root/models/depth_anything_v2_vits.mud\", dual_buff True) cam camera.Camera(model.input_width(), model.input_height(), model.input_format()) disp display.Display() while not app.need_exit(): img cam.read() res model.get_depth_image(img, image.Fit.FIT_CONTAIN, cmap) if res: disp.show(res) ``` 这里通过`get_depth_image` 直接获得一张伪彩色图像，`cmap`可以指定为彩色，支持的所有伪彩色可以看`maix.image.CMap` API 文档。 当然，如果你想要模型原始输出，也可以用`get_depth`方法获取 `float32` 类型的原始数据，可以将返回的数据通过`maix.tensor.tensor_to_numpy_float32`转换为`numpy`格式使用。 MaixCAM2 实机运行效果： ![](../../assets/depth_anything_v2_maixcam2.jpg) ## 注意点 注意 Depth Anything V2 是针对图片进行深度估计，输出原始数据是一个相对值，值范围会根据图像内容变化，比如 深度差距不大时为 0.0~2.0, 图像内容深度变化大时为 0.0~8.0，最后转为图片标准化值到 0～255。 所以对于视频和连续的图像帧来说，深度绝对值会变动，也就是你会看到的当用摄像头图像进行连续深度估计时输出图像会有轻微的闪动。 ## 更多输入分辨率 由于模型需要的算力比较大，默认采用的分辨率为 448x336, 如果你期望使用其它分辨率，可以到[MaixHub 模型库](https://maixhub.com/model/zoo?platform maixcam2)下载现有的其它分辨率的，如果 MaixHub 也没有你要的分辨率，可以自己转换模型。 对于 MaixCAM2，转换模型 参考[模型量化文档](../ai_model_converter/maixcam2.html) 以及 [huggingface.co/AXERA TECH/Depth Anything V2](https://huggingface.co/AXERA TECH/Depth Anything V2/tree/main) 和 [github.com/AXERA TECH/DepthAnythingV2.axera](https://github.com/AXERA TECH/DepthAnythingV2.axera)（注意 这个工程里 config.json 中输入是 BGR，建议改成MaixPy 默认使用的 RGB）。"},"/maixpy/doc/zh/vision/hand_landmarks.html":{"title":"MaixPy MaixCAM 人手部 21 个关键点三维坐标检测","content":" title: MaixPy MaixCAM 人手部 21 个关键点三维坐标检测 update: date: 2024 12 31 version: v1.0 author: neucrack content: 添加源码、模型、例程和文档 ## 简介 在一些应用中我们需要检测手的位置，或者手的姿态时，可以使用本算法，此算法可以检测到： * 手的位置，提供四个顶点坐标。 * 手的 21 个关键点坐标，以及每个点相对手掌的深度估计。 应用举例： * 点读机 * 手势控制 * 手指类游戏 * 手语转译 * 施魔法 效果图如下： <img src \"../../assets/hands_landmarks.jpg\" style \"max height:24rem\"> 效果视频： <video playsinline controls autoplay loop muted preload src \"/static/video/hands_landmarks.mp4\" type \"video/mp4\"> Classifier Result video </video> 21 个关键点包括： ![](../../assets/hand_landmarks_doc.jpg) ## MaixPy MaixCAM 中使用手关键点检测 在 **MaixPy** 中已经内置了该算法(移植于 mediapipe，有兴趣可自行学习)，可以方便地使用（**固件版本必须 > 4.9.3**)，此例程也可以在[MaixPy/examples](https://github.com/sipeed/maixpy)目录中找到： ```python from maix import camera, display, image, nn, app detector nn.HandLandmarks(model \"/root/models/hand_landmarks.mud\") # detector nn.HandLandmarks(model \"/root/models/hand_landmarks_bf16.mud\") landmarks_rel False cam camera.Camera(320, 224, detector.input_format()) disp display.Display() while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.7, iou_th 0.45, conf_th2 0.8, landmarks_rel landmarks_rel) for obj in objs: # img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) msg f'{detector.labels[obj.class_id]}: {obj.score:.2f}' img.draw_string(obj.points[0], obj.points[1], msg, color image.COLOR_RED if obj.class_id 0 else image.COLOR_GREEN, scale 1.4, thickness 2) detector.draw_hand(img, obj.class_id, obj.points, 4, 10, box True) if landmarks_rel: img.draw_rect(0, 0, detector.input_width(detect False), detector.input_height(detect False), color image.COLOR_YELLOW) for i in range(21): x obj.points[8 + 21*3 + i * 2] y obj.points[8 + 21** + i * 2 + 1] img.draw_circle(x, y, 3, color image.COLOR_YELLOW) disp.show(img) ``` 检测的结果用了`draw_hand`这个函数来画，你可以从`obj.points`得到所有关键点信息，一共`4 + 21`个点，格式为： * 前 4 个点是手外框的四个角坐标，从左上角开始，逆时针4个点，`topleft_x, topleft_y, topright_x, topright_y, bottomright_x, bottomright_y， bottomleft_x, bottomleft_y`，注意值可能会小于0. * 后 21 个点是手部的关键点，如简介中所说的顺序，格式：`x0, y0, z0, x1, y1, z1, ..., x20, y20, z20`，其中 `z`为相对于手掌的深度信息。注意值可能会小于 0。 另外`obj`的`x, y, w, h, angle` 属性也可以直接使用，分别代表了旋转前的框坐标和大小，以及旋转角度（0到360度）。 **精度优化**：这里使用了`nn.HandLandmarks`这个类来进行检测，默认用了`int8`量化的模型，速度会更快，如果需要更高的精度可以更换为`hand_landmarks_bf16.mud`这个模型。 **得到相对于手左上角顶点的关键点坐标**：你可以选择得到相对于手左上角顶点的关键点坐标值，值范围为 `0` 到 手框宽度(`obj.w`)，方法： ```python objs detector.detect(img, conf_th 0.7, iou_th 0.45, conf_th2 0.8, landmarks_rel True) ``` 这里`landmarks_rel` 参数就是告诉这个函数输出`21`个点相对于手左上角顶点的相对坐标，在`obj.points`最后`21x2`个值`x0y0x1y1..x20y20`排列。 ## 进阶：基于关键点检测实现手姿态识别 举个例子，比如我们要实现检测石头剪刀布检测，有两种方法： * 方法1： 直接根据关键点进行判断，使用代码判断手的形状，比如手指张开，手掌朝上，手掌朝下等等。 * 方法2： 使用 AI 模型进行分类。 方法1是传统的方法，简单快速，在简单的手势判断比较稳定，这里主要说`方法2`: 方法2 即用训练一个分类模型来对手势分类，不过可能需要大量图片和背景来训练，我们在此有两个优化方案： 1. 使用检测手的模型比如 YOLO11 先检测手，再裁切出只有手的部分，再训练分类模型，这样分类模型的输入只有手部分，减少了干扰。 2. 使用手关键点检测，得到关键点数据，用这 21 个关键点数据作为分类模型的输入进行分类，这样直接没有了背景信息，更加准确！ 所以这里主要采用的就是思路 `2`，将关键点信息作为分类模型的输入，因为没有图片背景信息干扰，只需要采集比较少量的数据就能达到比较好的效果。 步骤： * 确定分类的手势，比如石头剪刀布三个分类。 * 修改上面的代码，比如点击屏幕一下就记录下当前手的关键点信息到文件系统存起来。 * 修改上面的代码，为了让分类模型输入更统一，你可以选择得到相对于手左上顶点的关键点坐标值，值范围为 `0` 到 手框宽度(`obj.w`)，参考上面`landmarks_rel`参数。 * 分别采集这几个分类的数据。 * 在电脑上创建一个分类模型，比如基于 mobilenetv2 的分类模型，使用 pytorch 进行训练，实际输入还可以将坐标都归一化到[0, 1]。 * 分类模型训练完成后[导出成 MaixCAM 支持的格式](../ai_model_converter/maixcam.html)（量化数据需要先打包成`npz`格式）。 * 在 MaixPy 中检测手之后，得到关键点再运行分类模型进行得到结果，代码可以参考例程中的`nn_forward.py` 和 `nn_custom_classifier.py`。 这样就可以以很少的训练数据训练不同手势了，这种方式要求你会训练分类模型，以及量化转换模型格式。 ## 进阶：基于关键点检测实现手姿态识别之 模型训练简易版本 上面的方法需要你会自己使用 pytorch 修改训练模型，以及量化转模型格式比较麻烦。 这里提供另外一种简单很多的曲线救国的方式，无需自己搭建环境训练和模型转换： * 同上一个方法获取手相对于手左上角顶点的坐标。 * 基于这些点生成一幅图，不同的点可以用不同的颜色，具体请自行思考和尝试生成什么样的图比较好。 * 将生成的图片上传到[MaixHub.com](https://maixhub.com) 创建分类模型项目，在线训练，选择 MaixCAM 平台。 * 一键训练，完成后得到模型，后台会自动训练并转换成 MaixCAM 支持的格式。 * 修改例程，识别到关键点后，按照同样的方法生成图片，然后传给你训练的分类模型进行识别得到结果。 ## 进阶：基于关键点检测实现手动作识别之 复杂动作 上面的是简单的动作，是单张图片识别，如果想时间轴维度上识别，比如识别画圆圈动作： * 一种方法是把历史关键点存在队列中，根据队列中的关键点数据用代码来判断动作。 * 另外一种是将历史关键点作为一个序列输入到分类模型中，这样分类模型就可以识别时间轴上的动作了。 * 还可以将历史关键点合成一张图片给分类模型也可以。"},"/maixpy/doc/zh/vision/ocr.html":{"title":"MaixCAM MaixPy 实现 OCR 图片文字识别","content":" title: MaixCAM MaixPy 实现 OCR 图片文字识别 ## OCR 简介 OCR（Optical Character Recognition，光学字符识别）即用视觉的方式识别图像中的文字。 在很多场景会用到，比如： * 识别文字/数字卡片 * 提取卡片上的文字，比如身份证 * 电子化纸质文档 * 数显数字读取，可用于抄表、旧仪器数据电子化等 * 车牌文字识别 ## MaixPy 中使用 OCR MaixPy 移植了 [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR), 是由百度开源的一款 OCR 算法，想了解原理可以看这个开源项目。 ![OCR](../../assets/ocr.jpg) **首先保证 MaixPy 版本 > 4.6**。 然后执行代码：(完整的最新的代码在[MaixPy 仓库](https://github.com/sipeed/MaixPy/blob/main/examples/vision/ai_vision/nn_pp_ocr.py)，以源码为准) ```python from maix import camera, display, image, nn, app model \"/root/models/pp_ocr.mud\" ocr nn.PP_OCR(model) cam camera.Camera(ocr.input_width(), ocr.input_height(), ocr.input_format()) disp display.Display() image.load_font(\"ppocr\", \"/maixapp/share/font/ppocr_keys_v1.ttf\", size 20) image.set_default_font(\"ppocr\") while not app.need_exit(): img cam.read() objs ocr.detect(img) for obj in objs: points obj.box.to_list() img.draw_keypoints(points, image.COLOR_RED, 4, 1, 1) img.draw_string(obj.box.x4, obj.box.y4, obj.char_str(), image.COLOR_RED) disp.show(img) ``` 可以看到用了`ocr nn.PP_OCR(model)` 加载模型，然后用`ocr.detect(img)` 检测并且识别文字得到结果画在了屏幕上。 ## 更多模型选择 到[MaixHub 模型下载](https://maixhub.com/model/zoo/449) 可以下载到更完整的模型，不同输入分辨率，不同语言，不同的版本（MaixPy 目前默认pp_ocr.mud 模型为 PPOCRv3 检测+v4识别）。 ## 只识别不检测 如果你已经有处理好了的文字图，即一张图中已知文字的四个角坐标，可以不调用`detect`函数，二是只调用`recognize`函数，这样就不会检测而是仅仅识别图片中的文字。 ## 自定义模型 默认模型提供了中文和英文文字检测识别模型，如果你有特殊的需求，比如其它语言，或者只想检测特定的图形不想检测所有类型的文字， 可以到[PaddleOCR 官方模型库](https://paddlepaddle.github.io/PaddleOCR/ppocr/model_list.html) 下载对应的模型然后转换成 MaixCAM 支持的模型格式即可。 这里最复杂的就是将模型转换成 MaixCAM 可用的模型，过程**比较复杂**，需要有基本的 Linux 使用基础以及灵活变通的能力。 * 首先自己使用 PaddleOCR 源码进行训练模型或者下载官方提供的模型，检测模型请选择 PP OCRv3， 因为效果不错的同时速度比 v4 快，识别模型请下载 v4 模型，实测 v3 在 MaixCAM 上量化后效果不理想。 * 然后将模型转成 onnx: ```shell model_path ./models/ch_PP OCRv3_rec_infer paddle2onnx model_dir ${model_path} model_filename inference.pdmodel params_filename inference.pdiparams save_file ${model_path}/inference.onnx opset_version 14 enable_onnx_checker True ``` * 然后按照[onnx转MUD格式的模型文档](../ai_model_converter/maixcam.html) 安装好环境再转换模型，这里在附录提供示例转换脚本。 * 使用 MaixPy 加载运行即可。 ## 附录：模型转换脚本 检测： ```shell #!/bin/bash set e net_name ch_PP_OCRv3_det input_w 320 input_h 224 output_name sigmoid_0.tmp_0 # scale 1/255.0 # \"mean\": [0.485, 0.456, 0.406], # \"std\": [0.229, 0.224, 0.225], # mean: mean * 255 # scale: 1/(std*255) # mean: 123.675, 116.28, 103.53 # scale: 0.01712475, 0.017507, 0.01742919 mkdir p workspace cd workspace # convert to mlir model_transform.py \\ model_name ${net_name} \\ model_def ../${net_name}.onnx \\ input_shapes [[1,3,${input_h},${input_w}]] \\ mean \"123.675,116.28,103.53\" \\ scale \"0.01712475,0.017507,0.01742919\" \\ keep_aspect_ratio \\ pixel_format bgr \\ channel_format nchw \\ output_names \"${output_name}\" \\ test_input ../test_images/test3.jpg \\ test_result ${net_name}_top_outputs.npz \\ tolerance 0.99,0.99 \\ mlir ${net_name}.mlir # export bf16 model # not use quant_input, use float32 for easy coding model_deploy.py \\ mlir ${net_name}.mlir \\ quantize BF16 \\ processor cv181x \\ test_input ${net_name}_in_f32.npz \\ test_reference ${net_name}_top_outputs.npz \\ model ${net_name}_bf16.cvimodel echo \"calibrate for int8 model\" # export int8 model run_calibration.py ${net_name}.mlir \\ dataset ../images \\ input_num 200 \\ o ${net_name}_cali_table echo \"convert to int8 model\" # export int8 model # add quant_input, use int8 for faster processing in maix.nn.NN.forward_image model_deploy.py \\ mlir ${net_name}.mlir \\ quantize INT8 \\ quant_input \\ calibration_table ${net_name}_cali_table \\ processor cv181x \\ test_input ${net_name}_in_f32.npz \\ test_reference ${net_name}_top_outputs.npz \\ tolerance 0.9,0.5 \\ model ${net_name}_int8.cvimodel ``` 识别: ```shell #!/bin/bash set e # net_name ch_PP_OCRv4_rec # output_name softmax_11.tmp_0 net_name ch_PP_OCRv3_rec_infer_sophgo output_name softmax_5.tmp_0 input_w 320 input_h 48 cali_images ../images_crop_320 # scale 1/255.0 # \"mean\": [0.5, 0.5, 0.5], # \"std\": [0.5, 0.5, 0.5], # mean: mean * 255 # scale: 1/(std*255) # mean: 127.5,127.5,127.5 # scale: 0.00784313725490196,0.00784313725490196,0.00784313725490196 mkdir p workspace cd workspace # convert to mlir model_transform.py \\ model_name ${net_name} \\ model_def ../${net_name}.onnx \\ input_shapes [[1,3,${input_h},${input_w}]] \\ mean \"127.5,127.5,127.5\" \\ scale \"0.00784313725490196,0.00784313725490196,0.00784313725490196\" \\ keep_aspect_ratio \\ pixel_format bgr \\ channel_format nchw \\ output_names \"${output_name}\" \\ test_input ../test_images/test3.jpg \\ test_result ${net_name}_top_outputs.npz \\ tolerance 0.99,0.99 \\ mlir ${net_name}.mlir # export bf16 model # not use quant_input, use float32 for easy coding model_deploy.py \\ mlir ${net_name}.mlir \\ quantize BF16 \\ processor cv181x \\ test_input ${net_name}_in_f32.npz \\ test_reference ${net_name}_top_outputs.npz \\ model ${net_name}_bf16.cvimodel echo \"calibrate for int8 model\" # export int8 model run_calibration.py ${net_name}.mlir \\ dataset $cali_images \\ input_num 200 \\ o ${net_name}_cali_table echo \"convert to int8 model\" # export int8 model # add quant_input, use int8 for faster processing in maix.nn.NN.forward_image model_deploy.py \\ mlir ${net_name}.mlir \\ quantize INT8 \\ quant_input \\ calibration_table ${net_name}_cali_table \\ processor cv181x \\ test_input ${net_name}_in_f32.npz \\ test_reference ${net_name}_top_outputs.npz \\ tolerance 0.9,0.5 \\ model ${net_name}_int8.cvimodel ```"},"/maixpy/doc/zh/vision/display.html":{"title":"MaixCAM MaixPy 屏幕使用","content":" title: MaixCAM MaixPy 屏幕使用 update: date: 2024 03 31 author: neucrack version: 1.0.0 content: 初版文档 ## 简介 MaixPy 提供了`display`模块，可以将图像显示到屏幕上，同时，也可以将图像发送到 MaixVision 显示，方便调试和开发。 ## API 文档 本文介绍常用方法，更多 API 请看 API 文档的 [display](/api/maix/display.html) 部分。 ## 使用屏幕 * 导入`display`模块： ```python from maix import display ``` * 创建一个`Display`对象： ```python disp display.Display() ``` * 显示图像： ```python disp.show(img) ``` 这里`img`对象是`maix.image.Image`对象，可以通过`camera`模块的`read`方法获取，也可以通过`image`模块的`load`方法加载文件系统中的图像，也可以通过`image`模块的`Image`类创建一个空白图像。 比如： ```python from maix import image, display disp display.Display() img image.load(\"/root/dog.jpg\") disp.show(img) ``` 这里需要先把`dog.jpg`文件传到设备的`/root`目录下。 显示文字： ```python from maix import image, display disp display.Display() img image.Image(320, 240) img.draw_rect(0, 0, disp.width(), disp.height(), color image.Color.from_rgb(255, 0, 0), thickness 1) img.draw_rect(10, 10, 100, 100, color image.Color.from_rgb(255, 0, 0)) img.draw_string(10, 10, \"Hello MaixPy!\", color image.Color.from_rgb(255, 255, 255)) disp.show(img) ``` 从摄像头读取图像并显示： ```python from maix import camera, display, app disp display.Display() cam camera.Camera(320, 240) while not app.need_exit(): img cam.read() disp.show(img) ``` > 这里用了一个`while not app.need_exit():` 是方便程序在其它地方调用`app.set_exit_flag()`方法后退出循环。 ## 调整背光亮度 在系统的`设置`应用中可以手动调整背光亮度，如果你想在程序中调整背光亮度，可以使用`set_backlight`方法，参数就是亮度百分比，取值范围是 0 100： ```python disp.set_backlight(50) ``` 注意，程序退出回到应用选择界面后会自动恢复到系统设置的背光亮度。 > 如果亮度设置到 `100%` 仍然觉得暗，可以尝试修改`/boot/board`文件中的`disp_max_backlight 50`选项为更大的值，当`disp_max_backlight 100`并且`disp.set_backlight(100)`时硬件上背光控制引脚输出`100%`占空比即高电平。即最终输出到硬件的占空比 `set_backlight 设置值` * `disp_max_backlight`。 > **注意**，修改最大亮度限制会带来功耗和发热量的上升，按照自己实际需求合理设置，不要盲目追求拉满亮度。 ## 显示到 MaixVision 在使用 MaixVision 运行代码时，能够将图像显示到 MaixVision 上，方便调试和开发。 在调用`show`方法时，会自动压缩图像并发送到 MaixVision 显示。 当然，如果你没有屏幕，或者为了节省内存不想初始化屏幕，也可以直接调用`maix.dispaly`对象的`send_to_maixvision`方法发送图像到 MaixVision 显示。 ```python from maix import image,display img image.Image(320, 240) disp display.Display() img.draw_rect(0, 0, img.width(), img.height(), color image.Color.from_rgb(255, 0, 0), thickness 1) img.draw_rect(10, 10, 100, 100, color image.Color.from_rgb(255, 0, 0)) img.draw_string(10, 10, \"Hello MaixPy!\", color image.Color.from_rgb(255, 255, 255)) display.send_to_maixvision(img) ``` ## 更换其它型号屏幕 如果想换不同尺寸的屏幕，可以到[商城](https://wiki.sipeed.com/store)咨询购买。 对于 MaixCAM，目前支持 4 款屏幕和 1 款 MIPI 转 HDMI 模块： * 2.3寸 552x368 分辨率电容触摸屏： MaixCAM 带的屏幕。 * 2.4寸 640x480 分辨率电容触摸屏： MaixCAM Pro 带的屏幕。 * 5寸 854x480 分辨率无触摸屏： 注意无触摸，类似手机屏幕大小。 * 7寸 1280x800 分辨率电容触摸屏：7寸大屏，适合更多需要固定屏幕观看场景。 * LT9611（MIPI转HDMI模块） 支持1280x720等多种分辨率，适合驱动各种HDMI屏。 不同屏幕的刷新图像时间差别在1～5毫秒，差别不是很大，主要的区别在于图像分辨率大了图像处理时间的差别。 更换屏幕需要同时**修改配置文件**，否则可能刷新时序不同会**导致烧屏**（屏幕留下显示过的影子），所以需要注意，最好严格按照下面的步骤操作，如果出现了烧屏的问题也不要紧张，断电放置一晚上一般会恢复。 * 按照烧录系统的文档烧录系统，烧录完成后会有 U 盘出现。 * 打开 U 盘内容，看到有一个 `board` 文件。 * 编辑`board`文件，修改`pannel`键值，取值如下： * 2.3寸（MaixCAM 自带屏幕）：`st7701_hd228001c31`。 * 2.4寸（MaixCAM Pro 自带屏幕）： `st7701_lct024bsi20`。 * 5寸：`st7701_dxq5d0019_V0` 早期（2023年）测试屏幕`st7701_dxq5d0019b480854`。 * 7寸：`mtd700920b`，早期（2023年）测试屏幕用 `zct2133v1`。 * LT9611（MIPI转HDMI模块）： * 接线： * LT9611 I2C < > MaixCAM I2C5 * LT9611 MIPI IN < > MaixCAM MIPI OUT * 支持的配置 * `lt9611_1280x720_60hz`: 1280x720 60Hz * `lt9611_1024x768_60hz`: 1024x768 60Hz * `lt9611_640x480_60hz`: 640x480 60Hz * `lt9611_552x368_60hz`: 552x368 60Hz * 保存`board`，并且**点击弹出 U 盘**，不要直接断电，否则可能文件丢失。 * 按下板子的`reset`按键，或者重新上电启动。 以上的方式最保险，保证上电前已经设置好了屏幕型号，如果你已经烧录好系统了，也可以修改系统的`/boot/board`文件然后重启。 > 早期的系统和二进制应用(< 2024.11.25)依赖的是`uEnv.txt`里面的`panel`键值，如果系统和应用比较老旧，修改了`board` 也可以同时将`uEnv.txt`中一同修改。"},"/maixpy/doc/zh/vision/object_track.html":{"title":"MaixCAM MaixPy 物体轨迹追踪和计数（如人流计数）","content":" title: MaixCAM MaixPy 物体轨迹追踪和计数（如人流计数） ## 轨迹追踪简介 前面我们使用 YOLOv5 YOLOv8 甚至是 find_blobs 都可以检测到物体，但是如果画面中同时存在多个物体，当我们需要区分每一个物体，就需要物体追踪功能了。 比如画面中同时有 5 个人在移动，我们需要给每个人编号，知道他们的行动轨迹。 应用： * 人流计数，比如通过某个地段的人数量。 * 工件计数，比如流水线对生产的产品进行计数。 * 物体移动轨迹记录和识别。 ## MaixCAM/MaixPy 物体追踪和人流计数效果 效果如下视频，可以跟踪每个人，以及对从上往下跨越黄色区域的人进行计数（左下角）： <video playsinline controls autoplay loop muted preload src \"/static/video/tracker.mp4\" style \"width: 100%; min height: 20em;\"></video> ## MaixCAM / MaixPy 使用 物体追踪和人流计数 可以参考直接安装[应用](https://maixhub.com/app/61) 体验。 可以看[examples/vision/tracker 下的例程](https://github.com/sipeed/MaixPy/tree/main/examples/vision/tracker)。 其中`tracker_bytetrack.py` 例程是基本的物体跟踪例程，分为几个步骤： * 使用 YOLOv5 或者 YOLOv8 检测物体，这样你就可以根据你自己要检测的物体更换模型即可检测不同物体。 * 使用`maix.tracker.ByteTracker` 这个算法进行物体追踪，只需要调用一个`update`函数即可得到结果（画面中的每个轨迹），十分简单。 其中有几个参数根据自己的实际场景进行调整，具体参数以例程代码和 API 参数说明为准： ```python # configs conf_threshold 0.3 # detect threshold iou_threshold 0.45 # detect iou threshold max_lost_buff_time 120 # the frames for keep lost tracks. track_thresh 0.4 # tracking confidence threshold. high_thresh 0.6 # threshold to add to new track. match_thresh 0.8 # matching threshold for tracking, e.g. one object in two frame iou < match_thresh we think they are the same obj. max_history_num 5 # max tack's position history length. show_detect False # show detect valid_class_id [0] # we used classes index in detect model。 ``` `tracker_bytetrack_count.py` 例程则增加了人流计数例程，这里为了让例程更加简单，只简单地写了一个判断人从上往下走的计数，即当人处在黄色区域以下，同时轨迹在黄色区域内就认为是从上往下跨越了黄色区域。 实际在你的应用场景可以自己编写相关逻辑。"},"/maixpy/doc/zh/vision/line_tracking.html":{"title":"MaixCAM MaixPy 寻找直线","content":" title: MaixCAM MaixPy 寻找直线 update: date: 2024 05 09 author: lxowalle version: 1.0.0 content: 初版文档 阅读本文前，确保已经知晓如何开发MaixCAM，详情请阅读[快速开始](../index.html) ## 简介 在视觉应用中，在巡迹小车、巡线机器人等应用中经常需要寻找线条的功能。本文将介绍: 如何使用MaixPy来实现巡线功能 如何使用MaixCam的默认应用程序巡线 ## 如何使用MaixPy来寻找直线 MaixPy的 `maix.image.Image`中提供了`get_regression`方法来寻找直线 ### 代码示例 一个简单的示例，实现寻找并画出直线 ```python from maix import camera, display, image cam camera.Camera(320, 240) disp display.Display() # thresholds [[0, 80, 40, 80, 10, 80]] # red thresholds [[0, 80, 120, 10, 0, 30]] # green # thresholds [[0, 80, 30, 100, 120, 60]] # blue while 1: img cam.read() lines img.get_regression(thresholds, area_threshold 100) for a in lines: img.draw_line(a.x1(), a.y1(), a.x2(), a.y2(), image.COLOR_GREEN, 2) theta a.theta() rho a.rho() if theta > 90: theta 270 theta else: theta 90 theta img.draw_string(0, 0, \"theta: \" + str(theta) + \", rho: \" + str(rho), image.COLOR_BLUE) disp.show(img) ``` 步骤： 1. 导入image、camera、display模块 ```python from maix import image, camera, display ``` 2. 初始化摄像头和显示 ```python cam camera.Camera(320, 240)\t# 初始化摄像头，输出分辨率320x240 RGB格式 disp display.Display() ``` 3. 从摄像头获取图片并显示 ```python while 1: img cam.read() disp.show(img) ``` 4. 调用`get_regression`方法寻找摄像头图片中的直线，并画到屏幕上 ```python lines img.get_regression(thresholds, area_threshold 100) for a in lines: img.draw_line(a.x1(), a.y1(), a.x2(), a.y2(), image.COLOR_GREEN, 2) theta a.theta() rho a.rho() if theta > 90: theta 270 theta else: theta 90 theta img.draw_string(0, 0, \"theta: \" + str(theta) + \", rho: \" + str(rho), image.COLOR_BLUE) ``` `img`是通过`cam.read()`读取到的摄像头图像，当初始化的方式为`cam camera.Camera(320, 240)`时，`img`对象是一张分辨率为320x240的RGB图。 `img.get_regression`用来寻找直线， `thresholds` 是一个颜色阈值列表，每个元素是一个颜色阈值，同时找到多个阈值就传入多个，每个颜色阈值的格式为 `[L_MIN, L_MAX, A_MIN, A_MAX, B_MIN, B_MAX]`，这里的 `L`、`A`、`B` 是`LAB`颜色空间的三个通道，`L` 通道是亮度，`A` 通道是红绿通道，`B` 通道是蓝黄通道。`pixels_threshold`是一个像素面积的阈值，用来过滤一些不需要直线。 `for a in lines`用来遍历返回的`Line`对象， 其中`a`就是当前的`Line`对象。通常`get_regression`函数只会返回一个`Line`对象，如果需要寻找多条直线，可以尝试使用`find_line`方法 使用`img.draw_line`来画出找到的线条，`a.x1(), a.y1(), a.x2(), a.y2()`分别代表直线两端的坐标 使用`img.draw_string`在左上角显示直线与x轴的夹角， `a.theta()`是直线与y轴的夹角， 这里为了方便理解转换成直线与x轴的夹角`theta`，`a.rho()`是原点与直线的垂线的长度. 5. 通过maixvision运行代码，就可以寻线啦，看看效果吧 ![image 20240509110204007](../../../static/image/line_tracking_demo.jpg) ### 常用参数说明 列举常用参数说明，如果没有找到可以实现应用的参数，则需要考虑是否使用其他算法实现，或者基于目前算法的结果扩展所需的功能 参数 说明 示例 thresholds 基于lab颜色空间的阈值，threshold [[l_min, l_max, a_min, a_max, b_min, b_max]]，分别表示：<br />亮度范围为[l_min, l_max]\\<br />绿色到红色的分量范围为[a_min, a_max]<br />蓝色到黄色的分量范围为[b_min, b_max]<br />可同时设置多个阈值 设置两个阈值来检测红色和绿色<br />```img.find_blobs(threshold [[0, 80, 40, 80, 10, 80], [0, 80, 120, 10, 0, 30]])```<br />红色阈值为[0, 80, 40, 80, 10, 80]<br />绿色阈值为[0, 80, 120, 10, 0, 30] invert 使能阈值反转，使能后传入阈值与实际阈值相反，默认为False 使能阈值反转<br />```img.find_blobs(invert True)``` roi 设置算法计算的矩形区域，roi [x, y, w, h]，x，y表示矩形区域左上角坐标，w，h表示矩形区域的宽度和高度，默认为整张图片 计算坐标为(50,50)，宽和高为100的区域<br />```img.find_blobs(roi [50, 50, 100, 100])``` area_threshold 过滤像素面积小于area_threshold的直线，单位为像素点，默认为10。该参数可用于过滤一些无用的小直线 过滤面积小于1000的直线<br />```img.find_blobs(area_threshold 1000)``` pixels_threshold 过滤有效像素点小于pixels_threshold的直线，默认为10。该参数可用于过滤一些无用的小直线 过滤有效像素点小于1000的直线<br />```img.find_blobs(pixels_threshold 1000)``` 本文介绍常用方法，更多 API 请看 API 文档的 [image](../../../api/maix/image.html) 部分。 ### 提升巡线的速度 这里提供几个提升巡线速度的方法 1. 选择合适的分辨率 越大的分辨率计算速度越慢，可以根据识别距离和精度的要求来选择更合适的分辨率 2. 使用灰度图识别 使用灰度图识别时，算法只会处理一个通道，有更快的识别速度，在颜色单一的环境会很有用。注意此时向`get_regression`传入`thresholds`时，只有`l_min`和`l_max`有效。 获取灰度图的方法： ```python # 方法1 cam camera.Camera(320, 240， image.Format.FMT_GRAYSCALE) # MaixPy v4.2.1后支持 gray_img cam.read()\t\t\t\t\t\t\t\t\t\t# 获取灰度图 # 方法2 cam camera.Camera(320, 240) img cam.read() gray_img img.to_format(image.Format.FMT_GRAYSCALE)\t\t\t# 获取灰度图 ``` ## 如何使用MaixCam的默认应用程序寻找直线 为了快速验证寻找直线的功能，可以先使用MaixCam提供的`line_tracking`应用程序来体验寻找直线的效果。 ### 使用方法 1. 选择并打开`Line tracking`应用 2. 点击屏幕中需要识别的直线，左侧会显示该直线的颜色 3. 点击左侧（界面中`L A B`下方的颜色）需要检测的颜色 4. 此时就可以识别到对应的直线了，同时串口也会输出直线的坐标和角度信息。 ### 演示 <video src \"/static/video/line_tracking_app.mp4\" controls \"controls\" width \"100%\" height \"auto\"></video> ### 进阶操作 #### 手动设置LAB阈值寻找直线 APP提供手动设置LAB阈值来精确的寻找直线 操作方法： 1. `点击`左下角`选项图标`，进入配置模式 2. 将`摄像头对准`需要`寻找的物体`，`点击`屏幕上的`目标直线`，此时界面中`L A B`下方会显示该物体对应颜色的`矩形框`，并显示该物体颜色的`LAB值`。 3. 点击下方选项`L Min，L Max，A Min，A Max，B Min，B Max`，点击后右侧会出现滑动条来设置该选项值。这些值分别对应LAB颜色格式的L通道、A通道和B通道的最小值和最大值 4. 参考步骤2计算的物体颜色的`LAB值`，将`L Min，L Max，A Min，A Max，B Min，B Max`调整到合适的值，即可识别到对应的直线。 例如`LAB (20, 50, 80)`，由于`L 20`，为了适配一定范围让`L Min 10`，`L Max 30`;同理，由于`A 50`，让`A Min 40`，`A Max 60`; 由于`B 80`，让`B Min 70`，`B Max 90`。 #### 通过串口协议获取检测数据 寻找直线应用支持通过串口（默认波特率为115200）上报检测到的直线信息。 由于上报信息只有一条，这里直接用示例来说明上报信息的内容。 例如上报信息为： ```shell AA CA AC BB 0E 00 00 00 E1 09 FC 01 01 00 E9 01 6F 01 57 00 C1 C6 ``` `AA CA AC BB`：协议头部，内容固定 `0E 00 00 00`：数据长度，除了协议头部和数据长度外的总长度，这里表示长度为14 `E1`：标志位，用来标识串口消息标志 `09`：命令类型，对于寻找直线APP应用该值固定为0x09 `FC 01 01 00 E9 01 6F 01 57 00`：直线的两端坐标和角度信息，每个值用小端格式的2字节表示。`FC 01`和`01 00`表示第一个端点坐标为(508, 1)，`E9 01`和`6F 01`表示第二个端点坐标为(489, 367)，`57 00`表示直线与x轴的角度为87度 ` C1 C6`：CRC 校验值，用以校验帧数据在传输过程中是否出错"},"/maixpy/doc/zh/vision/segmentation.html":{"title":"MaixCAM MaixPy 图像语义分割","content":" title: MaixCAM MaixPy 图像语义分割 ## 简介 图像语义分割，就是识别图中特定的物体，并且讲物体部分的像素识别出来，比如下图识别到了人体和狗的身体部分，可以拿来做碰撞检测、汽车自动导航、面积测算等等。 ![](../../assets/yolov8_seg.jpg) ## MaixPy 使用图像语义分割 MaixPy 内置了 `YOLOv8 seg` 和 `YOLO11 seg` 来进行对象检测和图像分割。 MaixPy 默认提供了 coco 数据集 80 种物体分类模型。 > 使用 YOLOv8 MaixPy 版本必须 > 4.4.0 > 使用 YOLO11 MaixPy 版本必须 > 4.7.0 代码如下，也可以在 [MaixPy examples](https://github.com/sipeed/maixpy/tree/main/examples/) 中找到。 ```python from maix import camera, display, image, nn, app, time detector nn.YOLOv8(model \"/root/models/yolov8n_seg.mud\", dual_buff True) # detector nn.YOLO11(model \"/root/models/yolo11n_seg.mud\", dual_buff True) cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) disp display.Display() while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.5, iou_th 0.45) for obj in objs: # img.draw_image(obj.x, obj.y, obj.seg_mask) detector.draw_seg_mask(img, obj.x, obj.y, obj.seg_mask, threshold 127) img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) msg f'{detector.labels[obj.class_id]}: {obj.score:.2f}' img.draw_string(obj.x, obj.y, msg, color image.COLOR_RED) disp.show(img) ``` > 这里切换 YOLOv8 和 YOLO11 只需要修改上面代码种注释的部分即可。 ## 更多分辨率模型 默认是 320x224 输入分辨率的模型， 更多分辨率请到 MaixHub 模型库 下载： * YOLOv8 seg: [[MaixHub 模型库](https://maixhub.com/model/zoo/413)](https://maixhub.com/model/zoo/413) * YOLO11 seg: [[MaixHub 模型库](https://maixhub.com/model/zoo/455)](https://maixhub.com/model/zoo/455) ## dual_buff 双缓冲区加速 你可能注意到这里模型初始化使用了`dual_buff`（默认值就是 `True`），使能 `dual_buff` 参数可以加快运行效率，提高帧率，具体原理和使用注意点见 [dual_buff 介绍](./dual_buff.html)。 ## 自定义自己的物体分割模型 上面提供的是 coco 数据集 80 分类的模型，如果不满足你的要求，你也可以自己训练特定的物体检测和分割模型，按照 [离线训练YOLOv8/YOLO11](./customize_model_yolov8.html) 所述使用 YOLOv8/YOLO11 官方的分格模型训练方法进行训练，然后转换成 MaixCAM 支持的模型格式即可。"},"/maixpy/doc/zh/vision/face_detection.html":{"title":"MaixCAM MaixPy 人脸检测和关键点检测","content":" title: MaixCAM MaixPy 人脸检测和关键点检测 ## 简介 人脸检测在很多地方都能用到，比如是为人脸识别提供人脸检测这一步骤，或者是人脸跟踪相关的应用等等。 这里提供的人脸检测不光可以检测到人脸，还能检测到 5 个关键点，包括两个眼睛，一个鼻子，一张嘴巴的两个嘴角。 ![face detection](../../assets/face_detection.jpg) ## MaixPy 中使用人脸检测 MaixPy 官方提供了三种人脸检测模型，分别来自开源项目 [face detector 1MB with landmark](https://github.com/biubug6/Face Detector 1MB with landmark) 和 [Retinafate](https://github.com/biubug6/Pytorch_Retinaface) 以及 [YOLOv8 face](https://github.com/derronqi/yolov8 face)。 这三种模型都可以用，`YOLOv8 face` 效果比较好但是速度略微慢一些，可以自己实际测试选择使用。 使用`YOLOv8 face`：（需要 MaixPy 版本 > 4.3.8） ```python from maix import camera, display, image, nn, app detector nn.YOLOv8(model \"/root/models/yolov8n_face.mud\", dual_buff True) cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) disp display.Display() while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.5, iou_th 0.45, keypoint_th 0.5) for obj in objs: img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) msg f'{detector.labels[obj.class_id]}: {obj.score:.2f}' img.draw_string(obj.x, obj.y, msg, color image.COLOR_RED) detector.draw_pose(img, obj.points, 2, image.COLOR_RED) disp.show(img) ``` 另外两种模型使用方法： 这里有一行被注释了代码是加载`Retinafae`模型，根据你下载的模型选择使用哪一行代码 ```python from maix import camera, display, image, nn, app import math detector nn.Retinaface(model \"/root/models/retinaface.mud\") # detector nn.FaceDetector(model \"/root/models/face_detector.mud\") cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) disp display.Display() while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.4, iou_th 0.45) for obj in objs: img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) radius math.ceil(obj.w / 10) img.draw_keypoints(obj.points, image.COLOR_RED, size radius if radius < 5 else 4) disp.show(img) ``` ## 模型下载和其它分辨率模型 下载模型，下载的压缩包里面有多个分辨率可以选择，分辨率越高越精准但耗时更长： * [face detector 1MB with landmark](https://maixhub.com/model/zoo/377) * [Retinafate](https://maixhub.com/model/zoo/378) * [YOLOv8 face](https://maixhub.com/model/zoo/407) ## dual_buff 双缓冲区加速 你可能注意到这里模型初始化使用了`dual_buff`（默认值就是 `True`），使能 `dual_buff` 参数可以加快运行效率，提高帧率，具体原理和使用注意点见 [dual_buff 介绍](./dual_buff.html)。 ## 检测更多关键点 这里提供的人脸关键点检测基本都是一次性检测到几个点，但是缺点是点比较少，要想检测到更多点和更加精准的点，请看[人脸关键点文档](./face_landmarks.html)"},"/maixpy/doc/zh/vision/dual_buff.html":{"title":"MaixCAM MaixPy MaixCAM 模型运行 dual_buff 模式介绍","content":" title: MaixCAM MaixPy MaixCAM 模型运行 dual_buff 模式介绍 ## 简介 细心的你可能注意到模型运行相关的的代码初始化时有一个参数`dual_buff True`。 比如 `YOLOv5`： ```python from maix import camera, display, image, nn, app detector nn.YOLOv5(model \"/root/models/yolov5s.mud\", dual_buff True) # detector nn.YOLOv8(model \"/root/models/yolov8n.mud\", dual_buff True) cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) disp display.Display() while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.5, iou_th 0.45) for obj in objs: img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) msg f'{detector.labels[obj.class_id]}: {obj.score:.2f}' img.draw_string(obj.x, obj.y, msg, color image.COLOR_RED) disp.show(img) ``` 一般来说这个参数默认就是`True`，除非手动设置`dual_buff False`才会关闭 `dual_buff`功能。 使能这个功能后运行的效率会提升，即帧率会提升（以上代码假设摄像头的帧率没有限制的情况下，在 MaixCAM 上会减少循环一半的时间即帧率翻倍）。 但是也有缺点，`detect`函数返回的结果是上一次调用`detect`函数的图的结果，所以结果和输入会有一帧的时间差，如果你希望`detect`出来的结果就是输入的`img`的结果而不是上一帧的结果，请禁用这个功能；另外由于准备了双份缓冲区，也会加大内存的使用，如果使用时发现内存不足，也需要禁用这个功能。 ## 原理 模型检测物体分为了几步： * 获取图像 * 图像预处理 * 模型运行 * 结果后处理 其中只有 模型运行这一步是硬件NPU 上运行的，其它步骤都在 CPU 运行。 如果`dual_buff`设置为`False`，在`detect`的时候，CPU 先预处理（此时 NPU 空闲）， 然后给 NPU 运算（此时 CPU 空闲等待 NPU 运算结束），然后 CPU 后处理（NPU 空闲）， 整过过程是线性的，比较简单。 但是这里发现了问题，就是 CPU 和 NPU 两者总有一个空闲着的，当加了`dual_buff True`， CPU 预处理后交给 NPU 运算，此时 CPU 不再等待 NPU 出结果，二是直接退出`detect`函数进行下一次摄像头读取和预处理，等 NPU 运算完成后， CPU 已经准备好了下一次的数据直接交给 NPU 继续运算，不给 NPU 喘息的机会，这样就充分利用了 CPU 和 NPU 高效地同时进行运算。 不过这里也需要注意，摄像头帧率如果不够高也会限制整体帧率。"},"/maixpy/doc/zh/vision/customize_model_yolov5.html":{"title":"为 MaixCAM MaixPy 离线训练 YOLOv5 模型，自定义检测物体","content":" title: 为 MaixCAM MaixPy 离线训练 YOLOv5 模型，自定义检测物体 update: date: 2024 6 20 version: v1.0 author: neucrack content: 编写文档 date: 2025 7 01 version: v2.0 author: neucrack content: 增加 MaixCAM2 支持 ## 简介 默认官方提供了 80 种物体检测，如果不满足你的需求，可以自己训练检测的物体，两种方式： * 使用 [MaixHub 在线训练](./maixhub_train.html)，方便快捷，无需购买服务器也无需搭建环境，点几下鼠标就完成。 * 在自己的电脑或者服务器搭建训练环境训练。 前者好处是简单快速，后者是使用自己电脑，训练图片数量不受限制，但是后者难度会大非常多。 **注意：** 本文讲了如何自定义训练，但是有一些基础知识默认你已经拥有，如果没有请自行学习： * 本文不会讲解如何安装训练环境，请自行搜索安装（Pytorch 环境安装）测试。 * 本文不会讲解机器学习的基本概念、linux相关基础使用知识。 如果你觉得本文哪里需要改进，欢迎点击右上角`编辑本文`贡献并提交 文档 PR。 ## 流程和本文目标 要想我们的模型能在 MaixPy (MaixCAM)上使用，需要经历以下过程： * 搭建训练环境，本文略过，请自行搜索 pytorch 训练环境搭建。 * 拉取 [yolov5](https://github.com/ultralytics/yolov5) 源码到本地。 * 准备数据集，并做成 yolov5 项目需要的格式。 * 训练模型，得到一个 `onnx` 模型文件，也是本文的最终输出文件。 * 将`onnx`模型转换成 MaixPy 支持的 `MUD` 文件，这个过程在模型转换文章中有详细介绍： * [MaixCAM 模型转换](../ai_model_converter/maixcam.html) * [MaixCAM2 模型转换](../ai_model_converter/maixcam2.html) * 使用 MaixPy 加载模型运行。 ## 参考文章 因为是比较通用的操作过程，本文只给一个流程介绍，具体细节可以自行看 **[YOLOv5 官方代码和文档](https://github.com/ultralytics/yolov5)**(**推荐**)，以及搜索其训练教程，最终导出 onnx 文件即可。 这里有 MaixHub 的社区的几篇文章： * [maixcam部署yolov5s 自定义模型](https://maixhub.com/share/23) * [【流程分享】YOLOv5训练自定义数据集并部署在Maixcam上](https://maixhub.com/share/32) * [yolov5猫狗识别模型——免费云训练（新手也可复现）](https://maixhub.com/share/25) 如果你有觉得讲得不错的文章欢迎修改本文并提交 PR。 ## YOLOv5 导出 ONNX 模型文件 YOLOv5 提供了导出选项，直接在`yolov5`目录下执行 ```shell python export.py weights ../yolov5s.pt include onnx img 224 320 ``` 这里加载 pt 参数文件，转换成 onnx， 同时指定分辨率，注意这里 高在前，宽在后。 模型训练的时候用的`640x640`，我们重新指定了分辨率方便提升运行速度，这里使用`320x224`的原因是和 MaixCAM 的屏幕比例比较相近方便显示，对于 MaixCAM2 可以用 `640x480` 或者 `320x240`，具体可以根据你的需求设置就好了。 ## MaixCAM MUD 文件 将 onnx 转换为 `mud` 格式的模型文件时，参照 [MaixCAM 模型转换](../ai_model_converter/maixcam.html) 和 [MaixCAM2 模型转换](../ai_model_converter/maixcam2.html) 即可，最终会得到一个`mud`文件和`cvimodel`文件，其中 `mud` 文件内容： MaixCAM/MaixCAM Pro: ```ini [basic] type cvimodel model yolov5s_320x224_int8.cvimodel [extra] model_type yolov5 input_type rgb mean 0, 0, 0 scale 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 anchors 10,13, 16,30, 33,23, 30,61, 62,45, 59,119, 116,90, 156,198, 373,326 labels person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair drier, toothbrush ``` MaixCAM2: ```ini [basic] type axmodel model_npu yolov5s_640x480_npu.axmodel model_vnpu yolov5s_640x480_vnpu.axmodel [extra] model_type yolov5 type detector input_type rgb input_cache true output_cache true input_cache_flush false output_cache_inval true anchors 10,13, 16,30, 33,23, 30,61, 62,45, 59,119, 116,90, 156,198, 373,326 labels person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair drier, toothbrush mean 0,0,0 scale 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 ``` 根据你训练的内容替换参数即可，比如你训练检测`0~9`数字，那么只需要替换`labels 0,1,2,3,4,5,6,7,8,9` 即可， 然后运行模型时将两个文件放在同一个目录下加载`mud`文件即可。 ## 上传分享到 MaixHub 到 [MaixHub 模型库](https://maixhub.com/model/zoo?platform maixcam) 上传并分享你的模型，可以多提供几个分辨率供大家选择。"},"/maixpy/doc/zh/vision/detect_obb.html":{"title":"","content":" tite: 带旋转角度的目标检测(OBB, Oriented Bounding Box) update: date: 2024 12 20 version: v1.0 author: neucrack content: 支持 YOLO11/YOLOv8 OBB 模型并添加文档 ## 简介 普通的检测中输出结果是一个矩形框，但是在一些场景中，目标物体的形状是旋转的，这时候就需要输出一个带旋转角度的矩形框，这种矩形框叫做OBB(Oriented Bounding Box)。 ![](../../assets/ships detection using obb.jpeg) 普通检测结果： x, y, w, h, 分别是 矩形框左上角或者中心点坐标，以及矩形宽高。 OBB 检测结果：x, y, w, h, angle, 多了一个旋转角度。 ## MaixPy MaixCAM 中使用带旋转角度的目标检测(OBB) `MaixPy` 中移植了 `YOLO11/YOLOv8` `OBB` 模型，可以快速方便地实现， 以下为例程，以[MaixPy/examples](https://github.com/sipeed/maixpy)中的`nn_yolo11_obb.py`为准： ```python from maix import camera, display, image, nn, app detector nn.YOLO11(model \"/root/models/yolo11n_obb.mud\", dual_buff True) cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) disp display.Display() while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.5, iou_th 0.45) for obj in objs: points obj.get_obb_points() msg f'{detector.labels[obj.class_id]}: {obj.score:.2f}, {obj.angle * 180:.1f}' img.draw_string(points[0], points[1] 4, msg, color image.COLOR_RED) detector.draw_pose(img, points, 8 if detector.input_width() > 480 else 4, image.COLOR_RED, close True) disp.show(img) ``` 可以看到这里使用`YOLO11`加载了`obb`模型，然后在检测到目标后，通过`obj.angle`获取到矩形旋转角度，`obj`的`x,y,w,h`属性是未旋转的矩形，通过`get_obb_points`获取到旋转后的矩形的四个顶点坐标，然后通过`draw_pose`绘制出目标的旋转矩形框，`close`参数表示将矩形框四个顶点连线起来。 默认的模型是 YOLO11 官方的`15`类模型，分类标签如下： ```python plane, ship, storage tank, baseball diamond, tennis court, basketball court, ground track field, harbor, bridge, large vehicle, small vehicle, helicopter, roundabout, soccer ball field, swimming pool ``` 在`/root/models/yolo11n_obb.mud`文件中也能看到。 ## 更多输入分辨率 默认的输入图像分辨率是`320x224`，如果需要更高的分辨率，可以到[MaixHub 模型库](https://maixhub.com/model/zoo/869) 下载，或者按照后文自定义模型。 ## MaixPy MaixCAM 自定义自己的OBB模型 ### 电脑端使用模型 关于 `YOLO11` 官方的 OBB 模型介绍请看[YOLO11 OBB](https://docs.ultralytics.com/tasks/obb/)。 在这个文档中可以看到如何在电脑端使用`obb`模型，以及如何导出 ONNX 模型文件。 ### 导出模型给 MaixCAM 使用 根据 [YOLO11/YOLOv8 自定义模型](./customize_model_yolov8.html) 即可将 ONNX 模型转换为 MaixCAM 可以使用的 MUD 模型。 注意：转换时需要注意输出层的输出名不要弄错。 ### 训练自己的 OBB 模型 根据[YOLO11 官方训练文档](https://docs.ultralytics.com/datasets/obb/dota v2/) 准备自己的数据集，然后进行训练即可。"},"/maixpy/doc/zh/vision/yolov5.html":{"title":"MaixPy MaixCAM 使用 YOLOv5 / YOLOv8 / YOLO11 模型进行目标检测","content":" title: MaixPy MaixCAM 使用 YOLOv5 / YOLOv8 / YOLO11 模型进行目标检测 ## 目标检测概念 目标检测是指在图像或视频中检测出目标的位置和类别，比如在一张图中检测出苹果、飞机等物体，并且标出物体的位置。 和分类不同的是多了一个位置信息，所以目标检测的结果一般是一个矩形框，框出物体的位置。 ## MaixPy 中使用目标检测 MaixPy 默认提供了 `YOLOv5` 和 `YOLOv8` 和 `YOLO11` 模型，可以直接使用： > YOLOv8 需要 MaixPy > 4.3.0。 > YOLO11 需要 MaixPy > 4.7.0。 ```python from maix import camera, display, image, nn, app detector nn.YOLOv5(model \"/root/models/yolov5s.mud\", dual_buff True) # detector nn.YOLOv8(model \"/root/models/yolov8n.mud\", dual_buff True) # detector nn.YOLO11(model \"/root/models/yolo11n.mud\", dual_buff True) cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) disp display.Display() while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.5, iou_th 0.45) for obj in objs: img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) msg f'{detector.labels[obj.class_id]}: {obj.score:.2f}' img.draw_string(obj.x, obj.y, msg, color image.COLOR_RED) disp.show(img) ``` 效果视频: <div> <video playsinline controls autoplay loop muted preload src \"/static/video/detector.mp4\" type \"video/mp4\"> </div> 这里使用了摄像头拍摄图像，然后传给 `detector`进行检测，得出结果后，将结果(分类名称和位置)显示在屏幕上。 以及这里 替换`YOLO11` 和 `YOLOv5` 和`YOLOv8`即可实现`YOLO11/v5/v8/`切换，注意模型文件路径也要修改。 模型支持的 80 种物体列表请看本文附录。 更多 API 使用参考 [maix.nn](/api/maix/nn.html) 模块的文档。 ## dual_buff 双缓冲区加速 你可能注意到这里模型初始化使用了`dual_buff`（默认值就是 `True`），使能 `dual_buff` 参数可以加快运行效率，提高帧率，具体原理和使用注意点见 [dual_buff 介绍](./dual_buff.html)。 ## 更多输入分辨率 默认的模型输入是`320x224`分辨率，因为这个分辨率比例和默认提供的屏幕分辨率接近，你也可以手动下载其它分辨率的模型替换： YOLOv5: [https://maixhub.com/model/zoo/365](https://maixhub.com/model/zoo/365) YOLOv8: [https://maixhub.com/model/zoo/400](https://maixhub.com/model/zoo/400) YOLO11: [https://maixhub.com/model/zoo/453](https://maixhub.com/model/zoo/453) 分辨率越大精度越高，但是运行耗时越长，根据你的应用场景选择合适的即可。 ## YOLOv5 和 YOLOv8 和 YOLO11 用哪个？ 这里提供的 `YOLOv5s` 和 `YOLOv8n` 和 `YOLO11n` 三种模型，`YOLOv5s`模型更大，`YOLOv8n YOLO11n`速度快一点点， 精度按照官方数据来说`YOLO11n > YOLOv8n > YOLOv5s`，可以实际测试根据自己的实际情况选择。 另外你也可以尝试`YOLOv8s`或者`YOLO11s`，帧率会低一些（比如 yolov8s_320x224 比 yolov8n_320x224 慢 10ms），准确率会比前两个都高，模型可以在上面提到的模型库下载到或者自己从`YOLO`官方仓库导出模型。 ## 摄像头分辨率和模型分辨率不同可以吗 上面使用`detector.detect(img)`函数进行检测时，如果 `img` 的分辨率和模型分辨率不同，这个函数内部会自动调用`img.resize`将图像缩放成和模型输入分辨率相同的，`resize`默认使用`image.Fit.FIT_CONTAIN` 方法，即保持宽高比缩放，周围填充黑色的方式，检测到的坐标也会自动映射到原`img`的坐标上。 ## MaixHub 在线训练自己的目标检测模型 默认提供的 80 分类检测模型，如果你需要检测特定的物体，请到[MaixHub](https://maixhub.com) 学习并训练目标检测模型，创建项目时选择`目标检测模型`即可，参考[MaixHub 在线训练文档](./maixhub_train.html)。 或者到[MaixHub 模型库](https://maixhub.com/model/zoo?platform maixcam) 找社区成员分享的模型。 ## 离线训练自己的目标检测模型 强烈建议先使用 MaixHub 在线训练模型，此种方式难度比较大，不建议新手一来就碰这个方式。 此种方式有些许默认你知道的知识文中不会提，遇到问题多上网搜索学习。 请看 [离线训练YOLOv5模型](./customize_model_yolov5.html) 或者 [离线训练 YOLOv8/YOLO11 模型](./customize_model_yolov8.html) ## 附录：80分类 COCO 数据集的 8 种物体分别为： ```txt person bicycle car motorcycle airplane bus train truck boat traffic light fire hydrant stop sign parking meter bench bird cat dog horse sheep cow elephant bear zebra giraffe backpack umbrella handbag tie suitcase frisbee skis snowboard sports ball kite baseball bat baseball glove skateboard surfboard tennis racket bottle wine glass cup fork knife spoon bowl banana apple sandwich orange broccoli carrot hot dog pizza donut cake chair couch potted plant bed dining table toilet tv laptop mouse remote keyboard cell phone microwave oven toaster sink refrigerator book clock vase scissors teddy bear hair drier toothbrush ```"},"/maixpy/doc/zh/vision/find_barcodes.html":{"title":"MaixCAM MaixPy 条形码识别","content":" title: MaixCAM MaixPy 条形码识别 update: date: 2024 12 16 author: lxowalle version: 1.0.0 content: 初版文档 阅读本文前，确保已经知晓如何开发MaixCAM，详情请阅读[快速开始](../index.html) ## 简介 本文介绍如何使用MaixPy来识别条形码 ## 使用 MaixPy 识别条形码 MaixPy的 `maix.image.Image`中提供了`find_barcodes`方法，用来识别条形码 ### 如何识别条形码 一个简单的示例，实现识别条形码并画框 ```python from maix import image, camera, display cam camera.Camera(480, 320) disp display.Display() while 1: img cam.read() barcodes img.find_barcodes() for b in barcodes: rect b.rect() img.draw_rect(rect[0], rect[1], rect[2], rect[3], image.COLOR_BLUE, 2) img.draw_string(0, 0, \"payload: \" + b.payload(), image.COLOR_GREEN) disp.show(img) ``` 步骤： 1. 导入image、camera、display模块 ```python from maix import image, camera, display ``` 2. 初始化摄像头和显示 ```python cam camera.Camera(480, 320) # 初始化摄像头，输出分辨率480x320 RGB格式 disp display.Display() ``` 3. 从摄像头获取图片并显示 ```python while 1: img cam.read() disp.show(img) ``` 4. 调用`find_barcodes`方法识别摄像头中的条形码 ```python barcodes img.find_barcodes() ``` `img`是通过`cam.read()`读取到的摄像头图像，当初始化的方式为`cam camera.Camera(320, 240)`时，`img`对象是一张分辨率为480x320的RGB图。 `img.find_barcodes`用来寻找条形码，并将查询结果保存到`barcodes`，以供后续处理 注意: 条形码的间距较小, 并且一般宽度远大于高度, 所以在调整识别率和识别速度时可以尽量让识别目标图像的宽度更大, 高度更小 5. 处理识别条形码的结果并显示到屏幕上 ```python for b in barcodes: rect b.rect() img.draw_rect(rect[0], rect[1], rect[2], rect[3], image.COLOR_BLUE, 2) img.draw_string(0, 0, \"payload: \" + b.payload(), image.COLOR_GREEN) ``` `barcodes`是通过`img.find_barcodes()`查询条形码的结果，如果找不到条形码则`barcodes`内部为空 `b.rect()`用来获取已扫描到的条形码的位置和大小，`img.draw_rect()`利用这些位置信息画出条形码的形状 `img.draw_string`用来显示条形码的内容和位置等信息，`b.payload()`用来获取条形码的内容 ### 常用参数说明 列举常用参数说明，如果没有找到可以实现应用的参数，则需要考虑是否使用其他算法实现，或者基于目前算法的结果扩展所需的功能 参数 说明 示例 roi 设置算法计算的矩形区域，roi [x, y, w, h]，x，y表示矩形区域左上角坐标，w，h表示矩形区域的宽度和高度，默认为整张图片 计算坐标为(50,50)，宽和高为100的区域<br />```img.find_barcodes(roi [50, 50, 100, 100])``` 本文介绍常用方法，更多 API 请看 API 文档的 [image](../../../api/maix/image.html) 部分。"},"/maixpy/doc/zh/vision/opencv.html":{"title":"MaixCAM MaixPy 使用 OpenCV","content":" title: MaixCAM MaixPy 使用 OpenCV ## 简介 对于 MaixCAM，因为使用了 Linux， 并且性能基本能够支撑使用`Python`版本的`OpenCV`，所以除了使用`maix`模块，你也可以直接使用`cv2`模块。 本文例程以及更多可以在[MaixPy/examples/vision/opencv](https://github.com/sipeed/MaixPy/tree/main/examples/vision/opencv) 中找到。 **注意 OpenCV 的函数基本都是 CPU 计算的，能使用 maix 的模块尽量不使用 OpenCV，因为 maix 有很多函数都是经过硬件加速过的。** ## maix.image.Image 对象和 Numpy/OpenCV 格式互相转换 `maix.image.Image`对象可以转换成`numpy`数组，这样就能给`numpy`和`opencv`等库使用： ```python from maix import image, time, display, app disp display.Display() while not app.need_exit(): img image.Image(320, 240, image.Format.FMT_RGB888) img.draw_rect(0, 0, 100, 100, image.COLOR_RED, thickness 1) t time.ticks_ms() img_bgr image.image2cv(img, ensure_bgr True, copy True) img2 image.cv2image(img_bgr, bgr True, copy True) print(\"time:\", time.ticks_ms() t) print(type(img_bgr), img_bgr.shape) print(type(img2), img2) print(\"\") disp.show(img2) ``` 前面的程序因为每次转换都要拷贝一次内存，所以速度会比较慢，下面为优化速度版本，如果不是极限追求速度不建议使用，容易出错： ```python from maix import image, time, display, app disp display.Display() while not app.need_exit(): img image.Image(320, 240, image.Format.FMT_RGB888) img.draw_rect(0, 0, 100, 100, image.COLOR_RED, thickness 1) t time.ticks_ms() img_rgb image.image2cv(img, ensure_bgr False, copy False) img2 image.cv2image(img_rgb, bgr False, copy False) print(\"time:\", time.ticks_ms() t) print(type(img_rgb), img_rgb.shape) print(type(img2), img2) disp.show(img2) ``` * `img_rgb image.image2cv(img, ensure_bgr False, copy False)`中`img_rgb` 会直接使用 `img` 的数据，不会产生内存拷贝，注意此时得到的`img_rgb` 是 `RGB` 图，`opencv`的 API 都是认为图是 `BGR` 的，所以用`opencv`的 API 操作图像时要注意，如果你无法掌控请设置`ensure_bgr`为`True`。 * `img2 image.cv2image(img_rgb, bgr False, copy False)`中设置了`copy`为`False`，即直接使用`img_rgb`的内存，不会新拷贝一份内存，所以速度更快了，但是需要小心，在 `img2` 使用结束前`img_bgr`不能被销毁，否则程序会崩溃。 * 注意因为借用了内存，所以更改转换后的图像也会影响到转换前的图像。 ## 加载一张图片 ```python import cv2 file_path \"/maixapp/share/icon/detector.png\" img cv2.imread(file_path) print(img) ``` 因为`cv2`模块比较臃肿，`import cv2`可能会需要一点时间。 ## 显示图像到屏幕 但是由于直接使用了官方的 OpenCV，没有对接显示，所以要显示到屏幕上需要转换成`maix.image.Image`对象后再用`display`来显示： ```python from maix import display, image, time import cv2 disp display.Display() file_path \"/maixapp/share/icon/detector.png\" img cv2.imread(file_path) img_show image.cv2image(img) disp.show(img_show) while not app.need_exit(): time.sleep(1) ``` ## 使用 OpenCV 函数 以边缘检测为例： 基于上面的代码，使用`cv2.Canny`函数即可： ```python from maix import image, display, app, time import cv2 file_path \"/maixapp/share/icon/detector.png\" img0 cv2.imread(file_path) disp display.Display() while not app.need_exit(): img img0.copy() # canny method t time.ticks_ms() edged cv2.Canny(img, 180, 60) t2 time.ticks_ms() t # show by maix.display t time.ticks_ms() img_show image.cv2image(edged) print(f\"edge time: {t2}ms, convert time: {time.ticks_ms() t}ms\") disp.show(img_show) ``` ## 使用摄像头 在 PC 上， 我们使用 `OpenCV` 的`VideoCapture`类来读取摄像头，对于 `MaixCAM`, `OpenCV` 没有适配，我们可以用`maix.camera` 模块来读取摄像头，然后给`OpenCV`使用。 通过`image.image2cv`函数将`maix.image.Image`对象转为`numpy.ndarray`对象给`OpenCV`使用： ```python from maix import image, display, app, time, camera import cv2 disp display.Display() cam camera.Camera(320, 240, image.Format.FMT_BGR888) while not app.need_exit(): img cam.read() # convert maix.image.Image object to numpy.ndarray object t time.ticks_ms() img image.image2cv(img, ensure_bgr False, copy False) print(\"time: \", time.ticks_ms() t) # canny method edged cv2.Canny(img, 180, 60) # show by maix.display img_show image.cv2image(edged, bgr True, copy False) disp.show(img_show) ``` ## 读取 USB 摄像头 先在开发板设置里面`USB设置`中选择`USB 模式`为`HOST`模式。如果没有屏幕，可以用`examples/tools/maixcam_switch_usb_mode.py`脚本进行设置。 ```python from maix import image, display, app import cv2 import sys cap cv2.VideoCapture(0) cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640) cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) # cap.set(cv2.CAP_PROP_CONVERT_RGB, 0) disp display.Display() if not cap.isOpened(): print(\"无法打开摄像头\") sys.exit(1) print(\"开始读取\") while not app.need_exit(): ret, frame cap.read() if not ret: print(\"无法读取帧\") break img image.cv2image(frame, bgr True, copy False) disp.show(img) ```"},"/maixpy/doc/zh/vision/custmize_model.html":{"title":"","content":"请看 [MaixCAM 模型转换](../ai_model_converter/maixcam.html)，以及在左边目录找到你要转换的模型文档，比如[自定义 yolov5 模型](./customize_model_yolov5.html)。"},"/maixpy/doc/zh/vision/face_landmarks.html":{"title":"MaixCAM MaixPy 人脸 478 关键点检测","content":" title: MaixCAM MaixPy 人脸 478 关键点检测 update: date: 2025 01 08 version: v1.0 author: neucrack content: 增加人脸478关键点检测源码、文档、例程 ## 简介 前面的文章[人脸检测](./face_detection.html)中介绍了如何检测人脸，以及几个关键点（比如 5 个），本文介绍如何检测更多（478个）关键点。 更多的关键点有更多的用途，比如表情检测，人脸特征识别，换脸等等。 ![face_landmarks](../../assets/face_landmarks.jpg) <a href \"../../assets/maixcam_face_landmarks_full.jpg\" target \"_blank\">高清大图， 478个点位置在图中可以看到</a> ## MaixPy 中使用人脸关键点检测 MaixPy 中移植了 MediePipe 的人脸 **478 关键点**检测，效果如下： ![maixcam_face_landmarks](../../assets/maixcam_face_landmarks_1.jpg) 效果视频： <video playsinline controls autoplay loop muted preload src \"/static/video/maixcam_face_landmarks.mp4\" type \"video/mp4\"> Classifier Result video </video> 使用代码（MaixPy 版本必须 > 4.10.0），最新代码以[MaixPy/examples](https://github.com/sipeed/MaixPy)为准： ```python from maix import camera, display, image, nn, app detect_conf_th 0.5 detect_iou_th 0.45 landmarks_conf_th 0.5 landmarks_abs True landmarks_rel False max_face_num 2 detector nn.YOLOv8(model \"/root/models/yolov8n_face.mud\", dual_buff False) landmarks_detector nn.FaceLandmarks(model \"/root/models/face_landmarks.mud\") cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) disp display.Display() while not app.need_exit(): img cam.read() results [] objs detector.detect(img, conf_th detect_conf_th, iou_th detect_iou_th, sort 1) count 0 for obj in objs: img_std landmarks_detector.crop_image(img, obj.x, obj.y, obj.w, obj.h, obj.points) if img_std: res landmarks_detector.detect(img_std, landmarks_conf_th, landmarks_abs, landmarks_rel) if res and res.valid: results.append(res) count + 1 if count > max_face_num: break for res in results: landmarks_detector.draw_face(img, res.points, len(res.points_z), res.points_z) disp.show(img) ``` 这里有几个地方解释一下： * `max_face_num` 可以限制最多检测的人脸数量，防止画面人脸过多变卡。 * `landmarks_abs` 指定检测到源图`img`中人脸关键点的坐标，在结果的`points`变量中有`478`个点，以`x0,y0,x1,y1,...,x477,y477`顺序排列。 * `landmarks_rel` 则输出`img_std`中的坐标，结果追加到`points`变量中。 * `points_z` 是关键点深度估计，值相对于面部重心，离镜头越近值越大，在面部重心之后则为负值，值与面部宽度成比例。 ## 取部分关键点 478 个关键点有点多，如果你只需要其中几个，可以根据 <a href \"../../assets/maixcam_face_landmarks_full.jpg\" target \"_blank\">高清大图</a> 的下标取部分，常见的： **注意只提供参考，以模型实际输出为准** * 146 个点： ```python sub_146_idxes [0, 1, 4, 5, 6, 7, 8, 10, 13, 14, 17, 21, 33, 37, 39, 40, 46, 52, 53, 54, 55, 58, 61, 63, 65, 66, 67, 70, 78, 80, 81, 82, 84, 87, 88, 91, 93, 95, 103, 105, 107, 109, 127, 132, 133, 136, 144, 145, 146, 148, 149, 150, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 168, 172, 173, 176, 178, 181, 185, 191, 195, 197, 234, 246, 249, 251, 263, 267, 269, 270, 276, 282, 283, 284, 285, 288, 291, 293, 295, 296, 297, 300, 308, 310, 311, 312, 314, 317, 318, 321, 323, 324, 332, 334, 336, 338, 356, 361, 362, 365, 373, 374, 375, 377, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389, 390, 397, 398, 400, 402, 405, 409, 415, 454, 466, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477] ``` * 68 个点： ```python sub_68_idxes [162, 234, 93, 58, 172, 136, 149, 148, 152, 377, 378, 365, 397, 288, 323, 454, 389, 71, 63, 105, 66, 107, 336, 296, 334, 293, 301, 168, 197, 5, 4, 75, 97, 2, 326, 305, 33, 160, 158, 133, 153, 144, 362, 385, 387, 263, 373, 380, 61, 39, 37, 0, 267, 269, 291, 405, 314, 17, 84, 181, 78, 82, 13, 312, 308, 317, 14, 87] ``` * 5 个点 ```python sub_5_idxes [468, 473, 4, 61, 291] ``` 有了这些下标，我们用代码提取部分出来显示： ```python def get_sub_landmarks(points, points_z, idxes): new_points [] new_points_z [] for i in idxes: new_points.append(points[i*2]) new_points.append(points[i*2 + 1]) new_points_z.append(points_z[i]) return new_points, new_points_z sub_xy, sub_z get_sub_landmarks(res.points, res.points_z, sub_146_idxes) landmarks_detector.draw_face(img, sub_xy, len(sub_z), sub_z) ```"},"/maixpy/doc/zh/vision/yolo_world.html":{"title":"MaixPy MaixCAM2 使用 YOLO World 模型实现无需训练检测任意目标","content":" title: MaixPy MaixCAM2 使用 YOLO World 模型实现无需训练检测任意目标 ## YOLO World 硬件平台支持情况 硬件平台 是否支持 MaixCAM 否 MaixCAM2 是 ## 回顾 YOLO 目标检测 YOLO 大家都很熟悉，即一个适合边缘设备部署的目标检测模型，可以快速检测到训练好的目标。 比如我们想检测画面中`苹果`的位置，需要先采集`苹果`的图像数据，然后训练出一个模型，最后导出模型在 MaixPy 中使用这个模型进行检测。 也就是说每有一个想检测的目标，就需要重新训练一个模型，这个过程比较繁琐而且需要训练时间，最重要的是不能在端测进行训练，必须在有 GPU 的电脑或服务器训练。 ## YOLO World 概念 YOLO World 则不需要额外的训练，只需要告诉模型我们想检测的目标是什么，YOLO World 就可以检测到这个目标，听起来是不是很神奇。 YOLO World 是一个新的概念，YOLO World 是一个可以检测任意目标的模型，YOLO World 通过`Prompt`的方式来实现这个功能。 即在模型中加入了语言模型的能力，通过输入文字描述来告诉模型我们想检测的目标是什么。 比如我们要检测`苹果`，只需要输入`apple`和要检测的图像，模型就可以检测到图像中的`苹果`坐标。 此处不阐述更具体的专业知识，有兴趣学习请参考 [YOLO World 官方仓库](https://github.com/AILab CVC/YOLO World)。 ## MaixPy 中使用 YOLO World ### MaixPy 中的 YOLO World 实现 MaixPy 移植了[ultralytics](https://github.com/ultralytics/ultralytics/blob/main/docs/en/models/yolo world.md) 即 YOLOv8/YOLO11 官方移植的 YOLO World 模型，使用了[ONNX YOLO World Open Vocabulary Object Detection](https://github.com/AXERA TECH/ONNX YOLO World Open Vocabulary Object Detection)这个项目。 所以如果你想在 PC 上体验（**注意不是运行在 MaixCAM**)，可以按照这个文档体验。比如我们可以： 先指定要检测的目标分类，保存一个只能检测我们指定目标的模型： ```python from ultralytics import YOLO model YOLO(\"yolov8s world.pt\") # or select yolov8m/l world.pt model.set_classes([\"person\", \"bus\"]) model.save(\"custom_yolov8s.pt\") ``` 再使用新的模型执行检测： ```python from ultralytics import YOLO model YOLO(\"custom_yolov8s.pt\") results model.predict(\"path/to/image.jpg\") results[0].show() ``` ### 原理介绍 上面可以看到先指定检测的目标分类得到一个新的模型，然后使用这个模型进行检测。 原理如下： 由于边缘计算硬件的性能和功耗限制，我们把 YOLO World 模型（前面提到的`yolov8s world.pt`）内部分成了两部分： * **语言文字模型(text_feature model)**：通过运行这个模型，将语言文字(`Prompt`）预先编码成一个文本特征向量（可以简单理解一个数组），存储在一个`.bin`文件中。这个模型比较大，运行缓慢。 * **检测模型(yolo model)**：通过运行这个模型，将图像和特征向量(`.bin`)同时作为输入，进行目标检测，输出检测到的目标坐标和分类名称。这个模型比较小，运行速度快。 分成两个部分的原因是我们实际在检测的时候只需要检测模型，无需每次都运行语言模型，节省了运行时间和功耗。 比如我们要检测`苹果`，只需要运行一次语言模型（占用资源大），将`apple`编码成特征向量（很小的文件），存储在文件中，然后每次检测的时候只需要运行检测模型，将图像和特征向量结合起来进行检测。 当我们需要检测新的目标的时候再运行一次语言模型生成新的特征向量文件即可。 所以在前面的例子中，电脑上使用的`yolov8s world.pt`一个模型文件包含了语言模型和检测模型，为了方便边缘设备使用，我们把它拆分成了两个模型文件： * `yolo world_4_class.mud`：检测模型，运行速度快，体积小。 * `yolo world_text_feature_4_class.mud`：语言模型，运行速度慢，体积大。 ### 运行语言模型指定要检测的目标 运行一次语言模型，指定要检测的目标，生成特征向量文件，注意这段代码可以在 MaixCAM2 或者 电脑上运行。 建议先在终端执行 `pip install U yolo world utils` 或者 `Python` 运行`import os;os.system(\"pip install U yolo world utils\")`先安装并更新工具。 > 这一步是安装工具软件，第一次运行会提示需要下载一个 onnx 模型文件到某个路径，可以到[这里](https://github.com/Neutree/yolo world utils/releases) 手动下载放到提示的路径。 > 如果你在这一步遇到了困难，也可以先跳过此步骤，用内置的`/root/models/yolo world_4_class_person.txt` 和 `/root/models/yolo world_4_class_person.bin`两个文件继续尝试后面的步骤，再慢慢解决问题。 再执行： ```python import os labels [\"apple\", \"banana\", \"orange\", \"grape\"] out_dir \"/root/models\" name \"yolo world_4_class_my_feature\" feature_file os.path.join(out_dir, f\"{name}.bin\") labels_file os.path.join(out_dir, f\"{name}.txt\") with open(labels_file, \"w\") as f: for label in labels: f.write(f\"{label}\\n\") cmd f\"python u m yolo_world_utils gen_text_feature labels_path {labels_file} out_feature_path {feature_file}\" print(f\"Now run\\n\\t`{cmd}`\\nto generate text feature of\\n{labels}\") print(\"\\nplease wait a moment, it may take a few seconds ...\\n\") ret os.system(cmd) if ret ! 0: print(\"[ERROR] execute have error, please see log\") else: print(f\"saved\\n\\tlabels to:\\n\\t{labels_file}\\n and text feature to:\\n\\t{feature_file}\") print(f\"please use yolo world_{len(labels)}_class.mud model to run detect\") ``` 这里我们指定了要检测 4 个分类，设置`labels`就可以了，会生成检测需要的两个文件(`*.bin`和`*.txt`)。 **注意**：`labels`格式要求： * 每个分类名称必须是**英文**，不能是中文或其它语言的单词，因为语言模型只支持英文。 * 可以多个单词，但是长度不能太长，使用BPE编码后的长度最长为 75 个token，简单来说如果太长会报错，试一试就知道了。 ### 运行检测模型 前面我们生成了特征向量，现在我们已经有三个文件： 1. 文本特征向量`yolo world_4_class_my_feature.bin`。 2. 标签文本文件`yolo world_4_class_my_feature.txt`。 3. 1 分类检测模型`yolo world_4_class.mud`，内置在`/root/models`目录下。 > 注意这里检测模型为`4_class`，即只能检测 4 个分类的目标，那么 `.txt` 里面只能有四个分类，要一一对应。比如1分类要用`yolo world_1_class.mud`模型，`.txt`里面也要有 1 行分类名称。 > 系统在`/root/models`目录下内置了`1/4`种分类的检测模型，分别为`yolo world_1_class.mud`，`yolo world_4_class.mud`。如果你需要检测其它数量的分类，请按照下面的**下载更多分类数量的检测模型**下载对应的模型文件。 > 建议在文件名命名时加上分类数量防止弄混淆，比如`yolo world_4_class.mud`，`yolo world_4_class_my_feature.bin`，`yolo world_4_class_my_feature.txt`。 我们就可以直接使用 YOLO World 模型进行实时目标检测了，代码基本和 YOLOv8 和 YOLO11 一样： ```python detector nn.YOLOWorld(\"/root/models/yolo world_4_class.mud\", \"/root/models/yolo world_4_class_my_feature.bin\", \"/root/models/yolo world_4_class_my_feature.txt\", dual_buff True) cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) disp display.Display() while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.5, iou_th 0.45) for obj in objs: img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) msg f'{detector.labels[obj.class_id]}: {obj.score:.2f}' img.draw_string(obj.x, obj.y, msg, color image.COLOR_RED) disp.show(img) ``` ## 下载更多分类数量的检测模型 系统内默认提供了 1/4 分类的检测模型，提供了两种方式： ### 到 MaixHub 模型库下载 到[MaixHub 模型库]()下载更多分类（支持哪些分类数量可以看其介绍文档）。 比如只少提供了`2/3`分类数量的模型。 ### 自己生成模型 如果内置和 MaixHub 都找不到你需要的分类数量，那就需要自己生成了，方法如下： > 如果你自己没有环境或能力完成，可以到 QQ 群 86234035 或者 [telegram](https://t.me/maixpy) 请求有能力的群友有偿帮忙转。 提供了 docker 镜像，拉取镜像到本地运行即可生成任意分类的模型。 * 首先保证能正常从 dockerhub 拉取镜像文件，最好设置代理，可以参考[docker 设置代理](https://neucrack.com/p/286)。 * 可以用`docker pull hello world`测试是否能成功。 * `docker pull sipeed/yolo world generator maixcam2` > `sipeed/sipeed/yolo world generator maixcam2`依赖了 `sipeed/pulsar2`镜像，会自动下载，另外你也可以在[pulsar2官方网站](https://pulsar2 docs.readthedocs.io/zh cn/latest/user_guides_quick/quick_start_prepare.html)手动下载镜像文件，然后加载镜像并重命名 > * `docker load i *.tar.gz` > * `docker tag pulsar2:3.3 sipeed/pulsar2:latest`，这里`3.3`根据具体版本更改。 * `docker run it rm v ${PWD}/out:/root/out sipeed/yolo world generator maixcam2 /bin/bash` 这里` v ${PWD}/out:/root/out` 是将当前目录的 `out`文件夹映射到容器里面，容器生成的文件就可以在当前目录看到了（多个映射目录重复多个` v src:dst`参数就好了）。 另外如果你想替换量化图片，也可以映射目录到`/root/images`目录，不设置则使用默认的300张图量化。 如果想替换量化的文本(比如你需要很多分类，默认的80种分类可能不够用来量化，也许会造成量化误差)，映射目录到`/root/data`，`data`目录里面放一个`labes.txt`，每行一个类别名即可，不设置则使用默认内置的 coco 80 分类名。 就会进入 docker 容器内部了，执行转换命令即可： ```shell cd /root ./gen_model.sh 1 640 480 ``` 这里三个参数： * class_num: 即分类数量。 * width: 输入分辨率宽度。 * height: 输入分辨率高度。 * 生成完成后在 out 目录下会有模型文件压缩包，解压即可使用。 生成模型需要的时间比较久，需要耐心等待。 ### 其它参考 如果你想更深入了解移植过程，可以看[再谈 YOLO World 部署](https://zhuanlan.zhihu.com/p/721856217)"},"/maixpy/doc/zh/vision/customize_model_yolov8.html":{"title":"为 MaixCAM MaixPy 离线训练 YOLO11/YOLOv8 模型，自定义检测物体、关键点检测","content":" title: 为 MaixCAM MaixPy 离线训练 YOLO11/YOLOv8 模型，自定义检测物体、关键点检测 update: date: 2024 06 21 version: v1.0 author: neucrack content: 编写文档 date: 2024 10 10 version: v2.0 author: neucrack content: 增加 YOLO11 支持 date: 2025 07 01 version: v3.0 author: neucrack content: 增加 MaixCAM2 支持 ## 简介 默认官方提供了 80 种物体检测，如果不满足你的需求，可以自己训练检测的物体，可以在自己的电脑或者服务器搭建训练环境训练。 YOLOv8 / YOLO11 不光支持检测物体，还有 yolov8 pose / YOLO11 pose 支持关键点检测，出了官方的人体关键点，你还可以制作你自己的关键点数据集来训练检测指定的物体和关键点 因为 YOLOv8 和 YOLO11 主要是修改了内部网络，预处理和后处理都是一样的，所以 YOLOv8 和 YOLO11 的训练转换步骤相同，只是输出节点的名称不一样。 **注意：** 本文讲了如何自定义训练，但是有一些基础知识默认你已经拥有，如果没有请自行学习： * 本文不会讲解如何安装训练环境，请自行搜索安装（Pytorch 环境安装）测试。 * 本文不会讲解机器学习的基本概念、linux相关基础使用知识。 如果你觉得本文哪里需要改进，欢迎点击右上角`编辑本文`贡献并提交 文档 PR。 ## 流程和本文目标 要想我们的模型能在 MaixPy (MaixCAM)上使用，需要经历以下过程： * 搭建训练环境，本文略过，请自行搜索 pytorch 训练环境搭建。 * 拉取 [YOLO11/YOLOv8](https://github.com/ultralytics/ultralytics) 源码到本地。 * 准备数据集，并做成 YOLO11 / YOLOv8 项目需要的格式。 * 训练模型，得到一个 `onnx` 模型文件，也是本文的最终输出文件。 * 将`onnx`模型转换成 MaixPy 支持的 `MUD` 文件，这个过程在[MaixCAM 模型转换](../ai_model_converter/maixcam.html) 一文种有详细介绍。 * 使用 MaixPy 加载模型运行。 ## 哪里找数据集训练 请看[哪里找数据集](../pro/datasets.html) ## 参考文章 因为是比较通用的操作过程，本文只给一个流程介绍，具体细节可以自行看 **[YOLO11 / YOLOv8 官方代码和文档](https://github.com/ultralytics/ultralytics)**(**推荐**)，以及搜索其训练教程，最终导出 onnx 文件即可。 如果你有觉得讲得不错的文章欢迎修改本文并提交 PR。 ## YOLO11 / YOLOv8 导出 onnx 模型 在 `ultralytics` 目录下创建一个`export_onnx.py` 文件 ```python from ultralytics import YOLO import sys print(sys.path) net_name sys.argv[1] # yolov8n.pt yolov8n pose.pt # https://docs.ultralytics.com/models/yolov8/#supported tasks and modes input_width int(sys.argv[2]) input_height int(sys.argv[3]) # Load a model model YOLO(net_name) # load an official model # model YOLO(\"path/to/best.pt\") # load a custom model # Predict with the model results model(\"https://ultralytics.com/images/bus.jpg\") # predict on an image path model.export(format \"onnx\", imgsz [input_height, input_width], dynamic False, simplify True, opset 17) # export the model to ONNX format print(path) ``` 然后执行`python export_onnx.py yolov8n.pt 320 224` 就能导出 `onnx` 模型了，这里重新指定了输入分辨率，模型训练的时候用的`640x640`，我们重新指定了分辨率方便提升运行速度，这里使用`320x224`的原因是和 MaixCAM 的屏幕比例比较相近方便显示，对于 MaixCAM2 可以用 `640x480`或者 `320x240`，具体可以根据你的需求设置就好了。 ## 转换为 MaixCAM 支持的模型以及 mud 文件 MaixPy/MaixCDK 目前支持了 YOLOv8 / YOLO11 检测 以及 YOLOv8 pose / YOLO11 pose 关键点检测 以及 YOLOv8 seg / YOLO11 seg 三种模型（2024.10.10）。 按照[MaixCAM 模型转换](../ai_model_converter/maixcam.html) 和 [MaixCAM2 模型转换](../ai_model_converter/maixcam2.html) 进行模型转换。 ### 输出节点选择 注意模型输出节点的选择（**注意可能你的模型可能数值不完全一样，看下面的图找到相同的节点即可**）： 对于 YOLO11 / YOLOv8， MaixPy 支持了两种节点选择，可以根据硬件平台适当选择： 模型和特点 方案一 方案二 适用设备 **MaixCAM2**(推荐)<br>MaixCAM(速度比方案二慢一点点) **MaixCAM**(推荐) 特点 将更多的计算给 CPU 后处理，量化更不容易出问题，速度略微慢于方案二 将更多的计算给 NPU 并且参与量化 注意点 无 MaixCAM2 实测量化失败 检测 YOLOv8 `/model.22/Concat_1_output_0`<br>`/model.22/Concat_2_output_0`<br>`/model.22/Concat_3_output_0` `/model.22/dfl/conv/Conv_output_0`<br>`/model.22/Sigmoid_output_0` 检测 YOLO11 `/model.23/Concat_output_0`<br>`/model.23/Concat_1_output_0`<br>`/model.23/Concat_2_output_0` `/model.23/dfl/conv/Conv_output_0`<br>`/model.23/Sigmoid_output_0` 关键点 YOLOv8 pose `/model.22/Concat_1_output_0`<br>`/model.22/Concat_2_output_0`<br>`/model.22/Concat_3_output_0`<br>`/model.22/Concat_output_0` `/model.22/dfl/conv/Conv_output_0`<br>`/model.22/Sigmoid_output_0`<br>`/model.22/Concat_output_0` 关键点 YOLO11 pose `/model.23/Concat_1_output_0`<br>`/model.23/Concat_2_output_0`<br>`/model.23/Concat_3_output_0`<br>`/model.23/Concat_output_0` `/model.23/dfl/conv/Conv_output_0`<br>`/model.23/Sigmoid_output_0`<br>`/model.23/Concat_output_0` 分割 YOLOv8 seg`/model.22/Concat_1_output_0`<br>`/model.22/Concat_2_output_0`<br>`/model.22/Concat_3_output_0`<br>`/model.22/Concat_output_0`<br>`output1` `/model.22/dfl/conv/Conv_output_0`<br>`/model.22/Sigmoid_output_0`<br>`/model.22/Concat_output_0`<br>`output1` 分割 YOLO11 seg `/model.23/Concat_1_output_0`<br>`/model.23/Concat_2_output_0`<br>`/model.23/Concat_3_output_0`<br>`/model.23/Concat_output_0`<br>`output1``/model.23/dfl/conv/Conv_output_0`<br>`/model.23/Sigmoid_output_0`<br>`/model.23/Concat_output_0`<br>`output1` 旋转框 YOLOv8 obb `/model.22/Concat_1_output_0`<br>`/model.22/Concat_2_output_0`<br>`/model.22/Concat_3_output_0`<br>`/model.22/Concat_output_0``/model.22/dfl/conv/Conv_output_0`<br>`/model.22/Sigmoid_1_output_0`<br>`/model.22/Sigmoid_output_0` 旋转框 YOLO11 obb `/model.23/Concat_1_output_0`<br>`/model.23/Concat_2_output_0`<br>`/model.23/Concat_3_output_0`<br>`/model.23/Concat_output_0``/model.23/dfl/conv/Conv_output_0`<br>`/model.23/Sigmoid_1_output_0`<br>`/model.23/Sigmoid_output_0` YOLOv8/YOLO11 检测输出节点图 ![](../../assets/yolo11_detect_nodes.png) ![](../../assets/yolov8_out.jpg) YOLOv8/YOLO11 pose 额外输出节点 ![](../../assets/yolo11_pose_node.png) 见上图 pose 分支 YOLOv8/YOLO11 seg 额外输出节点 ![](../../assets/yolo11_seg_node.png) ![](../../assets/yolo11_seg_node.png) YOLOv8/YOLO11 OBB 额外输出节点 ![](../../assets/yolo11_obb_node.png) ![](../../assets/yolo11_out_obb.jpg) ### 修改 mud 文件 对于物体检测，mud 文件为（YOLO11 model_type 改为 yolo11） MaixCAM/MaixCAM Pro: ```ini [basic] type cvimodel model yolov8n.cvimodel [extra] model_type yolov8 input_type rgb mean 0, 0, 0 scale 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 labels person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair drier, toothbrush ``` MaixCAM2: ```ini [basic] type axmodel model_npu yolo11n_640x480_npu.axmodel model_vnpu yolo11n_640x480_vnpu.axmodel [extra] model_type yolo11 type detector input_type rgb labels person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair drier, toothbrush input_cache true output_cache true input_cache_flush false output_cache_inval true mean 0,0,0 scale 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 ``` 根据你训练的对象替换`labels`即可。 对于关键点检测(yolov8 pose)，修改 `type pose`。 对于关键点检测(yolov8 seg)，修改 `type seg`。 对于关键点检测(yolov8 obb)，修改 `type obb`。 ## 上传分享到 MaixHub 到 [MaixHub 模型库](https://maixhub.com/model/zoo?platform maixcam) 上传并分享你的模型，可以多提供几个分辨率供大家选择。"},"/maixpy/doc/zh/vision/apriltag.html":{"title":"MaixCAM MaixPy 识别 Apriltag 标签","content":" title: MaixCAM MaixPy 识别 Apriltag 标签 update: date: 2024 04 03 author: lxowalle version: 1.0.0 content: 初版文档 阅读本文前，确保已经知晓如何开发MaixCAM，详情请阅读[快速开始](../index.html) ## 简介 本文介绍如何使用MaixPy来识别Apriltag标签 ## 使用 MaixPy 识别Apriltag标签 MaixPy的 `maix.image.Image`中提供了`find_apriltags`方法，可以可以识别apriltag标签。 ### 如何识别Apriltag标签 一个简单的示例，实现识别apriltag标签并画框 ```python from maix import image, camera, display cam camera.Camera() disp display.Display() families image.ApriltagFamilies.TAG36H11 x_scale cam.width() / 160 y_scale cam.height() / 120 while 1: img cam.read() new_img img.resize(160, 120) apriltags new_img.find_apriltags(families families) for a in apriltags: corners a.corners() for i in range(4): corners[i][0] int(corners[i][0] * x_scale) corners[i][1] int(corners[i][1] * y_scale) x int(a.x() * x_scale) y int(a.y() * y_scale) w int(a.w() * x_scale) h int(a.h() * y_scale) for i in range(4): img.draw_line(corners[i][0], corners[i][1], corners[(i + 1) % 4][0], corners[(i + 1) % 4][1], image.COLOR_RED) img.draw_string(x + w, y, \"id: \" + str(a.id()), image.COLOR_RED) img.draw_string(x + w, y + 15, \"family: \" + str(a.family()), image.COLOR_RED) disp.show(img) ``` 步骤： 1. 导入image、camera、display模块 ```python from maix import image, camera, display ``` 2. 初始化摄像头和显示 ```python cam camera.Camera() disp display.Display() ``` 3. 从摄像头获取图片并显示 ```python while 1: img cam.read() disp.show(img) ``` 4. 调用`find_apriltags`方法识别摄像头图片中的apriltag标签 ```python new_img img.resize(160, 120) apriltags new_img.find_apriltags(families families) ``` `img`是通过`cam.read()`读取到的摄像头图像 `img.resize(160, 120)`是用来将图像缩放得更小，用更小的图像来让算法计算得更快 `new_img.find_apriltags(families families)`用来寻找apriltag标签，并将查询结果保存到`apriltags`，以供后续处理。其中families用来选择apriltag族，默认为`image.ApriltagFamilies.TAG36H11` 5. 处理识别标签的结果并显示到屏幕上 ```python for a in apriltags: # 获取位置信息（并映射坐标到原图） x int(a.x() * x_scale) y int(a.y() * y_scale) w int(a.w() * x_scale) corners a.corners() for i in range(4): corners[i][0] int(corners[i][0] * x_scale) corners[i][1] int(corners[i][1] * y_scale) # 显示 for i in range(4): img.draw_line(corners[i][0], corners[i][1], corners[(i + 1) % 4][0], corners[(i + 1) % 4][1], image.COLOR_RED) img.draw_string(x + w, y, \"id: \" + str(a.id()), image.COLOR_RED) img.draw_string(x + w, y + 15, \"family: \" + str(a.family()), image.COLOR_RED) img.draw_string(x + w, y + 30, \"rotation : \" + str(180 * a.rotation() // 3.1415), image.COLOR_RED) ``` 遍历`apriltags`的成员，`apriltags`是通过`img.find_apriltags()`扫描apriltag标签的结果，如果找不到标签则`apriltags`的成员为空 `x_scale`和`y_scale`用来映射坐标，由于`new_img`是缩放后的图像，计算apriltag的坐标时需要经过映射后才能正常的画在原图`img`上 `a.corners()`用来获取已扫描到的标签的四个顶点坐标，`img.draw_line()`利用这四个顶点坐标画出标签的形状 `img.draw_string`用来显示标签的内容，其中`a.x()`和`a.y()`用来获取标签左上角坐标x和坐标y，`a.id()`用来获取标签的id，`a.family()`用来获取标签族类型，`a.rotation()`用来获取标签的旋转角度。 ### 常用参数说明 列举常用参数说明，如果没有找到可以实现应用的参数，则需要考虑是否使用其他算法实现，或者基于目前算法的结果扩展所需的功能 参数 说明 示例 roi 设置算法计算的矩形区域，roi [x, y, w, h]，x，y表示矩形区域左上角坐标，w，h表示矩形区域的宽度和高度，默认为整张图片 计算坐标为(50,50)，宽和高为100的区域<br />```img.find_apriltags(roi [50, 50, 100, 100])``` families apriltag标签家族类型 扫描TAG36H11家族的标签<br />```img.find_apriltags(families image.ApriltagFamilies.TAG36H11)``` 本文介绍常用方法，更多 API 请看 API 文档的 [image](../../../api/maix/image.html) 部分。 ### 测距1：物体垂直与摄像头的距离 这里提供一种使用`distance k/width`的公式来测距, 其中`distance`是摄像头和物体的距离,单位`mm`, `k`是一个常量, `width`是物体在画面中的宽度,单位是像素点. 测量方法分两步: 1. 测量常量系数k; 2. 通过常量系数和标签宽度来计算物体与摄像头的距离 #### 前期准备 1. `apriltag`标签纸 2. 尺子(或其他测距工具) #### 测量常量系数k 将`apriltag`标签纸固定,并在距离`apriltag`标签20cm处固定`maixcam` 使用`maixcam`检测`apriltag`标签并计算标签的宽度, 参考代码: ```python from maix import camera, display import math ''' x1,y1,x2,y2: apriltag宽度的两点坐标, 一般通过corners()方法获取 返回标签的宽度,单位为像素点 ''' def caculate_width(x1, y1, x2, y2): return math.sqrt((x2 x1)**2 + (y2 y1)**2) cam camera.Camera(160, 120) disp display.Display() while 1: img cam.read() apriltags img.find_apriltags() for a in apriltags: corners a.corners() # 通过水平方向的两个坐标点计算宽度 width caculate_width(corners[0][0], corners[0][1], corners[1][0], corners[1][1]) # 打印apriltag标签的实际宽度 print(f'apriltag width:{width}') disp.show(img) ``` 计算常量系数k ```python ''' width: 当距离为distance时,检测到apriltag标签的宽度 distance: 检测apriltag标签时距离apriltag标签的实际距离, 单位mm 返回常量系数 ''' def caculate_k(width, distance): return width * distance # 距离200mm时检测到标签宽度为43个像素 k caculate_k(43, 200) ``` #### 通过常量系数计算摄像头和物体间的距离 ```python ''' width: apriltag标签的宽度 k: 常量系数 返回摄像头与物体的距离,单位mm ''' def caculate_distance(width, k): return k / width distance caculate_distance(55, 8600) ``` #### 完整的代码参考: ```python from maix import camera, display, image import math ''' x1,y1,x2,y2: apriltag宽度的两点坐标, 一般通过corners()方法获取 返回标签的宽度,单位为像素点 ''' def caculate_width(x1, y1, x2, y2): return math.sqrt((x2 x1)**2 + (y2 y1)**2) ''' width: 当距离为distance时,检测到apriltag标签的宽度 distance: 检测apriltag标签时距离apriltag标签的实际距离, 单位mm 返回常量系数 ''' def caculate_k(width, distance): return width * distance ''' width: apriltag标签的宽度 k: 常量系数 返回摄像头与物体的距离,单位mm ''' def caculate_distance(width, k): return k / width cam camera.Camera(192, 108) disp display.Display() # 距离200mm时检测到标签宽度为43个像素 k caculate_k(43, 200) while 1: img cam.read() apriltags img.find_apriltags() for a in apriltags: corners a.corners() for i in range(4): img.draw_line(corners[i][0], corners[i][1], corners[(i + 1) % 4][0], corners[(i + 1) % 4][1], image.COLOR_GREEN) # 通过水平方向的两个坐标点计算宽度 width caculate_width(corners[0][0], corners[0][1], corners[1][0], corners[1][1]) # 计算距离 distance caculate_distance(width, k) print(f'apriltag width:{width} distance:{distance} mm') disp.show(img) ``` 上面的方法是通过`apriltag`的宽度计算距离, 同样也可以扩展为使用高度来计算距离. 但需要注意该方法是在对距离估测, 实际应用中会有些许误差存在. ### 测距2：利用apriltag标签测量物体到摄像头的距离 通过`apriltag`标签测距，可以比较准确的测量标签在空间中的位置，这里我们也利用`find_apriltag()`方法返回的参数来计算任意位置的`apriltag`标签到摄像头的位置，当然前提是你必须检测到`apriltag`标签。 测量方法共两步：1. 计算常量系数k。2.通过`find_apriltag()`返回的位置信息计算标签到摄像头的距离 优点：可以在`apriltag`标签旋转、与摄像头有偏移的情况测量出标签到摄像头的距离 #### 前期准备 1. `apriltag`标签纸 2. 尺子(或其他测距工具) #### 测量常量系数 将`apriltag`标签纸固定,并在距离`apriltag`标签20cm处固定`maixcam` 使用`maixcam`检测`apriltag`标签并通过`z_translation`计算常量系数, 参考代码: ```python from maix import camera, display ''' z_trans: 当距离为distance时,检测到apriltag标签z_translation()的值 distance: 检测apriltag标签时距离apriltag标签的实际距离, 单位mm 返回常量系数 ''' def caculate_k(z_trans, distance): return distance / z_trans cam camera.Camera(160, 120) disp display.Display() while 1: img cam.read() apriltags img.find_apriltags() for a in apriltags: k caculate_k(a.z_translation(), 200) print(f\"k:{k}\") disp.show(img) ``` #### 测量标签到物体的距离 通过`apriltag`标签返回的`x_translation`,`y_translation`和`z_translation`计算标签到摄像头的距离 ```python ''' x_trans: 检测apriltag标签返回的x_translation()的值 y_trans: 检测apriltag标签返回的y_translation()的值 z_trans: 检测apriltag标签返回的z_translation()的值 k: 常量系数 返回距离, 单位mm ''' def calculate_distance(x_trans, y_trans, z_trans, k): return k * math.sqrt(x_trans * x_trans + y_trans * y_trans + z_trans * z_trans) ``` #### 完整的代码参考: ```python from maix import camera, display, image import math ''' z_trans: 当距离为distance时,检测到apriltag标签z_translation()的值 distance: 检测apriltag标签时距离apriltag标签的实际距离, 单位mm 返回常量系数 ''' def caculate_k(z_trans, distance): return distance / z_trans ''' x_trans: 检测apriltag标签返回的x_translation()的值 y_trans: 检测apriltag标签返回的y_translation()的值 z_trans: 检测apriltag标签返回的z_translation()的值 k: 常量系数 返回距离, 单位mm ''' def calculate_distance(x_trans, y_trans, z_trans, k): return abs(k * math.sqrt(x_trans * x_trans + y_trans * y_trans + z_trans * z_trans)) cam camera.Camera(160, 120) disp display.Display() # 距离200mm时检测到apriltag标签返回的z_translation()为 9.7 k caculate_k( 9.7, 200) while 1: img cam.read() apriltags img.find_apriltags() for a in apriltags: corners a.corners() for i in range(4): img.draw_line(corners[i][0], corners[i][1], corners[(i + 1) % 4][0], corners[(i + 1) % 4][1], image.COLOR_GREEN) # 计算距离 x_trans a.x_translation() y_trans a.y_translation() z_trans a.z_translation() distance calculate_distance(x_trans, y_trans, z_trans, k) print(f'apriltag k:{k} distance:{distance} mm') disp.show(img) ``` 这段代码使用 `MaixCAM` 不断读取摄像头图像，检测 `apriltag`，并通过常量系数以及标签在三个轴向的位移计算标签到摄像头的距离。计算出的距离以毫米为单位打印出来, 需要注意该方法仍是在对距离估测, 实际应用中会有些许误差存在。"},"/maixpy/doc/zh/vision/qrcode.html":{"title":"MaixCAM MaixPy 二维码识别","content":" title: MaixCAM MaixPy 二维码识别 update: date: 2024 04 03 author: lxowalle version: 1.0.0 content: 初版文档 阅读本文前，确保已经知晓如何开发MaixCAM，详情请阅读[快速开始](../index.html) ## 简介 本文介绍如何使用MaixPy来识别二维码 ## 使用 MaixPy 识别二维码 MaixPy的 `maix.image.Image`中提供了`find_qrcodes`方法，用来识别二维码。 ### 如何识别二维码 一个简单的示例，实现识别二维码并画框 ```python from maix import image, camera, display cam camera.Camera(320, 240) disp display.Display() while 1: img cam.read() qrcodes img.find_qrcodes() for qr in qrcodes: corners qr.corners() for i in range(4): img.draw_line(corners[i][0], corners[i][1], corners[(i + 1) % 4][0], corners[(i + 1) % 4][1], image.COLOR_RED) img.draw_string(qr.x(), qr.y() 15, qr.payload(), image.COLOR_RED) disp.show(img) ``` 步骤： 1. 导入image、camera、display模块 ```python from maix import image, camera, display ``` 2. 初始化摄像头和显示 ```python cam camera.Camera(320, 240) # 初始化摄像头，输出分辨率320x240 RGB格式 disp display.Display() ``` 3. 从摄像头获取图片并显示 ```python while 1: img cam.read() disp.show(img) ``` 4. 调用`find_qrcodes`方法识别摄像头中的二维码 ```python qrcodes img.find_qrcodes() ``` `img`是通过`cam.read()`读取到的摄像头图像，当初始化的方式为`cam camera.Camera(320, 240)`时，`img`对象是一张分辨率为320x240的RGB图。 `img.find_qrcodes`用来寻找二维码，并将查询结果保存到`qrocdes`，以供后续处理 5. 处理识别二维码的结果并显示到屏幕上 ```python for qr in qrcodes: corners qr.corners() for i in range(4): img.draw_line(corners[i][0], corners[i][1], corners[(i + 1) % 4][0], corners[(i + 1) % 4][1], image.COLOR_RED) img.draw_string(qr.x(), qr.y() 15, qr.payload(), image.COLOR_RED) ``` `qrcodes`是通过`img.find_qrcodes()`查询二维码的结果，如果找不到二维码则`qrcodes`内部为空 `qr.corners()`用来获取已扫描到的二维码的四个顶点坐标，`img.draw_line()`利用这四个顶点坐标画出二维码的形状 `img.draw_string`用来显示二维码的内容和位置等信息，其中`qr.x()`和`qr.y()`用来获取二维码左上角坐标x和坐标y，`qr.payload()`用来获取二维码的内容 ### 常用参数说明 列举常用参数说明，如果没有找到可以实现应用的参数，则需要考虑是否使用其他算法实现，或者基于目前算法的结果扩展所需的功能 参数 说明 示例 roi 设置算法计算的矩形区域，roi [x, y, w, h]，x，y表示矩形区域左上角坐标，w，h表示矩形区域的宽度和高度，默认为整张图片 计算坐标为(50,50)，宽和高为100的区域<br />```img.find_qrcodes(roi [50, 50, 100, 100])``` qrcoder_type 设置二维码库解码器类型，可以选择image.QRCodeDecoderType.QRCODE_DECODER_TYPE_ZBAR或者image::QRCodeDecoderType::QRCODE_DECODER_TYPE_QUIRC. QRCODE_DECODER_TYPE_ZBAR在分辨率较小时识别速度更快，识别精度更高. QRCODE_DECODER_TYPE_QUIRC在分辨率较大时相对速度更快，但识别精度相对较低. 默认使用QRCODE_DECODER_TYPE_ZBAR.<br />v4.7.7及以后的版本有效. img.find_qrcodes(decoder_type image.QRCodeDecoderType.QRCODE_DECODER_TYPE_ZBAR) 本文介绍常用方法，更多 API 请看 API 文档的 [image](../../../api/maix/image.html) 部分。 ## 使用硬件加速的方法识别二维码 MaixPy内置了一个`image.QRCodeDetector`对象可以使用硬件加速的方法识别二维码，在320x224分辨率下单帧算法最高速度可以到60+fps > 注：MaixPy v4.7.8之后的版本支持该方法（不包括v4.7.8） ### 使用方法 ```python from maix import camera, display, app, image cam camera.Camera(320, 224) disp display.Display() detector image.QRCodeDetector() while not app.need_exit(): img cam.read() qrcodes detector.detect(img) for q in qrcodes: img.draw_string(0, 0, \"payload: \" + q.payload(), image.COLOR_BLUE) disp.show(img) ``` 步骤： 1. 导入image、camera、display模块 ```python from maix import camera, display, app, image ``` 2. 捕获和显示图像 ```python cam camera.Camera(320, 224) disp display.Display() while not app.need_exit(): img cam.read() disp.show(img) ``` 创建`Camera`和`Display`对象，通过`cam.read()`方法来捕获图像，用`disp.show()`方法来显示图像 3. 创建`QRCodeDetector`对象来检测二维码 ```python detector image.QRCodeDetector() ``` 4. 使用`detect`方法来检测二维码，检测结果保存到`qrcodes`变量中 ```python qrcodes detector.detect(img) for q in qrcodes: img.draw_string(0, 0, \"payload: \" + q.payload(), image.COLOR_BLUE) ``` 注意：检测过程中会占用NPU资源，如果此时有其他模型也再使用，则可能导致意外的结果 检测的结果与`find_qrcodes`返回结果的数据结构一致，参考`QRCode`对象的方法来获取检测结果。例如：调用`q.payload()`即可获取二维码的内容字符串。"},"/maixpy/doc/zh/vision/face_emotion.html":{"title":"MaixCAM MaixPy 人脸表情情绪识别、性别、口罩，年龄等识别","content":" title: MaixCAM MaixPy 人脸表情情绪识别、性别、口罩，年龄等识别 update: date: 2025 01 010 version: v1.0 author: neucrack content: 增加人脸情绪识别源码、文档、例程 ## 简介 前面的文章[人脸检测和少量关键点检测](./face_detection.html) 和 [人脸多个关键点]中介绍了如何检测人脸，以及关键点，以及人脸识别，本文介绍如何识别人脸情绪（表情）。 以及介绍如何实现识别其它特征，比如性别、是否戴口罩、年龄等等。 ![](../../assets/face_emotion_happy.jpg) ![](../../assets/face_emotion_neutral.jpg) 在 MaixCAM 上的效果视频： <video playsinline controls autoplay loop muted preload src \"/static/video/maixcam_face_emotion.mp4\" type \"video/mp4\"> Classifier Result video </video> > 视频素材来自 [oarriaga/face_classification](https://github.com/oarriaga/face_classification) ## 在 MaixCAM MaixPy 中使用人脸表情(情绪)识别 MaixPy 默认提供的情绪识别有 7 个分类，包括： * angry: 生气 * disgust: 恶心 * fear: 害怕 * happy: 高兴 * sad: 悲伤 * surprise: 惊讶 * neutral: 自然状态 情绪识别分了几个步骤： * 检测人脸。 * 将人脸裁切出来变成一个比较标准的人脸图，如上面图中左上角小图。 * 将小图使用一个简单的分类模型进行分类。 在MaixPy 中，先使用`yolov8 face` 模型进行人脸和眼睛的位置检测，然后再进行分类，代码如下，完整代码也可以在[MaixPy](https://github.com/sipeed/maixpy) `examples`目录中找到： ```python from maix import camera, display, image, nn, app detect_conf_th 0.5 detect_iou_th 0.45 emotion_conf_th 0.5 max_face_num 1 crop_scale 0.9 # detect face model detector nn.YOLOv8(model \"/root/models/yolov8n_face.mud\", dual_buff False) # we only use one of it's function to crop face from image, wo we not init model actually landmarks_detector nn.FaceLandmarks(model \"\") # emotion classify model classifier nn.Classifier(model \"/root/models/face_emotion.mud\", dual_buff False) cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) disp display.Display() # for draw result info max_labels_length 0 for label in classifier.labels: size image.string_size(label) if size.width() > max_labels_length: max_labels_length size.width() max_score_length cam.width() / 4 while not app.need_exit(): img cam.read() results [] objs detector.detect(img, conf_th detect_conf_th, iou_th detect_iou_th, sort 1) count 0 idxes [] img_std_first : image.Image None for i, obj in enumerate(objs): img_std landmarks_detector.crop_image(img, obj.x, obj.y, obj.w, obj.h, obj.points, classifier.input_width(), classifier.input_height(), crop_scale) if img_std: img_std_gray img_std.to_format(image.Format.FMT_GRAYSCALE) res classifier.classify(img_std_gray, softmax True) results.append(res) idxes.append(i) if i 0: img_std_first img_std count + 1 if max_face_num > 0 and count > max_face_num: break for i, res in enumerate(results): # draw fisrt face detailed info if i 0: img.draw_image(0, 0, img_std_first) for j in range(len(classifier.labels)): idx res[j][0] score res[j][1] img.draw_string(0, img_std_first.height() + idx * 16, classifier.labels[idx], image.COLOR_WHITE) img.draw_rect(max_labels_length, int(img_std_first.height() + idx * 16), int(score * max_score_length), 8, image.COLOR_GREEN if score > emotion_conf_th else image.COLOR_RED, 1) img.draw_string(int(max_labels_length + score * max_score_length + 2), int(img_std_first.height() + idx * 16), f\"{score:.1f}\", image.COLOR_RED) # draw on all face color image.COLOR_GREEN if res[0][1] > emotion_conf_th else image.COLOR_RED obj objs[idxes[i]] img.draw_rect(obj.x, obj.y, obj.w, obj.h, color, 1) img.draw_string(obj.x, obj.y, f\"{classifier.labels[res[0][0]]}: {res[0][1]:.1f}\", color) disp.show(img) ``` 可以看到，这里核心代码就是： ```python objs detector.detect(img, conf_th detect_conf_th, iou_th detect_iou_th, sort 1) img_std landmarks_detector.crop_image(...) img_std_gray img_std.to_format(image.Format.FMT_GRAYSCALE) res classifier.classify(img_std_gray, softmax True) ``` 分别对应了上面讲的： * 找人脸。 * 裁切人脸。 * 使用分类模型预测类别（输入用了灰度图像输入，所以先转为灰度图）。 ## 优化识别精确度 MaixPy 默认提供了一个 7 分类的模型，是基于图片输入的分类，为了得到精确度更好的识别，以及更适合你你可以从以下方面优化模型： * 用关键点作为分类模型的输入: 除了使用小图，也可以不用图像作为输入，可以前面文章中检测到的人脸关键点作为分类模型的输入，这样去掉了背景的影响，模型更容易训练，理论上精度更高。 * 优化数据集，增加样本量。 * 优化裁切图的步骤：这里裁切小图用了比较简单的变换，借用了`landmarks_detector.crop_image` 函数，利用人脸的两只眼睛的位置进行图像旋转和裁切。你也可以用更精准的变换算法讲脸变换到固定位置，比如人脸识别中使用的放射变换等。 ## 自定义分类训练模型 这里只讲输入为图像的方式，为关键点数据的请自行琢磨。 详细步骤： * 确定分类类别：比如上面的 7 个分类，或者识别性别、是否戴口罩等等。 * 确定模型：分类一般使用一个很小的分类模型即可，用几个卷积搭建的模型就可以，也可以用现成的比如 MobilenetV2 等模型，根据自己的精度要求和运行时间要求选择，建议直接用 Mobilenet 试试，跑通再尝试其它的。 * 确定训练平台： * 可以直接使用 [MaixHub](https://maixhub.com) 进行在线训练，创建分类项目，这种方式好处是无需搭建环境和写代码，一键训练生成模型（**推荐**）。 * 也可以自己在本地搭建 pytorch 或者 tensorflow 环境，自行搜索 mobilenet 分类模型训练教程。 * 采集数据：直接基于上面的代码修改为采集程序，比如把摄像头读取到的`img`以及裁切过后的`img_std`标准人脸图像都采集保存到文件系统（使用`img.save(\"/root/image0.jpg\")`类似的方法），然后传输到电脑备用。 * 其它数据集：当然你也可以从网上找数据，最好是用 MaixPy 识别一遍将标准图像裁切出来保存。 * 数据清洗：检查一下数据中是否有不正确的数据，进行整理，每个类别放一个文件夹下。 * 训练： * 在 MaixHub 上传数据进行训练：会得到一个包含模型文件的压缩包，直接是 MaixPy 支持的格式。 * 离线训练：训练完成后需要转换成 onnx 模型格式，然后按照[模型转换为MUD文件](../ai_model_converter/maixcam.html) 进行模型转换，安装环境会比较麻烦。 * 运行：替换例程中的分类模型即可。 ## 识别其它面部特征，比如性别、是否戴口罩、年龄等 如上面所说，原理和训练情绪识别一样，用一个分类模型，使用不同数据即可，识别年龄这种数值需要使用回归模型，可以自行网上搜索学习。"},"/maixpy/doc/zh/vision/camera.html":{"title":"MaixCAM MaixPy 摄像头使用","content":" title: MaixCAM MaixPy 摄像头使用 update: date: 2024 04 03 author: neucrack version: 1.0.0 content: 初版文档 date: 2024 08 21 author: YWJ version: 1.0.1 content: 修正文档部分bug,增加部分内容 date: 2024 10 24 author: neucrack version: 1.1.0 content: 增加 USB 摄像头支持说明 date: 2025 07 28 author: neucrack & lxo version: 1.2.0 content: 添加 AWB 和镜头使用文档。 ## 简介 对于 MaixCAM 默认搭载了 GC4653 摄像头，或者可选的 OS04A10 摄像头或者全局快门摄像头，甚至是 HDMI 转 MIPI 模块，都可以直接用简单的 API 调用。 ## API 文档 本文介绍常用方法，更多 API 使用参考 [maix.camera](/api/maix/camera.html) 模块的文档。 ## 摄像头切换 目前支持的摄像头： * **GC4653**：M12 通用镜头, 1/3\" 传感器，画质清晰， 4M 像素。适合常见场景，比如AI识别、图像处理等。 * **OS04A10**：M12 通用镜头，1/1.8\" 大底传感器，画质超清， 4M像素。适合对画质有要求的场景，比如拍照、视频录制等，注意发热量也会更大。 * **OV2685**：不支持镜头更换，1/5\"传感器，2M 像素，画质最差，成本最低，一般不建议使用。 * **SC035HGS**：黑白全局快门摄像头，30W黑白像素，适合拍摄高速物体。 系统会自动切换，只接硬件换上即可使用。 ## 镜头盖 镜头盖遮灰尘用，**请先取下镜头盖！！**再使用。 ## 摄像头调焦距 对于 MaixCAM，默认配的是**手动调焦镜头**，物理上拧镜头可以实现调整焦距。 如果你发现**画面模糊**，可以尝试拧镜头（顺时针和逆时针进行尝试）来对焦使画面清晰。 ## 获取摄像头的图像信息 使用 MaixPy 轻松获取： ```python from maix import camera cam camera.Camera(640, 480) while 1: img cam.read() print(img) ``` 这里我们从`maix`模块导入`camera`模块，然后创建一个`Camera`对象，指定图像的宽度和高度。然后在一个循环中不断读取图像， 默认出的图为`RGB`格式，如果需要`BGR`格式，其它格式请看 API 文档。 你还可以获取灰度图像 ```python from maix import camera, image cam camera.Camera(640, 480, image.Format.FMT_GRAYSCALE)\t# 设置输出灰度图像 ``` 还可以获取NV21图像 ```python from maix import camera, image cam camera.Camera(640, 480, image.Format.FMT_YVU420SP)\t# 设置输出NV21图像 ``` ## 设置摄像头的分辨率 代码中直接指定宽高即可： ```python from maix import camera cam camera.Camera(width 640, height 480) ``` 或 ```python from maix import camera cam camera.Camera() cam.set_resolution(width 640, height 480) ``` ### 分辨率大小选择 不同板子和摄像头模组支持的分辨率不同，首先请使用偶数分辨率值。 重要的一点需要明确，分辨率不是越高越高，根据使用场景选择合适的分辨率。 * 拍照/摄影/监控: 这种场景我们可能希望更大分辨率更清晰。 GC4653和OS04A10最大支持`2560x1440`分辨率，也就是 `2K/4M像素`，不过更大分辨率对编程能力和内存要求更高，可以稍微用小一点的分辨率比如`1920x1080`，`1280x720`，`640x480`等。 注意：使用 `MaixVision` 在线运行代码，如果设置了很高的分辨率（例如`2560x1440`），需要关闭 MaixVision 的图像预览功能，否则可能会因为内存不足导致代码运行异常。 * AI 识别 / 图像处理：为了让模型和算法运行更快，我们需要在能识别到的情况下尽量降低分辨率。 * `640x480`：VGA 分辨率，对于 AI 和算法来说是比较大的分辨率了，能满足大部分 AI 识别和图像**清晰处理**的需求。对于 MaixCAM 很多算法比较吃力，对于 MaixCAM2 则比较轻松。 * `320x320`：正方形，适合一些 AI 模型，但是一般屏幕是长方形的，显示起来两边会有黑边。 * `320x240`: QVGA 分辨率，对于 AI 和视觉算法来说比较容易运算，同时也能满足大部分清晰度要求。 * `320x224`: 宽高都是 32 的倍数，比较适合想要分辨率小，同时适合 AI 模型输入，同时宽高比和 MaixCAM 自带的屏幕 `552x368` 比较相近的分辨率方便显示。 * `224x224`：正方形，宽高都是 32 的倍数，比较适合想要分辨率小，同时适合 AI 模型输入，比如 `MobileNetV2`，`MobileNetV3` 等模型输入。 ### 分辨率宽高比 分辨率宽高比会影响视野范围，比如传感器最大是`2560x1440`，即`16:9`的宽高比，使用`640x480`分辨率时，宽高比变成了`4:3`，视野范围会变小，如果你想要视野最大化，则建议使用和传感器相同的分辨率比例，比如`1280x720`，`2560x1440`等。 一般宽高比不同，会对画面进行居中裁剪。 ## 设置摄像头的帧率 摄像头会设置在特定的帧率下工作，MaixPy 支持设置摄像头的帧率。不同摄像头模组支持的帧率不同。 GC4653 OS04A10 OV2685 SC035HGS 2560x1440@30fps<br>1280x720@60fps<br>1280x720@80fps 2560x1440@30fps<br>1280x720@80fps 1920x1080@30fps 640x480@180fps 由创建`Camera`对象时传入的`width`，`height`，`fps`参数来选择帧率。 ### 设置帧率为30帧 ```python from maix import camera cam camera.Camera(640, 480, fps 30)\t\t\t# 设置帧率为30帧 # or cam camera.Camera(1920, 1280) # 分辨率高于1280x720时帧率会设置为30帧 ``` ### 设置帧率为60帧 ```python from maix import camera cam camera.Camera(640, 480, fps 60)\t # 设置帧率为60帧 # or cam camera.Camera(640, 480) # 分辨率低于或等于1280x720时帧率会设置为80fps ``` ### 设置帧率为80帧 ```python from maix import camera cam camera.Camera(640, 480, fps 80)\t # 设置帧率为80帧 ``` 注意： 1. 如果`Camera`传入的尺寸大于`1280x720`，例如写成`camera.Camera(1920, 1080, fps 60)`，此时`fps`参数将会失效，帧率将保持在`30fps`。 2. `60/80fps`与`30fps`的画面相比会有几个像素的偏移，在对视角有严格要求的应用下需要注意修正偏移。 3. 需要注意由于`60/80fps`和`30fps`共用了`isp`配置，在某些环境下两种帧率下的画面画质会存在一些偏差。 4. 摄像头需要看体制，有些体制无法设置到80fps，会出现画面有奇怪的纹路，请换回正常的60fps使用。 ## 图像矫正 对于画面存在鱼眼等畸变的情况，可以使用`Image`对象下的`lens_corr`函数对图片进行畸变矫正。一般情况只需要调大和调小`strength`的值来将画面调整到合适效果即可。 ```python from maix import camera, display,app,time cam camera.Camera(320, 240) disp display.Display() while not app.need_exit(): t time.ticks_ms() img cam.read() img img.lens_corr(strength 1.5)\t# 调整strength的值直到画面不再畸变 disp.show(img) ``` 注意由于是软件矫正，运行需要耗费一定时间，另外也可以只接用无畸变镜头（询问商家）从硬件层面解决。 ## 跳过 开头的帧 摄像头初始化的一小段时间，可能图像采集还没稳定出现奇怪的画面，如果你不想画面看到这些画面，可以通过`skip_frames`函数跳过开头的几帧或者刚开始读取的图像不用就好了： ```python cam camera.Camera(640, 480) cam.skip_frames(30) # 跳过开头的30帧 ``` ## 显示摄像头获取的图像 MaixPy 提供了`display`模块，可以方便的显示图像： ```python from maix import camera, display cam camera.Camera(640, 480) disp display.Display() while 1: img cam.read() disp.show(img) ``` ## 设置摄像头参数 ### 设置曝光时间 注意设置曝光时间后，摄像头会切换到手动曝光模式，如果要切换回自动曝光模式需运行`cam.exp_mode(camera.AeMode.Auto)` ```python from maix import camera cam camera.Camera() cam.exposure(1000) ``` ### 设置增益 注意设置增益后，摄像头会切换到手动曝光模式，如果要切换回自动曝光模式需运行`cam.exp_mode(camera.AeMode.Auto)`。自定义的增益值只能在手动曝光模式下生效。 ```python from maix import camera cam camera.Camera() cam.gain(100) ``` ### 设置白平衡 一般情况下自动白平衡就足够了，某些特殊情况，比如检测颜色，或者拍摄特定颜色的物体时，可能需要手动设置白平衡来防止颜色偏差。 目前只支持通过设置增益来手动设置白平衡, 先用`cam.awb_mode(camera.AwbMode.Manual)` 禁用自动白平衡，然后通过 `set_wb_gain()` 传入一个长度为4的数组，分别对应`R`,`Gr`,`Gb`,`B`的增益值, 范围为 `[0.0, 1.0]`。 这里有一个默认增益值，可以基于这个值调整： * `MaixCAM`: `[0.134, 0.0625, 0.0625, 0.1239]` * `MaixCAM2`: `[0.0682, 0, 0, 0.04897]` 通常只需要调整`R`通道和`B`通道, `Gr`和`Gb`通道可以保持不变 ```python from maix import camera cam camera.Camera() cam.awb_mode(camera.AwbMode.Manual)\t\t\t# AwbMode.Auto,开启自动白平衡, AwbMode.Manual,开启手动白平衡; cam.set_wb_gain([0.134, 0.0625, 0.0625, 0.1239]) # 设置r, gr, gb, b四个通道的增益 ``` ### 设置更低抓图延时 通过设置buff_num来减小抓图的延时, 需要注意修改该参数会改变图片缓存大小,降低后可能会导致图像丢失的情况. 对于maixcam, 由于内部软件框架的限制, 即使设置buff_num为1, 实际至少还是会存在一个双缓存, 测试取图延时最低在30+ms左右 ```python from maix import camera cam camera.Camera(buff_num 1) # 只使用1个缓存 ``` ### 设置亮度、对比度和饱和度 ```python from maix import camera cam camera.Camera() cam.luma(50)\t\t # 设置亮度，范围[0, 100] cam.constrast(50)\t\t# 设置对比度，范围[0, 100] cam.saturation(50)\t\t# 设置饱和度，范围[0, 100] ``` ### 读取原始raw图 在某些特殊场景你可能需要读取摄像头的原始`bayer`图像数据，比如需要进行图像处理或者调试等。可以通过设置`raw true`来读取原始图像数据。 注意不同摄像头模组输出的`bayer`图格式可能不一样。 ```python from maix import camera cam camera.Camera(raw true) raw_img cam.read_raw() print(raw_img) ``` 如果需要在第三方软件打开`raw`图，需要额外在PC端进行转换，可以参考[bayer_to_tiff](https://github.com/sipeed/MaixPy/blob/dev/examples/tools/bayer_to_tiff.py)的示例代码 ## 更换镜头 MaixCAM 默认配备了 M12 通用镜头，支持更换镜头。更换镜头时请注意以下几点： 1. 确保新镜头是 M12 接口的镜头。 2. 不同镜头的法兰距（镜头到传感器的距离）不同，自带的镜头座子高度固定的（mm），购买镜头时请确认镜头的法兰距是否适合 MaixCAM 的座子和传感器（不懂可以问商家）。 3. 更换镜头时注意不要刮花或者弄赃传感器表面，否则会严重影响图像质量，如果有毛发灰尘掉上去，可以用气吹轻轻吹掉，吹不掉再考虑用镜头纸轻轻擦拭。 4. 是否可以用变焦镜头？可以，买 M12 接口的变焦镜头即可。 5. 默认都是手动对焦镜头，如果你想用自动对焦，需要购买支持自动对焦的镜头，注意 MaixCAM 的摄像头接口没有自动对焦电路，所以可能需要你自己写程序控制对焦电机。 ## 使用 USB 摄像头 除了使用开发板自带的 MIPI 接口摄像头，你也可以使用 USB 外接 USB 摄像头。 方法： * 先在开发板设置里面`USB设置`中选择`USB 模式`为`HOST`模式。如果没有屏幕，可以用`examples/tools/maixcam_switch_usb_mode.py`脚本进行设置。 * `maix.camera` 模块目前(2024.10.24) 还不支持 USB 摄像头，不过你可以参考 [OpenCV 使用 USB 摄像头](./opencv.html)。"},"/maixpy/doc/zh/vision/self_learn_classifier.html":{"title":"MaixCAM MaixPy 自学习分类器","content":" title: MaixCAM MaixPy 自学习分类器 ## MaixPy 自学习分类器介绍 一般情况下我们要识别新的类别，需要在电脑端重新采集数据集并训练，步骤很麻烦，难度较高，这里提供一种不需要电脑端训练，而是直接在设备端就能秒学习新的物体，适合场景不太复杂的使用场景。 比如眼前有饮料瓶和手机，使用设备分别拍一张它们的照片作为两个分类的依据，然后再采集几张他们各个角度的照片，提取它们的特征保存，然后识别时根据图像的特征值分别和保存的特征值进行对比，和保存的哪个更相近就认为是对应的分类。 ## MaixPy 中使用自学习分类器 默认镜像自带了 [自学习分类 APP](https://maixhub.com/app/30)，可以直接尝试使用熟悉使用流程。 ![](../../assets/self_learn_classifier.jpg) 步骤： * 点击`+ Class` 按钮， 采集 n 张分类(class)图，采集图时物体需要在屏幕的白色框中。 * 点击`+ Sample`按钮，采集 m 张样本图，每个分类都采集一些，顺序无所谓，张数也比较随意，最好是在各个角度拍一点，不要差距过大。 * 点击`Learn`按钮，启动学习，会自动根据采集的分类图和样本图进行分类学习，得到分类的特征。 * 屏幕中央对准物体，识别图像输出结果，可以看到屏幕显示了所属的分类，以及和这个分类的相似距离，相似距离越近则越相似。 * 此 APP 学习后的特征值会存到`/root/my_classes.bin`，所以退出应用或者重启了仍然会自动加载上一次的。 简洁版本代码，完整版本请看[例程](https://github.com/sipeed/maixpy/tree/main/examples/vision/ai_vision)里面的完整代码。 ```python from maix import nn, image classifier nn.SelfLearnClassifier(model \"/root/models/mobilenet_v2_no_top.mud\", dual_buff True) img1 image.load(\"/root/1.jpg\") img2 image.load(\"/root/2.jpg\") img3 image.load(\"/root/3.jpg\") sample_1 image.load(\"/root/sample_1.jpg\") sample_2 image.load(\"/root/sample_2.jpg\") sample_3 image.load(\"/root/sample_3.jpg\") sample_4 image.load(\"/root/sample_4.jpg\") sample_5 image.load(\"/root/sample_5.jpg\") sample_6 image.load(\"/root/sample_6.jpg\") classifier.add_class(img1) classifier.add_class(img2) classifier.add_class(img3) classifier.add_sample(sample_1) classifier.add_sample(sample_2) classifier.add_sample(sample_3) classifier.add_sample(sample_4) classifier.add_sample(sample_5) classifier.add_sample(sample_6) classifier.learn() img image.load(\"/root/test.jpg\") max_idx, max_score classifier.classify(img) print(maix_idx, max_score) ``` ## 储存和加载学习到的特征值 使用 `save` 函数进行储存，会得到一个二进制文件，里面存了物体的特征值。 再使用时用`load`函数进行加载即可。 ```python classifier.save(\"/root/my_classes.bin\") classifier.load(\"/root/my_classes.bin\") ``` 如果你给每一个分类命名了，比如存到了`labels`变量，也可以使用： ```python classifier.save(\"/root/my_classes.bin\", labels labels) labels classifier.load(\"/root/my_classes.bin\") ``` ## dual_buff 双缓冲区加速 你可能注意到这里模型初始化使用了`dual_buff`（默认值就是 `True`），使能 `dual_buff` 参数可以加快运行效率，提高帧率，具体原理和使用注意点见 [dual_buff 介绍](./dual_buff.html)。"},"/maixpy/doc/zh/vision/touchscreen.html":{"title":"MaixPy / MaixCAM 触摸屏使用方法","content":" title: MaixPy / MaixCAM 触摸屏使用方法 ## 简介 对于 MaixCAM 自带了一个触摸屏，写应用时配合触摸屏可以实现很多有趣应用，我们可以通过 API 读取到触摸屏的点按操作。 ## MaixPy 读取触摸 MaixPy 提供了一个简单的`maix.touchscreen.TouchScreen` 类来读取，举例： ```python from maix import touchscreen, app, time ts touchscreen.TouchScreen() pressed_already False last_x 0 last_y 0 last_pressed False while not app.need_exit(): x, y, pressed ts.read() if x ! last_x or y ! last_y or pressed ! last_pressed: print(x, y, pressed) last_x x last_y y last_pressed pressed if pressed: pressed_already True else: if pressed_already: print(f\"clicked, x: {x}, y: {y}\") pressed_already False time.sleep_ms(1) # sleep some time to free some CPU usage ``` ## 配合屏幕实现交互 配合屏幕可以做出一些用户交互的内容，更多可以看[MaixPy/examples/vision/touchscreen](https://github.com/sipeed/MaixPy) 目录下例程。 如前面的文章介绍的，我们要往屏幕显示内容，一般是得到一个`maix.image.Image`对象，然后调用`disp.show(img)`来显示这张图像。 实现一个按钮的最原始和简单的方法就是在这个图像上画一个按钮，然后判断用户触摸到这个区域就算是触发了按下事件，注意图像的大小要和屏幕的大小保持一致： ```python from maix import touchscreen, app, time, display, image ts touchscreen.TouchScreen() disp display.Display() img image.Image(disp.width(), disp.height()) # draw exit button exit_label \"< Exit\" size image.string_size(exit_label) exit_btn_pos [0, 0, 8*2 + size.width(), 12 * 2 + size.height()] img.draw_string(8, 12, exit_label, image.COLOR_WHITE) img.draw_rect(exit_btn_pos[0], exit_btn_pos[1], exit_btn_pos[2], exit_btn_pos[3], image.COLOR_WHITE, 2) def is_in_button(x, y, btn_pos): return x > btn_pos[0] and x < btn_pos[0] + btn_pos[2] and y > btn_pos[1] and y < btn_pos[1] + btn_pos[3] while not app.need_exit(): x, y, pressed ts.read() if is_in_button(x, y, exit_btn_pos): app.set_exit_flag(True) img.draw_circle(x, y, 1, image.Color.from_rgb(255, 255, 255), 2) disp.show(img) ``` ## 屏幕和图像大小不一样时如何处理 上面的例子可以看到 `img` 大小和屏幕大小一样，如果你的`img`和屏幕大小不一样怎么办（比如上面使用`img image.Image(240, 240)`，比如屏幕是`640x480`， 图像是`240x240`，`disp.show(img)`的默认行为是`image.Fit.FIT_CONTAIN`， 即把图片放大到`480x480`然后边上填充黑色，如果你在`240x240`的图上画了按钮，比如坐标`(0, 0, 60, 40)`，那么按钮也会自动被放大，所以触摸判断的坐标就不能用`(0, 0, 60, 40)`，需要用`((640 480) / 2, 0, 480/240*60, 480/240*40)`， 即`(80, 0, 120, 80)`。 这里为了方便缩放图像时，快速计算源图像的点或者矩形框 在 缩放后的目标图像的位置和大小，提供了`image.resize_map_pos`函数来进行此计算过程。 ```python from maix import touchscreen, app, time, display, image ts touchscreen.TouchScreen() disp display.Display() img image.Image(240, 240) img.draw_rect(0, 0, img.width(), img.height(), image.COLOR_WHITE) # draw exit button exit_label \"< Exit\" size image.string_size(exit_label) exit_btn_pos [0, 0, 8*2 + size.width(), 12 * 2 + size.height()] img.draw_string(8, 12, exit_label, image.COLOR_WHITE) img.draw_rect(exit_btn_pos[0], exit_btn_pos[1], exit_btn_pos[2], exit_btn_pos[3], image.COLOR_WHITE, 2) # 图像按键坐标映射到屏幕上的坐标 exit_btn_disp_pos image.resize_map_pos(img.width(), img.height(), disp.width(), disp.height(), image.Fit.FIT_CONTAIN, exit_btn_pos[0], exit_btn_pos[1], exit_btn_pos[2], exit_btn_pos[3]) def is_in_button(x, y, btn_pos): return x > btn_pos[0] and x < btn_pos[0] + btn_pos[2] and y > btn_pos[1] and y < btn_pos[1] + btn_pos[3] while not app.need_exit(): x, y, pressed ts.read() if is_in_button(x, y, exit_btn_disp_pos): app.set_exit_flag(True) # 屏幕的坐标映射回图像上对应的坐标，然后在图像上画点 x, y image.resize_map_pos_reverse(img.width(), img.height(), disp.width(), disp.height(), image.Fit.FIT_CONTAIN, x, y) img.draw_circle(x, y, 1, image.Color.from_rgb(255, 255, 255), 2) disp.show(img, fit image.Fit.FIT_CONTAIN) ```"},"/maixpy/doc/zh/vision/body_key_points.html":{"title":"MaixCAM MaixPy 检测人体关键点姿态检测","content":" title: MaixCAM MaixPy 检测人体关键点姿态检测 ## 简介 使用 MaixPy 可以轻松检测人体关节的关键点的坐标，用在姿态检测比如坐姿检测，体感游戏输入等。 MaixPy 实现了基于 [YOLOv8 Pose / YOLO11 Pose](https://github.com/ultralytics/ultralytics) 的人体姿态检测，可以检测到人体`17`个关键点。 ![](../../assets/body_keypoints.jpg) ## 使用 使用 MaixPy 的 `maix.nn.YOLOv8` 或者 `maix.nn.YOLO11` 类可以轻松实现： ```python from maix import camera, display, image, nn, app detector nn.YOLO11(model \"/root/models/yolo11n_pose.mud\", dual_buff True) # detector nn.YOLOv8(model \"/root/models/yolov8n_pose.mud\", dual_buff True) cam camera.Camera(detector.input_width(), detector.input_height(), detector.input_format()) disp display.Display() while not app.need_exit(): img cam.read() objs detector.detect(img, conf_th 0.5, iou_th 0.45, keypoint_th 0.5) for obj in objs: img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) msg f'{detector.labels[obj.class_id]}: {obj.score:.2f}' img.draw_string(obj.x, obj.y, msg, color image.COLOR_RED) detector.draw_pose(img, obj.points, 8 if detector.input_width() > 480 else 4, image.COLOR_RED) disp.show(img) ``` 另外代码也在[MaixPy/examples/vision](https://github.com/sipeed/MaixPy/tree/main/examples/vision/ai_vision)目录下可以找到。 可以看到因为用了`YOLOv8 Pose` 所以这里直接用了`YOLOv8`这个类，和`YOLOv8`物体检测模型只是模型文件不同， `YOLO11`同理，然后就是`detect`函数返回的结果多了`points`值，是一个`int`类型的`list`列表，一共`17`个点，按次序依次排列，比如第一个值是鼻子的 x 坐标， 第二个值是鼻子的 y 坐标，依次为： ```python 1. 鼻子（Nose） 2. 左眼（Left Eye） 3. 右眼（Right Eye） 4. 左耳（Left Ear） 5. 右耳（Right Ear） 6. 左肩（Left Shoulder） 7. 右肩（Right Shoulder） 8. 左肘（Left Elbow） 9. 右肘（Right Elbow） 10. 左手腕（Left Wrist） 11. 右手腕（Right Wrist） 12. 左髋（Left Hip） 13. 右髋（Right Hip） 14. 左膝（Left Knee） 15. 右膝（Right Knee） 16. 左脚踝（Left Ankle） 17. 右脚踝（Right Ankle） ``` 如果某些部位被遮挡，那么值为` 1`。 ## 更多输入分辨率模型 默认的模型是输入是`320x224`分辨率，如果你希望使用更大分辨率的模型，可以到 MaixHub 模型库下载并传输到设备使用: * YOLOv8 Pose: [https://maixhub.com/model/zoo/401](https://maixhub.com/model/zoo/401) * YOLO11 Pose: [https://maixhub.com/model/zoo/454](https://maixhub.com/model/zoo/454) 分辨率越大理论上精度越高但是运行速度更低，根据你的使用场景选择，另外如果提供的分辨率不满足你的要求你也可以自己到 [YOLOv8 Pose / YOLO11 Pose](https://github.com/ultralytics/ultralytics) 使用摸新训练源码导出自己的onnx模型，然后转换为 MaixCAM 支持的模型（方法见后面的文章）。 ## dual_buff 双缓冲区加速 你可能注意到这里模型初始化使用了`dual_buff`（默认值就是 `True`），使能 `dual_buff` 参数可以加快运行效率，提高帧率，具体原理和使用注意点见 [dual_buff 介绍](./dual_buff.html)。"},"/maixpy/doc/zh/vision/face_recognition.html":{"title":"MaixCAM MaixPy 人脸识别","content":" title: MaixCAM MaixPy 人脸识别 ## 人脸识别简介 ![face_recognize](../../assets/face_recognize.jpg) 人脸识别就是识别当前画面中的人脸的位置以及是谁。 所以人脸识别除了要检测到人脸，一般会有一个库来保存认识的人和不认识的人。 ## 识别原理 * 使用 AI 模型检测人脸，获得坐标和五官的坐标。 * 利用五官的坐标仿射变换将图中的脸拉正对其到标准脸的样子，方便模型提取脸的特征。 * 使用特征提取模型提取脸的特征值。 * 与库中记录的人脸特征值进行对比（计算保存的和当前画面中的脸的特征值的余弦距离，得出最小的距离的库中的人脸，小于设定的阈值就认为当前画面中就是这个库中的人） ## MaixPy 使用 MaixPy maix.nn 模块中提供了人脸识别的 API， 可以直接使用，模型也内置了，也可以到 [MaixHub 模型库](https://maixhub.com/model/zoo) 下载（筛选选则对应的硬件平台，比如 maixcam）。 识别： ```python from maix import nn, camera, display, image import os import math recognizer nn.FaceRecognizer(detect_model \"/root/models/yolov8n_face.mud\", feature_model \"/root/models/insghtface_webface_r50.mud\", dual_buff True) # recognizer nn.FaceRecognizer(detect_model \"/root/models/retinaface.mud\", feature_model \"/root/models/face_feature.mud\", dual_buff True) if os.path.exists(\"/root/faces.bin\"): recognizer.load_faces(\"/root/faces.bin\") cam camera.Camera(recognizer.input_width(), recognizer.input_height(), recognizer.input_format()) disp display.Display() while 1: img cam.read() faces recognizer.recognize(img, 0.5, 0.45, 0.85) for obj in faces: img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) radius math.ceil(obj.w / 10) img.draw_keypoints(obj.points, image.COLOR_RED, size radius if radius < 5 else 4) msg f'{recognizer.labels[obj.class_id]}: {obj.score:.2f}' img.draw_string(obj.x, obj.y, msg, color image.COLOR_RED) disp.show(img) ``` 第一次运行这个代码会发现能检测到人脸，但是都不认识，需要我们进入添加人脸模式学习人脸才行。 > 这里 `recognizer.labels[0]` 默认就是`unknown`，后面每添加一个人脸就会自动给 `labels` 增加一个。 比如可以在用户按下按键的时候学习人脸： ```python faces recognizer.recognize(img, 0.5, 0.45, 0.85, True) for face in faces: print(face) # 这里考虑到了一个画面中有多个人脸的情况， obj.class_id 为 0 代表是没有录入的人脸 # 这里写你自己的逻辑 # 比如可以在这里根据 face 的 class_id 和坐标决定要不要添加到库里面，以及可以做用户交互逻辑，比如按下按钮才录入等 recognizer.add_face(face, label) # label 是要给人脸取的标签（名字） recognizer.save_faces(\"/root/faces.bin\") ``` 这里 `0.5` 是检测人脸的阈值,越大越严格, `0.45`是`IOU`阈值,用来过滤多个重合的人脸结果； `0.85`是人脸对比阈值, 即和库中存好的人脸对比相似度,某个人脸对比分数大于这个阈值就认为是这个人。值越大过滤效果越好，值越小越容易误识别，可以根据实际情况调整。 检测模型这里支持`yolov8n_face`/`retinaface`/`face_detector`三种，速度和精度略微区别，可以根据实际情况选择使用。 ## 完整例程 这里提供一个按键录入未知人脸，以及人脸识别的例程，可以在[MaixPy 的 example 目录](https://github.com/sipeed/MaixPy/tree/main/examples) 找到`nn_face_recognize.py`。 ## dual_buff 双缓冲区加速 你可能注意到这里模型初始化使用了`dual_buff`（默认值就是 `True`），使能 `dual_buff` 参数可以加快运行效率，提高帧率，具体原理和使用注意点见 [dual_buff 介绍](./dual_buff.html)。 ## 更换其它默认识别模型 这里识别模型（区分不同人）用了 `mobilenetv2` 和 [insight face resnet50](https://maixhub.com/model/zoo/462) 模型，如果不满足精度要求，可以更换成其它模型，需要自己训练或者找其它训练好的模型转换成 MaixCAM 支持的模型即可，比如 [insightface](https://github.com/deepinsight/insightface)的其它模型， 转换方法看[MaixCAM 模型转换文档](../ai_model_converter/maixcam.html)， mud 文件参考以有的文件写即可。"},"/maixpy/doc/zh/vision/maixhub_train.html":{"title":"MaixCAM MaixPy 使用 MaixHub 在线训练 AI 模型给 MaixPy 使用","content":" title: MaixCAM MaixPy 使用 MaixHub 在线训练 AI 模型给 MaixPy 使用 update: date: 2024 04 03 author: neucrack version: 1.0.0 content: 初版文档 ## 简介 MaixHub 提供了在线训练 AI 模型的功能，可以直接在浏览器中训练模型，不需要购买昂贵的机器，不需要搭建复杂的开发环境，也不需要写代码，非常适合入门，也适合懒得翻代码的老手。 ## 使用 MaixHub 训练模型的基本步骤 ### 确认要识别的数据类型和模型类型 要训练一个 AI 模型，需要先确定是什么数据和模型，目前 MaixHub（2024.4）提供了图像数据的`物体分类模型`和`物体检测模型`，都是图像识别模型， `物体分类模型` 比 `物体检测模型` 更简单，因为物体检测需要标注物体在图中的位置，会比较麻烦，物体分类则只需要给出图像中是什么，不需要坐标，所以更简单， 如果是初学者建议先从物体分类开始。 ### 采集数据 如前面的 AI 基础所说，要训练模型，必须准备训练用的数据集让 AI 学习，对于图像训练，我们需要创建一个数据集，并且上传图片到数据集。 保证设备已经连接网络（WiFi）。 打开设备上的 MaixHub 应用选择 采集数据 来拍照并一键上传到 MaixHub。需要先在 MaixHub 创建数据集，然后点击 设备 上传数据，会出现一个 二维码，设备扫描二维码来与MaixHub 建立连接。 注意要分清训练集和验证集的区别，要想实机运行的效果和训练效果相当，验证集的数据一定要和实机运行拍摄的图像质量一样，训练集也建议用设备拍摄的，如果要用网上的图片，一定只能用在训练集，不要用在验证集，因为数据量小，数据集与实机运行越接近越好。 ### 标注数据 对于分类模型，在上传的时候就顺便已经标注好了，即上传时选择好了图片属于那个分类。 对于目标检测模型，上传完成后需要进行手动标注，即在每一张图中框出要被识别物体的坐标大小和分类。 这个标注过程你也可以选择自己在自己的电脑中离线用比如 labelimg 这样的软件标注完毕后使用数据集中的导入功能导入到 MaixHub。 标注时善用快捷键标注起来会更快，后面MaixHub 也会增加更多辅助标注和自动标注工具（目前在上传视频处有自动标注工具也可以尝试使用）。 ### 训练模型 选择训练参数训练，选择对应的设备平台，选择 maixcam，等待排队训练，可以实时看到训练进度，等待完成即可。 ### 部署模型 训练完成后，可以设备的 MaixHub 应用中选择 部署 功能，扫码进行部署。 设备开会自动下载模型并且运行起来，模型会被存在本地，后面也能选择再次运行。 如果你觉得识别效果很不错，可以一键分享到模型库让更多人使用。 ## 使用方法 请到 [MaixHub](https://maixhub.com) 注册账号，然后登录，主页有视频教程，学习即可。 注意教程如果是使用了 M2dock 这个开发板，和 MaixCAM也是类似的，只是设备（板子）上使用的 MaixHub 应用可能稍微有点区别，大体上是相同的，请注意举一反三。"},"/maixpy/doc/zh/vision/body_pose_classification.html":{"title":"MaixCAM MaixPy 基于yolo11 pose估计人体关键点初步分类人体姿态","content":" title: MaixCAM MaixPy 基于yolo11 pose估计人体关键点初步分类人体姿态 ## 简介 由`MaixCAM MaixPy 检测人体关键点姿态检测`可估计人体的 `17` 个关键点。 ![](../../assets/body_keypoints.jpg) 特定关键点之间的连线可以简单模拟人的肢体，如 ```markdown 3 1 0 2 4 构成 头部 (Head) 5 6 12 11 5 构成 躯干 (Torso) 5 7 9 或 6 8 10 构成 上肢 (Upper Limbs) 11 13 15 或 12 14 16 构成 下肢 (Lower Limbs) \"大腿\": \"Thigh\", \"小腿\": \"Shin\", \"大臂\": \"Upper Arm\", \"小臂\": \"Forearm\", ``` 每个肢体为一个向量，可由此计算不同肢体间夹角，如 大腿和小腿间夹角，然后可以判断小腿是伸直还是弯曲，且人类不可能在小腿弯曲的情况下直立，以此类推 等等，可对人体的姿态进行初步分类。 当前有以下几个分类： 1. \"躺下\": \"Lying Down\", 2. \"直立\": \"Standing Up\", 3. \"坐下\": \"Sitting Down\", 4. \"斜躺\": \"Reclining\", 5. \"向左1\": \"To Left 1\", 6. \"向右1\": \"To Right 1\", 7. \"双手平举\": \"Both Hands Raised Horizontally\", 8. \"举左手\": \"Left Hand Raised\", 9. \"举右手\": \"Right Hand Raised\", 10. \"举双手\": \"Both Hands Raised Up\", 11. \"双手比心\": \"Both Hands Forming a Heart\", 12. \"大字型\": \"Big 'T' Shape\", 示例图 ![](../../assets/body_pose_classification.jpg) ## 使用 `projects/app_human_pose_classifier/` 打包的 app `Human Pose Classifier` 可直接运行。 `examples/vision/ai_vision/` 下的 `nn_yolo11_pose_cls.py` 是单单文件实现，可以在 MaixVision 直接点击 run 按钮运行。 建议参考 `PoseEstimation.py` 进行定制修改。"},"/maixpy/doc/zh/index.html":{"title":"MaixCAM MaixPy 快速开始","content":" title: MaixCAM MaixPy 快速开始 <style> #head_links table { width: 100%; display: table; } .biliiframe { width: 100%; min height: 30em; border radius: 0.5em; border: 1em solid white; } @media screen and (max width: 900px){ #head_links th, #head_links td { /* padding: 8px; */ font size: 0.9em; padding: 0.1em 0.05em; } } </style> <div id \"head_links\"> 资源汇总 链接 : : : : MaixPy 教程文档 📖 [wiki.sipeed.com/maixpy](https://wiki.sipeed.com/maixpy) MaixPy 例程和源码 <img src \"/static/image/github fill.svg\" style \"height: 1.5em;vertical align: middle;\"> [github.com/sipeed/MaixPy](https://github.com/sipeed/MaixPy) MaixCAM 硬件资料 📷 [wiki.sipeed.com/maixcam](https://wiki.sipeed.com/maixcam) / [wiki.sipeed.com/maixcam pro](https://wiki.sipeed.com/maixcam pro) MaixPy API 文档 📚 [wiki.sipeed.com/maixpy/api/](https://wiki.sipeed.com/maixpy/api/index.html) MaixPy 视频和教程 💿 [B站搜 MaixCAM 或 MaixPy](https://search.bilibili.com/all?keyword maixcam&from_source webtop_search&spm_id_from 333.1007&search_source 5) MaixHub 应用商店 📦 [maixhub.com/app](https://maixhub.com/app) MaixHub 分享广场 🎲 [maixhub.com/share](https://maixhub.com/share) 开源项目 📡 GitHub 搜：[MaixCAM](https://github.com/search?q maixcam&type repositoriese) / [MaixCAM2](https://github.com/search?q maixcam2&type repositoriese) / [MaixPy](https://github.com/search?q maixpy&type repositoriese) </div> <div style \"font size: 1.2em;padding:1em; text align:center; color: white\"> <div style \"padding: 1em 0 0 0\"> <a target \"_blank\" style \"color: white; font size: 0.9em; border radius: 0.3em; padding: 0.5em; background color: #c33d45\" href \"https://item.taobao.com/item.htm?id 784724795837\">淘宝(MaixCAM)</a> <a target \"_blank\" style \"color: white; font size: 0.9em; border radius: 0.3em; padding: 0.5em; background color: #c33d45\" href \"https://item.taobao.com/item.htm?id 846226367137\">淘宝(MaixCAM Pro)</a> <a target \"_blank\" style \"color: white; font size: 0.9em; border radius: 0.3em; padding: 0.5em; background color: #c33d45\" href \"https://www.aliexpress.com/store/911876460\">速卖通</a> </div> </div> <br> > 关于 MaixPy 介绍请看 [MaixPy 官网首页](../../index.html) > 喜欢 MaixPy 请给 [ MaixPy 项目](https://github.com/sipeed/MaixPy) 点个 Star ⭐️ 以鼓励我们开发更多功能。 <iframe src \"//player.bilibili.com/player.html?isOutside true&aid 113485669204279&bvid BV1ncmRYmEDv&cid 26768769718&p 1\" scrolling \"no\" border \"0\" frameborder \"no\" framespacing \"0\" allowfullscreen \"true\" class \"biliiframe\"></iframe> ## 写在前面 * 请**仔细**阅读按照下面文档的步骤，不要遗漏内容，对比进行操作。 * **左边目录**请仔细查看，基础部分一定要耐心阅读完。 * **提问前**先在左边目录仔细查找文档，以及看[FAQ](./faq.html)。 * 本文档是`MaixPy v4 教程文档`，注意与 [MaixPy v1](https://wiki.sipeed.com/soft/maixpy/zh/index.html)（k210系列）区别开，勿错看文档。 * 也可以参考下面的视频上手教程，注意视频内容有更正在**评论区和弹幕会补充，以最新的文档为准**，更多视频教程可以到 B 站搜索 MaixCAM。 <iframe src \"//player.bilibili.com/player.html?isOutside true&aid 112865415531014&bvid BV1vcvweCEEe&cid 500001630687957&p 1\" scrolling \"no\" border \"0\" frameborder \"no\" framespacing \"0\" allowfullscreen \"true\" style \"min height:20em; width: 90%\"></iframe> ## 获得 MaixCAM 设备 ![maixcam_pro](../../static/image/maixcam_pro.png) * **MaixCAM 主体**，目前有几个版本，根据自己的需求买： * **MaixCAM Pro**（推荐）： 在 [Sipeed 淘宝](https://item.taobao.com/item.htm?id 846226367137) 或者 [Sipeed 速卖通](https://www.aliexpress.com/store/911876460) 店铺购买 <a href \"https://wiki.sipeed.com/maixcam pro\" target \"_blank\">MaixCAM Pro</a>。 * **MaixCAM**：在 [Sipeed 淘宝](https://item.taobao.com/item.htm?id 784724795837) 或者 [Sipeed 速卖通](https://www.aliexpress.com/store/911876460) 店铺购买 <a href \"https://wiki.sipeed.com/maixcam\" target \"_blank\">MaixCAM</a>。 * **MaixCAM Lite**（不推荐）: 无屏幕和外壳版本，价格更便宜，学习开发不建议购买，量产可以考虑购买。 * **TF 卡**： 系统安装在 TF 卡，没有 TF 无法启动。 * **摄像头**: 视觉相关应用需要摄像头，可以根据自己的使用场景和财力选择合适的摄像头型号。比如 OS01A10 成像质量比 GC4653 高。 * **触摸屏**： 方便交互，官方默认集成的应用都需要触摸屏交互，可以大大提升交互体验和开发难度。 * **电源**： 一个稳定的供电方式，MaixCAM 需要 `5v 500mA` 的稳定供电，如果供电不足可能会导致无法开机，或者运行过程中死机等情况。特别是有些电脑的 USB 口供电可能不稳定。 * **TF 读卡器**: 用来烧录系统，必备。 * **USB转串口模块**: 如果你想要电脑和 MaixCAM 之间串口通信，需要备一个，淘宝随便买一个就行，也可以直接在 Sipeed 店里一起买，比如这个[双串口转USB模块](https://item.taobao.com/item.htm?id 610365562537)。 >! 注意，目前只支持 MaixCAM 系列开发板，其它同型号芯片的开发板均不支持，包括 Sipeed 的同型号芯片开发板，请注意不要买错造成不必要的时间和金钱浪费。 ## 使用无屏幕版本 如果你使用的是无屏幕版本，请看[快速开始（无屏幕版本）](./README_no_screen.html)文档。 ## 上手配置 ### 准备 TF 镜像卡和插入到设备 如果你买的套餐里面有 TF 卡，里面已经有出厂镜像了，如果出厂时 TF 卡没有安装到设备，需要先小心打开外壳（注意里面有排线连接不要扯断了），然后插入 TF 卡。另外因为出厂的固件可能比较老旧，**务必**按照<a href \"./basic/os\" target \"_blank\">升级和烧录系统</a>先将系统升级到最新版本，否则可能会遇到某些应用 和 API 无法使用的问题。 如果没买 TF 卡，则需要将系统烧录进自备的 TF 卡中，烧录方法请看<a href \"./basic/os\" target \"_blank\">升级和烧录系统</a>，然后再安装到板子。 ### 上电开机 使用 `Type C` 数据线连接 `MaixCAM` 设备给设备供电，等待设备开机，开机会进入功能选择界面。 ![maixcam_font](../../static/image/maixcam_font.png) 如果屏幕没有显示 * 请确认购买了配套的 TF 卡，如果确认有 TF 卡，并且已经插入到设备，可以**尝试[更新到最新的系统](./basic/os.html)**。 * 如果你没有购买 TF 卡套餐，你需要按照<a href \"./basic/os\" target \"_blank\">升级和烧录系统</a>的方法烧录最新的系统到 TF 卡。 * 另外请确认屏幕和摄像头的排线没有松动，屏幕的排线在拆开外壳时很容易脱落，需要注意。 ### 联网 首次运行需要连接网络，后面会激活设备和使用 IDE 会用到。 如果没有路由器可以用手机开一个热点。 设备上点击 `设置`(`Settings`)，选择`WiFi`，有两种方法连接 `WiFi` 热点： * 扫描 WiFi 分享码： * 使用手机分享`WiFi`热点二维码，或者到[maixhub.com/wifi](https://maixhub.com/wifi) 生成一个二维码。 * 点击`扫描二维码`按钮，会出现摄像头的画面，扫描前面生成的二维码进行连接。 * 搜索热点： * 点击 `扫描` 按钮开始扫描周围 `WiFi`， 可以多次点击刷新列表。 * 找到你的 WiFi 热点。 * 输入密码点击`连接`按钮进行连接。 然后等待获取到 `IP` 地址，这可能需要 `10` 到 `30` 秒，如果界面没有刷新可以退出`WiFi`功能重新进入查看，或者在`设置` > `设备信息` 中也可以看到 `IP` 信息。 ### 升级运行库 **这一步很重要 ！！！** 这一步如果不做好，其它应用和功能可能无法运行（比如闪退等）。 * 首先保证上一步连接 WiFi 已经完成，并且获取到 IP 地址能访问公网。 * 设备上点击 `设置`(`Settings`)，选择`安装运行库`。 * 安装完成后可以看到更新到了最新版本，然后退出即可。 如果显示`Request failed` 或者`请求失败`，请先检查网络是否已经连接，需要能连接到互联网，如果还不行，请拍照联系客服处理即可。 ### 使用内置应用 内置了很多应用，比如 找色块，AI 检测器，巡线等等，自学习检测举例： <video playsinline controls autoplay loop muted preload class \"pl 6 pb 4 self end\" src \"/static/video/self_learn_tracker.mp4\" type \"video/mp4\" style \"width:95%\"> Classifier Result video </video> 其它的请自行摸索，以后还会更新更多应用，使用文档以及应用更新请看 [MaixHub 应用商店](https://maixhub.com/app) 。 **注意：应用只包含了 MaixPy 能实现的一部分功能，使用 MaixPy 能创造更多功能**。 ## 作为串口模块使用 > 如果是想把设备当成主控使用（或者你还不懂什么是串口模块）可以跳过这一步。 内置的各种应用可以直接当成串口模块使用，比如`找色块`、`找人脸`、`找二维码`等等， 注意这里串口仅能直接和其它单片机连接，**如果要和电脑串口通信请自备一个 USB 转串口模块**。 使用方法： * 硬件连接： 可以给设备接上`Type C一转二小板`（对于 MaixCAM Pro 是 6Pin 接口），这样我们就能将设备通过串口连接到你的主控上了，比如`Arduino`、`树莓派`、`STM32`等等。 * 打开你想用的应用，比如二维码识别，当设备扫描到二维码就会通过串口把结果发送给你的主控了。 > 发送的串口波特率是 `115200`，数据格式是 `8N1`，协议遵循 [Maix 串口通信协议标准](https://github.com/sipeed/MaixCDK/blob/master/docs/doc/convention/protocol.md)，可以在[MaixHub APP](https://maixhub.com/app) 找到对应的应用介绍查看协议。 > 如果应用没有做串口输出结果，你也可以自己基于对应功能的例程，自行按照[串口使用文档](./peripheral/uart.html)添加串口输出结果。 ## 准备连接电脑和设备 为了后面电脑（PC）能和 设备（MaixCAM）通信，我们要让它们在同一个局域网内，提供了两种方式： * **方法一 (强烈推荐)**：无线连接， 设备使用 WiFi 连接到电脑连接的同一个路由器或者 WiFi 热点下： 在设备的`设置 > WiFi 设置`中连接到你的 WiFi 即可。（WiFi 如果出现**画面卡顿或者延迟**的问题可以尝试下面的方法二使用有线连接。） * **方法二**：有线连接， 设备通过 USB 线连接到电脑，设备会虚拟成一个 USB 网卡，这样和电脑就通过 USB 在同一局域网了。推荐先用 WiFi 开始是因为有线虽然传输稳定但是可能会遇到线缆不良，接触不良，驱动等问题，遇到问题也可以在 [FAQ](./faq.html) 中找常见问题。 .. details::方法二在不同电脑系统中驱动安装方法： :open: true 默认会有两种 USB 虚拟网卡驱动（NCM 和 RNDIS驱动），以满足不同系统的需求，你也可以在设备端`设置`应用 > `USB设置` 里面关掉不用的虚拟网卡： * **Windows**: windows 所有系统会自动安装 RNDIS 驱动， 仅 Win11 会自动安装 NCM 驱动，两种驱动**有一个能用就行**。 * 打开任务管理器 > 性能，可以看到一个虚拟的以太网，并且可以看到 ip 比如 `10.131.167.100` 是电脑的 ip, 设备的 ip 是最后一位改为`1` 即 `10.131.167.1`。如果是 Win11 则会看到两个虚拟网卡，随便选择一个 IP 使用即可。 * 另外也可以打开电脑的 `设备管理器`（搜索栏搜索`设备管理器`）， RNDIS 和 NCM 驱动被正确安装的效果： ![RNDIS ok](../../static/image/windows_rndis_ok.png) ![NCM ok](../../static/image/windows_ncm_ok.png) * **Linux**: 无需额外设置，插上 USB 线即可。 使用 `ifconfig` 或者 `ip addr` 查看到 `usb0` 和 `usb1` 网卡，两个 IP 都可以使用，**注意** 这里看到的 ip 比如 `10.131.167.100` 是电脑的 ip, 设备的 ip 是最后一位改为`1` 即 `10.131.167.1`。 * **MacOS**: 在`系统设置` >`网络`里面查看到 `usb` 网卡，**注意** 这里看到的 ip 比如 `10.131.167.100` 是电脑的 ip, 设备的 ip 是最后一位改为`1` 即 `10.131.167.1`。 ## 开发环境准备 * 首先保证上一步电脑和设备已经在同一个局域网中了。 * 下载 [MaixVision](https://wiki.sipeed.com/maixvision) 并安装。 * 使用 Type C 连接设备和电脑，打开 MaixVision，点击左下角的`“连接”`按钮，会自动搜索设备，稍等一下就能看到设备，点击设备有点的连接按钮以连接设备。 如果**没有扫描到设备**，你也可以在**设备**的 `设置 > 设备信息` 中查看设备的 IP 地址手动输入， 也可以在 [FAQ](./faq.html) 中找到解决方法。 **连接成功后，设备的功能选择界面会消失，屏幕会黑屏，释放了所有硬件资源，如果仍然有画面显示，可以断开连接重连。** 这里有 MaixVision 的使用示例视频: <video style \"width:100%\" controls muted preload src \"/static/video/maixvision.mp4\"></video> ## 运行例程 点击 MaixVision 左侧的`示例代码`，选择一个例程，点击左下角`运行`按钮将代码发送到设备上运行。 比如： * `hello_maix.py`，点击`运行`按钮，就能看到 MaixVision 终端有来自设备打印的消息，以及右上角出现了图像。 * `camera_display.py`，这个例程会打开摄像头并在屏幕上显示摄像头的画面。 ```python from maix import camera, display, app disp display.Display() # 构造一个显示对象，并初始化屏幕 cam camera.Camera(640, 480) # 构造一个摄像头对象，手动设置了分辨率为 640x480, 并初始化摄像头 while not app.need_exit(): # 一直循环，直到程序退出（可以通过按下设备的功能按键退出或者 MaixVision 点击停止按钮退出） img cam.read() # 读取摄像头画面保存到 img 变量，可以通过 print(img) 来打印 img 的详情 disp.show(img) # 将 img 显示到屏幕上 ``` * `yolov5.py` 会检测摄像头画面中的物体框出来并显示到屏幕上，支持 80 种物体的检测，具体请看[YOLOv5/YOLOv8/YOLO11 物体检测](./vision/yolov5.html)。 其它例程可以自行尝试。 > 如果你使用相机例程遇到了图像显示卡顿，可能是网络不通畅，或者 USB 线质量或者主机 USB 质量太差造成，可以更换连接方式或者更换线缆、主机 USB 口或者电脑等。 ## 安装应用到设备 上面是在设备中运行代码，`MaixVision` 断开后代码就会停止运行，如果想让代码出现在开机菜单中，可以打包成应用安装到设备上。 点击 `MaixVision` 左下侧的安装应用按钮，填写应用信息，会将应用安装到设备上，然后在设备上就能看到应用了。 也可以选择打包应用，将你的应用分享到[MaixHub 应用商店](https://maixhub.com/app)。 > 默认例程没有显式编写退出功能，进入应用后按下设备的功能按键即可退出应用。（对于 MaixCAM 是 user 键） 如果想让程序开机自启动，可以在 `设置 > 开机启动` 中设置。 更多 MaixVision 使用请看 [MaixVision 文档](./basic/maixvision.html)。 ## 下一步 看到这里，如果你觉得不错，**请务必来 [github](https://github.com/sipeed/MaixPy) 给 MaixPy 开源项目点一个 star（需要先登录 github）, 你的 star 和认同是我们不断维护和添加新功能的动力！** 到这里你已经体验了一遍使用和开发流程了，接下来可以学习 `MaixPy` 语法和功能相关的内容，请按照左边的目录进行学习，如果遇到 `API` 使用问题，可以在[API 文档](/api/)中查找。 学习前最好带着自己学习的目的学，比如做一个有趣的小项目，这样学习效果会更好，项目和经验都可以分享到[MaixHub 分享广场](https://maixhub.com/share)，会获得现金奖励哦！ ## 常见问题 FAQ 遇到问题可以优先在 [FAQ](./faq.html) 里面找，找不到再在下面的论坛或者群询问，或者在 [MaixPy issue](https://github.com/sipeed/MaixPy/issues) 提交源码问题。 ## 分享交流 * **[MaixHub 项目和经验分享](https://maixhub.com/share)** ：分享你的项目和经验，获得现金打赏，获得官方打赏的基本要求： * **可复现型**：较为完整的项目制作复现过程。 * **炫耀型**：无详细的项目复现过程，但是项目展示效果吸引人。 * Bug 解决经验型：解决了某个难题的过程和具体解决方法分享。 * [MaixPy 官方论坛](https://maixhub.com/discussion/maixpy)（提问和交流） * QQ 群： （建议在 QQ 群提问前先发个帖，方便群友快速了解你需要了什么问题，复现过程是怎样的） * MaixPy (v4) AI 视觉交流大群: 862340358 * Telegram: [MaixPy](https://t.me/maixpy) * MaixPy 源码问题: [MaixPy issue](https://github.com/sipeed/MaixPy/issues) * 商业合作或批量购买请联系 support@sipeed.com 。"},"/maixpy/doc/zh/ai_model_converter/maixcam.html":{"title":"将 ONNX 模型转换为 MaixCAM MaixPy 可以使用的模型（MUD）","content":" title: 将 ONNX 模型转换为 MaixCAM MaixPy 可以使用的模型（MUD） > MaixCAM2 模型转换请看[MaixCAM2 模型转换文档](./maixcam2.html) ## 简介 电脑上训练的模型不能直接给 MaixCAM 使用，因为 MaixCAM 的硬件性能有限，一般我们需要将模型进行`INT8`量化以减少计算量，并且转换为 MaixCAM 支持的模型格式。 本文介绍如何将 ONNX 模型转换为 MaixCAM 能使用的模型（MUD模型）。 ## MaixCAM 支持的模型文件格式 MUD（模型统一描述文件， model universal description file）是 MaixPy 支持的一种模型描述文件，用来统一不同平台的模型文件，方便 MaixPy 代码跨平台，本身是一个 `ini`格式的文本文件，可以使用文本编辑器编辑。 一般 MUD 文件会伴随一个或者多个实际的模型文件，比如对于 MaixCAM， 实际的模型文件是`.cvimodel`格式， MUD 文件则是对它做了一些描述说明。 这里以 `YOLOv8` 模型文件举例，一共两个文件`yolov8n.mud`和`yolov8n.cvimodel`，前者内容： ```ini [basic] type cvimodel model yolov8n.cvimodel [extra] model_type yolov8 input_type rgb mean 0, 0, 0 scale 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 labels person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair drier, toothbrush ``` 可以看到， 指定了模型类别为`cvimodel`, 模型路径为相对`mud`文件的路径下的`yolov8n.cvimodel`文件； 以及一些需要用到的信息，比如预处理`mean`和`scale`，这里需要和训练的时候对模型输入的数据的预处理方法一致，`labels`则是检测对象的 80 种分类。 实际用这个模型的时候将两个文件放在同一个目录下即可。 ## 准备 ONNX 模型 准备好你的 onnx 模型， 然后在[https://netron.app/](https://netron.app/) 查看你的模型，确保你的模型使用的算子在转换工具的支持列表中，转换工具的支持列表可以在[算能 TPU SDK](https://developer.sophgo.com/thread/473.html)的 **CVITEK_TPU_SDK开发指南.pdf** 中看到列表。 ## 找出合适的量化输出节点 一般模型都有后处理节点，这部分是 CPU 进行运算的，我们将它们剥离出来，它们会影响到量化效果，可能会导致量化失败。 这里以`YOLOv5 举例`， ![](../../assets/yolov5s_onnx.jpg) 可以看到这里有三个`conv`，后面的计算均由 CPU 进行，我们量化时就采取这几个`conv`的输出作为模型的最后输出，在这里输出名分别叫`/model.24/m.0/Conv_output_0,/model.24/m.1/Conv_output_0,/model.24/m.2/Conv_output_0`。 YOLO11/YOLOv8 请看[离线训练 YOLO11/YOLOv8](../vision/customize_model_yolov8.html). 分类模型一般来说取最后一个输出名称就行，不过如果有`osftmax`的话，建议不把`softmax`包含在模型里面，即取`softmax`前一层的输出名，下图是没有`softmax`层的所以直接取最后一层即可。 ![](../../assets/mobilenet_top.png) ## 安装模型转换环境 模型转换使用算能的[https://github.com/sophgo/tpu mlir](https://github.com/sophgo/tpu mlir)，要安装它我们直接在 docker 环境中安装，防止我们电脑的环境不匹配，如果你没用过 docker，可以简单理解成它类似虚拟机。 ### 安装 docker 参考[docker 安装官方文档](https://docs.docker.com/engine/install/ubuntu/)安装即可。 比如： ```shell # 安装docker依赖的基础软件 sudo apt get update sudo apt get install apt transport https ca certificates curl gnupg agent software properties common # 添加官方来源 curl fsSL https://download.docker.com/linux/ubuntu/gpg sudo apt key add sudo add apt repository \"deb [arch amd64] https://download.docker.com/linux/ubuntu $(lsb_release cs) stable\" # 安装 docker sudo apt get update sudo apt get install docker ce docker ce cli containerd.io ``` ### 拉取 docker 镜像 ```shell docker pull sophgo/tpuc_dev:latest ``` 如果docker拉取失败，可以通过以下方式进行下载： ```shell wget https://sophon file.sophon.cn/sophon prod s3/drive/24/06/14/12/sophgo tpuc_dev v3.2_191a433358ad.tar.gz docker load i sophgo tpuc_dev v3.2_191a433358ad.tar.gz ``` 这个方法参考[tpu mlir官方docker环境配置](https://github.com/sophgo/tpu mlir/blob/master/README_cn.md)。 此外你也可以设置国内的镜像，可自行搜索或者参考[docker 设置代理，以及国内加速镜像设置](https://neucrack.com/p/286)。 ### 运行容器 ```shell docker run privileged name tpu env v /home/$USER/data:/home/$USER/data it sophgo/tpuc_dev ``` 这就起了一个容器，名叫`tpu env`，并且把本机的`~/data`目录挂载到了容器的`~/data`，这样就实现了文件共享，并且和宿主机路径一致。 下次启动容器用`docker start tpu env && docker attach tpu env`即可。 ### 安装 tpu mlir 先到[github](https://github.com/sophgo/tpu mlir/releases)下载 `whl` 文件，放到`~/data`目录下。 在容器中执行命令安装： ```shell pip install tpu_mlir*.whl # 这里就是下载文件的名字 ``` 在容器内**直接输入**`model_transform.py`回车执行会有打印帮助信息就算是安装成功了。 ## 编写转换脚本 转换模型主要就两个命令，`model_transform.py` 和 `model_deploy.py`，主要麻烦的是参数，所以我们写一个脚本`convert_yolov5_to_cvimodel.sh`存下来方便修改。 ```shell #!/bin/bash set e net_name yolov5s input_w 640 input_h 640 # mean: 0, 0, 0 # std: 255, 255, 255 # mean # 1/std # mean: 0, 0, 0 # scale: 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 mkdir p workspace cd workspace # convert to mlir model_transform.py \\ model_name ${net_name} \\ model_def ../${net_name}.onnx \\ input_shapes [[1,3,${input_h},${input_w}]] \\ mean \"0,0,0\" \\ scale \"0.00392156862745098,0.00392156862745098,0.00392156862745098\" \\ keep_aspect_ratio \\ pixel_format rgb \\ channel_format nchw \\ output_names \"/model.24/m.0/Conv_output_0,/model.24/m.1/Conv_output_0,/model.24/m.2/Conv_output_0\" \\ test_input ../dog.jpg \\ test_result ${net_name}_top_outputs.npz \\ tolerance 0.99,0.99 \\ mlir ${net_name}.mlir # export bf16 model # not use quant_input, use float32 for easy coding model_deploy.py \\ mlir ${net_name}.mlir \\ quantize BF16 \\ processor cv181x \\ test_input ${net_name}_in_f32.npz \\ test_reference ${net_name}_top_outputs.npz \\ model ${net_name}_bf16.cvimodel echo \"calibrate for int8 model\" # export int8 model run_calibration.py ${net_name}.mlir \\ dataset ../images \\ input_num 200 \\ o ${net_name}_cali_table echo \"convert to int8 model\" # export int8 model # add quant_input, use int8 for faster processing in maix.nn.NN.forward_image model_deploy.py \\ mlir ${net_name}.mlir \\ quantize INT8 \\ quant_input \\ calibration_table ${net_name}_cali_table \\ processor cv181x \\ test_input ${net_name}_in_f32.npz \\ test_reference ${net_name}_top_outputs.npz \\ tolerance 0.9,0.6 \\ model ${net_name}_int8.cvimodel ``` 可以看到，这里有几个比较重要的参数： * `output_names` 就是我们前面说到的输出节点的输出名。 * `mean, scale` 就是训练时使用的预处理方法，比如 `YOLOv5` 官方代码的预处理是把图像 RGB 3个通道分别 ` mean`再除以`std`，并且默认`mean` 为`0`， `std`为`255`，即将图像的值归一，这里`scale`就是`1/std`。你的模型需要根据实际的预处理方法修改。 * `test_input` 就是转换时用来测试的图像，这里是`../dog.jpg`，所以实际模型转换时我们需要在此脚本所在同目录放一张`dog.jpg`的图，你的模型根据你的实际情况替换图像。 * `tolerance` 就是量化前后允许的误差，如果转换模型时报错提示值小于设置的这个值，说明转出来的模型可能相比 onnx 模型误差较大，如果你能够容忍，可以适当调小这个阈值让模型转换通过，不过大多数时候都是因为模型结构导致的，需要优化模型，以及仔细看后处理，把能去除的后处理去除了。 * `quantize` 即量化的数据类型，在 MaixCAM 上我们一般用 INT8 模型，这里我们虽然也顺便转换了一个 BF16 模型，BF16 模型的好处时精度高，不过运行速率比较慢，能转成 INT8 就推荐先用 INT8,实在不能转换的或者精度要求高速度要求不高的再考虑 BF16。 * `dataset` 表示用来量化的数据集，也是放在转换脚本同目录下，比如这里是`images`文件夹，里面放数据即可，对于 YOLOv5 来说就是图片，从 coco 数据集中复制一部分典型场景的图片过来即可。 用` input_num` 可以指定实际使用图片的数量（小于等于 images 目录下实际的图片）。 ## 执行转换脚本 直接执行`chmod +x convert_yolov5_to_cvimodel.sh && ./convert_yolov5_to_cvimodel.sh` 等待转换完成。 如果出错了，请仔细看上一步的说明，是不是参数有问题，或者输出层选择得不合理等。 然后就能在`workspace`文件夹下看到有`**_int8.cvimodel` 文件了。 ## 编写`mud`文件 根据你的模型情况修改`mud`文件，对于 YOLOv5 就如下，修改成你训练的`labels`就好了。 ```ini [basic] type cvimodel model yolov5s.cvimodel [extra] model_type yolov5 input_type rgb mean 0, 0, 0 scale 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 anchors 10,13, 16,30, 33,23, 30,61, 62,45, 59,119, 116,90, 156,198, 373,326 labels person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair drier, toothbrush ``` 这里`basic`部分指定了模型文件类别和模型文件路径，是必要的参数，有了这个参数就能用`MaixPy`或者`MaixCDK`中的`maix.nn.NN`类来加载并运行模型了。 `extra`则根据不同模型的需求设计不同参数。 比如这里对`YOLOv5`设计了这些参数，主要是 预处理、后处理、标签等参数。 对于 `MaixPy` 已经支持了的模型可以直接下载其模型复制修改。 也可以看具体的代码，比如[YOLOv5 的源码](https://github.com/sipeed/MaixCDK/blob/71d5b3980788e6b35514434bd84cd6eeee80d085/components/nn/include/maix_nn_yolov5.hpp#L73 L223)，可以看到源码使用了哪些参数。 比如你用`YOLOv5`训练了检测数字`0~9`的模型，那么需要将`labels`改成`0,1,2,3,4,5,6,7,8,9`，其它参数如果你没改训练代码保持即可。 如果你需要移植 `MaixPy` 没有支持的模型，则可以根据模型的预处理和后处理情况定义 `extra`, 然后编写对应的解码类。如果你不想用C++修改 MaixPy 源码，你也可以用MaixPy 的`maix.nn.NN`类加载模型，然后用 `forward` 或者 `forward_image` 方法或者原始输出，在 Python 层面写后处理也可以，只是运行效率比较低不太推荐。 ## 编写后处理代码 如上一步所说，如果是按照已经支持的模型的`mud`文件修改好，那直接调用`MaixPy`或者`MaixCDK`对应的代码加载即可。 如果支持新模型，设计好 `mud` 文件后，你需要实际编写预处理和后处理，有两种方法： * 一：MaixPy 用 `maix.nn.NN`加载模型，然后`forward`或者`forward_image`函数运行模型，获得输出，然后用 Python 函数编写后处理得到最终结果。 * 二：在`MaixCDK`中，可以参考[YOLOv5 的源码](https://github.com/sipeed/MaixCDK/blob/71d5b3980788e6b35514434bd84cd6eeee80d085/components/nn/include/maix_nn_yolov5.hpp), 新增一个`hpp`文件，增加一个处理你的模型的类，并且修改所有函数和类的`@maixpy`注释，编写好了编译`MaixPy`项目，即可在`MaixPy`中调用新增的类来运行模型了。 支持了新模型后还可以将源码提交（Pull Request）到主`MaixPy`仓库中，成为`MaixPy`项目的一员，为社区做贡献，也可以到 [MaixHub 分享](https://maixhub.com/share) 分享你新支持的模型，根据质量可以获得最少 `30元` 最高 `2000元` 的打赏！"},"/maixpy/doc/zh/ai_model_converter/maixcam2.html":{"title":"将 ONNX 模型转换为 MaixCAM2 MaixPy 可以使用的模型（MUD）","content":" title: 将 ONNX 模型转换为 MaixCAM2 MaixPy 可以使用的模型（MUD） > MaixCAM / MaixCAM Pro 模型转换请看[MaixCAM 模型转换文档](./maixcam.html) ## 简介 电脑上训练的模型不能直接给 MaixCAM2 使用，因为 MaixCAM2 的硬件性能有限，一般我们需要将模型进行`INT8`量化以减少计算量，并且转换为 MaixCAM2 支持的模型格式。 本文介绍如何将 ONNX 模型转换为 MaixCAM2 能使用的模型（MUD模型）。 ## MaixCAM2 支持的模型文件格式 MUD（模型统一描述文件， model universal description file）是 MaixPy 支持的一种模型描述文件，用来统一不同平台的模型文件，方便 MaixPy 代码跨平台，本身是一个 `ini`格式的文本文件，可以使用文本编辑器编辑。 一般 MUD 文件会伴随一个或者多个实际的模型文件，比如对于 MaixCAM2， 实际的模型文件是`.axmodel`格式， MUD 文件则是对它做了一些描述说明。 这里以 `YOLOv8` 模型文件举例，一共三个文件`yolov8n.mud`， `yolo11n_640x480_vnpu.axmodel`和`yolo11n_640x480_npu.axmodel`，前者内容： ```ini [basic] type axmodel model_npu yolo11n_640x480_npu.axmodel model_vnpu yolo11n_640x480_vnpu.axmodel [extra] model_type yolo11 type detector input_type rgb labels person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair drier, toothbrush input_cache true output_cache true input_cache_flush false output_cache_inval true mean 0,0,0 scale 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 ``` 可以看到， 指定了模型类别为`axmodel`, 模型路径为相对`mud`文件的路径下的`*.axmodel`文件； 以及一些需要用到的信息: * `labels`: 检测对象的 80 种分类。 * `input_cache`/`output_cache`： 代表着输入输出是否使用缓存内存，使用缓存能在需要多次读取数据的情况下加快读取速度，比如你的后处理需要连续多次读取模型输出结果则建议使用缓冲。 * `input_cache_flush`： 表示运行模型前是不是将 内存 cache 刷新到 DDR 中，一般模型第一层如果是 NPU 算子则必须设置为`true`，对于 YOLO11 因为模型集成了预处理，也就是说第一层是 CPU 处理的，所以设置为了 `false`，如果你不确定则设置为`true`。 * `output_cache_inval`: 表示模型运行完成后是否将输出内存缓冲区设置为无效，保证我们在读取模型输出数据时是直接从 DDR 读取的。一般模型最后一层是 NPU 算子输出则必须设置为`true`，如果是 CPU 算子则可以设置为 `false`减少耗时，如果不确定可以设置为`true`保证数据正确。 * `mean`/`scale`: 实际我们在转模型时将预处理已经集成在模型中，这里只是写着方便看，需要和训练的时候对模型输入的数据的预处理方法一致。 实际用这个模型的时候将三个文件放在同一个目录下即可。 ## 准备 ONNX 模型 准备好你的 onnx 模型， 然后在[https://netron.app/](https://netron.app/) 查看你的模型，确保你的模型使用的算子在转换工具的支持列表中，转换工具的支持列表可以在[Pulsar2 工具链文档](https://pulsar2 docs.readthedocs.io/)找到。 对于 `MaixCAM2`，对应了 Pulsar2 文档中 `AX620E` 平台。 ## 找出合适的量化输出节点 一般模型都有后处理节点，这部分是 CPU 进行运算的，我们将它们剥离出来，它们会影响到量化效果，可能会导致量化失败。 这里以`YOLOv5 举例`， ![](../../assets/yolov5s_onnx.jpg) 可以看到这里有三个`conv`，后面的计算均由 CPU 进行，我们量化时就采取这几个`conv`的输出作为模型的最后输出，在这里输出名分别叫`/model.24/m.0/Conv_output_0,/model.24/m.1/Conv_output_0,/model.24/m.2/Conv_output_0`。 YOLO11/YOLOv8 请看[离线训练 YOLO11/YOLOv8](../vision/customize_model_yolov8.html). 分类模型一般来说取最后一个输出名称就行，不过如果有`osftmax`的话，建议不把`softmax`包含在模型里面，即取`softmax`前一层的输出名，下图是没有`softmax`层的所以直接取最后一层即可。 ![](../../assets/mobilenet_top.png) ## 安装模型转换环境 参考 [Pulsar2 工具链文档](https://pulsar2 docs.readthedocs.io/) 进行安装，要安装它我们直接在 docker 环境中安装，防止我们电脑的环境不匹配，如果你没用过 docker，可以简单理解成它类似虚拟机。 ### 安装 docker 参考[docker 安装官方文档](https://docs.docker.com/engine/install/ubuntu/)安装即可。 比如： ```shell # 安装docker依赖的基础软件 sudo apt get update sudo apt get install apt transport https ca certificates curl gnupg agent software properties common # 添加官方来源 curl fsSL https://download.docker.com/linux/ubuntu/gpg sudo apt key add sudo add apt repository \"deb [arch amd64] https://download.docker.com/linux/ubuntu $(lsb_release cs) stable\" # 安装 docker sudo apt get update sudo apt get install docker ce docker ce cli containerd.io ``` ### 拉取 docker 镜像 可以按照 [Pulsar2 工具链文档](https://pulsar2 docs.readthedocs.io/) 中的方法下载和加载，如果文档中不是最新的，也可以到[huggingface](https://huggingface.co/AXERA TECH/Pulsar2/tree/main) 下载。 即下载镜像文件后，使用命令加载： ```shell docker load i pulsar2_vxx.tar.gz ``` 工具链会定期更新，下载新的加载即可。 ### 运行容器 ```shell docker run it privileged name pulsar2 v /home/$USER/data:/home/$USER/data pulsar2 ``` 这就起了一个容器，名叫`pulsar2`，并且把本机的`~/data`目录挂载到了容器的`~/data`，这样就实现了文件共享，并且和宿主机路径一致。 下次启动容器用`docker start pulsar2 && docker attach pulsar2`即可。 在容器中执行`pulsar2` 就可以看到打印的帮助信息就表示可以使用了。 ## 转换模型 可以详细读一读 pulsar2 工具的文档。 主要核心就是一个命令： ```shell pulsar2 build target_hardware AX620E input onnx_path output_dir out_dir config config_path ``` 这里核心就是 `onnx`模型文件和`config`文件了，`onnx`文件在前面提到需要提取节点，可以用脚本`extract_onnx.py`提取： ```python import onnx import sys input_path sys.argv[1] output_path sys.argv[2] input_names_str sys.argv[3] output_names_str sys.argv[4] input_names [] for s in input_names_str.split(\",\"): input_names.append(s.strip()) output_names [] for s in output_names_str.split(\",\"): output_names.append(s.strip()) onnx.utils.extract_model(input_path, output_path, input_names, output_names) ``` 以及可应用`onnxsim` 简化一下模型。 `config` 文件是一个 `json`配置文件，配置了预处理和输出节点，以及量化策略，具体可以看 pulsar2 文档，比如 yolo11: ```json { \"model_type\": \"ONNX\", \"npu_mode\": \"NPU2\", \"quant\": { \"input_configs\": [ { \"tensor_name\": \"images\", \"calibration_dataset\": \"tmp_images/images.tar\", \"calibration_size\": 64, \"calibration_mean\": [0, 0, 0], \"calibration_std\": [255, 255, 255] } ], \"calibration_method\": \"MinMax\", \"precision_analysis\": true }, \"input_processors\": [ { \"tensor_name\": \"images\", \"tensor_format\": \"RGB\", \"tensor_layout\": \"NCHW\", \"src_format\": \"RGB\", \"src_dtype\": \"U8\", \"src_layout\": \"NHWC\", \"csc_mode\": \"NoCSC\" } ], \"output_processors\": [ { \"tensor_name\": \"/model.23/Concat_output_0\", \"dst_perm\": [0, 2, 3, 1] }, { \"tensor_name\": \"/model.23/Concat_1_output_0\", \"dst_perm\": [0, 2, 3, 1] }, { \"tensor_name\": \"/model.23/Concat_2_output_0\", \"dst_perm\": [0, 2, 3, 1] } ], \"compiler\": { \"check\": 3, \"check_mode\": \"CheckOutput\", \"check_cosine_simularity\": 0.9 } } ``` 注意到这里`calibration_dataset` 是量化校准数据，从数据集里面抽取一部分即可。 有一个参数需要注意：`npu_mode`，这里是`NPU2`，意思是使用所有NPU算力。 如果你想使用 AI ISP 功能，需要开启虚拟 NPU 功能将 NPU 分成两个虚拟 NPU，一个给 AI ISP 用，另一个虚拟 NPU 给我们的模型，即只用一半 NPU 的算力，换成`NPU1`即可。 MaixCAM2 为了方便用户可自由选择是否启用 AI ISP，所以建议在转模型时两种模型都转换，即对应了 mud 文件中的`model_npu`和 `model_vnpu`两个模型。 ## 编写转换脚本 为了方便使用，这里提供几个脚本方便大家使用： * `extract_onnx.py`: 上面提供的抽取子模型的脚本。 * `gen_cali_images_tar.py`: 从数据集文件夹提取指定数量的图片打包为 `tar` 格式。 ```python import sys import os import random import shutil images_dir sys.argv[1] images_num int(sys.argv[2]) print(\"images dir:\", images_dir) print(\"images num:\", images_num) print(\"current dir:\", os.getcwd()) files os.listdir(images_dir) valid [] for name in files: path os.path.join(images_dir, name) ext os.path.splitext(name)[1] if ext.lower() not in [\".jpg\", \".jpeg\", \".png\"]: continue valid.append(path) print(f\"images dir {images_dir} have {len(valid)} images\") if len(valid) < images_num: print(f\"no enough images in {images_dir}, have: {len(valid)}, need {images_num}\") sys.exit(1) idxes random.sample(range(len(valid)), images_num) shutil.rmtree(\"tmp_images\", ignore_errors True) os.makedirs(\"tmp_images/images\") for i in idxes: target os.path.join(\"tmp_images\", \"images\", os.path.basename(valid[i])) shutil.copyfile(valid[i], target) os.chdir(\"tmp_images/images\") os.system(\"tar cf ../images.tar *\") # shutil.rmtree(\"tmp_images/images\") ``` * `convert.sh`: 一键转换脚本，包含了简化 onnx， 提取量化图片数据集，生成 NPU 和 VNPU 两个模型。 ```shell #!/bin/bash set e ############# 修改 #################### model_name $1 model_path ../../${model_name}.onnx config_path yolo11_build_config.json images_dir ../../images images_num 100 input_names images output_names \"/model.23/Concat_output_0,/model.23/Concat_1_output_0,/model.23/Concat_2_output_0\" ############################################# echo \"current path: $(pwd)\" # extract and onnxsim mkdir p tmp1 onnx_extracted tmp1/${model_name}_extracted.onnx onnxsim_path tmp1/$model_name.onnx python extract_onnx.py $model_path $onnx_extracted $input_names $output_names onnxsim $onnx_extracted $onnxsim_path python gen_cali_images_tar.py $images_dir $images_num mkdir p out tmp_config_path tmp/$config_path # vnpu echo e \"\\e[32mBuilding ${model_name}_vnpu.axmodel\\e[0m\" rm rf tmp mkdir tmp cp $config_path $tmp_config_path sed i '/npu_mode/c\\\"npu_mode\": \"NPU1\",' $tmp_config_path sed i \"/calibration_size/c\\\\\\\"calibration_size\\\": ${images_num},\" \"$tmp_config_path\" pulsar2 build target_hardware AX620E input $onnxsim_path output_dir tmp config $tmp_config_path cp tmp/compiled.axmodel out/${model_name}_vnpu.axmodel # npu all echo e \"\\e[32mBuilding ${model_name}_npu.axmodel\\e[0m\" rm rf tmp mkdir tmp cp $config_path $tmp_config_path sed i '/npu_mode/c\\\"npu_mode\": \"NPU2\",' $tmp_config_path sed i \"/calibration_size/c\\\\\\\"calibration_size\\\": ${images_num},\" \"$tmp_config_path\" pulsar2 build target_hardware AX620E input $onnxsim_path output_dir tmp config $tmp_config_path cp tmp/compiled.axmodel out/${model_name}_npu.axmodel rm rf tmp echo e \"\\e[32mGenerate models done, in out dir\\e[0m\" ``` 执行成功后就会得到 `*_npu.axmodel`和`*_vnpu.axmodel`两个模型。 ## 编写`mud`文件 根据你的模型情况修改前面提到的`mud`文件，比如对于 YOLO11，修改成你训练的`axmodel`名字和`labels`就好了。 ```ini [basic] type axmodel model_npu yolo11n_640x480_npu.axmodel model_vnpu yolo11n_640x480_vnpu.axmodel [extra] model_type yolo11 type detector input_type rgb labels person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair drier, toothbrush input_cache true output_cache true input_cache_flush false output_cache_inval true mean 0,0,0 scale 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 ``` 这里`basic`部分指定了模型文件类别和模型文件路径，是必要的参数，有了这个参数就能用`MaixPy`或者`MaixCDK`中的`maix.nn.NN`类来加载并运行模型了。 如果你需要移植 `MaixPy` 没有支持的模型，则可以根据模型的预处理和后处理情况定义 `extra`, 然后编写对应的解码类。如果你不想用C++修改 MaixPy 源码，你也可以用MaixPy 的`maix.nn.NN`类加载模型，然后用 `forward` 或者 `forward_image` 方法或者原始输出，在 Python 层面写后处理也可以，只是运行效率比较低不太推荐。 ## 编写后处理代码 如上一步所说，如果是按照已经支持的模型的`mud`文件修改好，那直接调用`MaixPy`或者`MaixCDK`对应的代码加载即可。 如果是仍未支持的新模型，设计好 `mud` 文件后，你需要实际编写预处理和后处理，有两种方法： * 一：**适合快速验证**。MaixPy 用 `maix.nn.NN`加载模型，然后`forward`或者`forward_image`函数运行模型，获得输出，然后用 Python 函数编写后处理得到最终结果。可以参考[移植新模型](../pro/customize_model.html) * 二：**适合正式封装，让`MaixCDK`和`MaixPy`都可以调用而且运行效率更高**。在`MaixCDK`中，可以参考[YOLOv5 的源码](https://github.com/sipeed/MaixCDK/blob/71d5b3980788e6b35514434bd84cd6eeee80d085/components/nn/include/maix_nn_yolov5.hpp), 新增一个`hpp`文件，增加一个处理你的模型的类，并且修改所有函数和类的`@maixpy`注释，编写好了编译`MaixPy`项目，即可在`MaixPy`中调用新增的类来运行模型了。 支持了新模型后还可以将源码提交（Pull Request）到主`MaixPy`仓库中，成为`MaixPy`项目的一员，为社区做贡献，也可以到 [MaixHub 分享](https://maixhub.com/share) 分享你新支持的模型，根据质量可以获得最少 `30元` 最高 `2000元` 的打赏！"},"/maixpy/doc/zh/audio/deploy_online_recognition.html":{"title":"MaixCAM MaixPy 部署在线语音识别环境","content":" title: MaixCAM MaixPy 部署在线语音识别环境 update: date: 2024 12 23 author: lxowalle version: 1.0.0 content: 初版文档 ## 简介 本地部署在线语音识别是一种实现语音输入实时处理的解决方案。它通过在本地服务器上运行语音识别模型并与`MaixCAM`交互，无需依赖外部云服务，实现语音数据的即时处理和结果返回。这种方式不仅能够提升响应速度，还能更好地保护用户隐私，特别适用于对数据安全和实时性要求较高的应用场景，如智能硬件、工业控制和实时字幕生成等。 本文选择了开源的[`sherpa onnx`](https://github.com/k2 fsa/sherpa onnx)框架进行部署, `sherpa onnx`框架是`sherpa`的子项目, 支持流式语音识别,非流式语音识别,文本转语音,说话人分类,说话人识别,说话人验证,口语识别等等。下文主要介绍使用`MaixCAM`与`sherpa onnx`实现流式语音识别. > 注: 流式语音识别的特点是实时性高,并且可以边说边识别, 常用于实时翻译, 语音助手等场景; 非流式语音识别的特点是必须每次推理完整的一句话,准确度高 ## 部署语音识别服务器 `sherpa onnx`支持非常多的语言部署，包括`C/C++`，`Python`，`Java`等等，为了部署方便，我们选择使用`Python`语言部署。下面操作过程中有任何疑问，可以自己先看一遍`sherpa`的[文档](https://k2 fsa.github.io/sherpa/intro.html)， 下面开始部署吧～ #### 下载`sherpa onnx`仓库 ```shell git clone https://github.com/k2 fsa/sherpa onnx.git ``` #### 安装依赖包 ```python pip install numpy pip install websockets ``` #### 安装sherpa onnx包 ```python pip install sherpa onnx ``` 如果需要使用`GPU`， 则下载带`cuda`的包 ```python pip install sherpa onnx 1.10.16+cuda f https://k2 fsa.github.io/sherpa/onnx/cuda.html # 中国用户可以使用 # pip install sherpa onnx 1.10.16+cuda f https://k2 fsa.github.io/sherpa/onnx/cuda cn.html ``` 如果找不到包或安装失败，可以选择从源码编译安装 ```python cd sherpa onnx export SHERPA_ONNX_CMAKE_ARGS \" DSHERPA_ONNX_ENABLE_GPU ON\" python3 setup.py install ``` 如果有`GPU`但是没有`cuda`环境，则点击[`这里`](https://k2 fsa.github.io/k2/installation/cuda cudnn.html)的方法安装对应版本`cuda` #### 检查`sherpa onnx`包是否安装成功 ```python python3 c \"import sherpa_onnx; print(sherpa_onnx.__version__)\" # 输出应该是 # sherpa onnx 或 1.10.16+cuda ``` #### 下载模型 [`中英文双语zipformer模型 sherpa onnx streaming zipformer bilingual zh en 2023 02 20 mobile`](https://github.com/k2 fsa/sherpa onnx/releases/download/asr models/.tar.bz2) [`中英文双语paraformer模型 sherpa onnx streaming paraformer trilingual zh cantonese en`](https://github.com/k2 fsa/sherpa onnx/releases/download/asr models/sherpa onnx streaming paraformer trilingual zh cantonese en.tar.bz2) > 注：中文识别建议用`sherpa onnx streaming zipformer bilingual zh en 2023 02 20 mobile`模型 > > 英文识别建议用`sherpa onnx streaming paraformer trilingual zh cantonese en`模型 #### 运行服务器 `sherpa onnx`提供了一个服务器的示例代码，所以不需要我们再造轮子编代码才能体验在线语音识别，启动方法看下面的示例 ##### 运行`zipformer`模型 ```shell cd sherpa onnx export MODEL_PATH \"sherpa onnx streaming zipformer bilingual zh en 2023 02 20\" python3 ./python api examples/streaming_server.py \\ encoder ./${MODEL_PATH}/encoder epoch 99 avg 1.onnx \\ decoder ./${MODEL_PATH}/decoder epoch 99 avg 1.onnx \\ joiner ./${MODEL_PATH}/joiner epoch 99 avg 1.onnx \\ tokens ./${MODEL_PATH}/tokens.txt \\ provider \"cuda\" ``` 这个示例运行了`streaming_server.py`作为服务器代码，其中` encoder`、` decoder`和` joiner`是模型文件，` tokens`是用来映射模型输出的列表， ` provider`用来指示是否启用`GPU`，默认使用`CPU` ##### 运行`paraformer`模型 ```shell cd sherpa onnx export MODEL_PATH \"sherpa onnx streaming paraformer trilingual zh cantonese en\" python3 ./python api examples/streaming_server.py \\ paraformer encoder ./${MODEL_PATH}/encoder.onnx \\ paraformer decoder ./${MODEL_PATH}/decoder.onnx \\ tokens ./${MODEL_PATH}/tokens.txt \\ provider \"cuda\" ``` 这个示例运行了`streaming_server.py`作为服务器代码，其中` paraformer encoder`和` paraformer encoder`是模型文件，` tokens`是用来映射模型输出的列表， ` provider`用来指示是否启用`GPU`，默认使用`CPU` ##### 运行成功后的日志 ```shell 2024 12 23 09:25:17,557 INFO [streaming_server.py:667] No certificate provided 2024 12 23 09:25:17,561 INFO [server.py:715] server listening on [::]:6006 2024 12 23 09:25:17,561 INFO [server.py:715] server listening on 0.0.0.0:6006 2024 12 23 09:25:17,561 INFO [streaming_server.py:693] Please visit one of the following addresses: http://localhost:6006 Since you are not providing a certificate, you cannot use your microphone from within the browser using public IP addresses. Only localhost can be used.You also cannot use 0.0.0.0 or 127.0.0.1 ``` 至此ASR模型服务器就跑起来了，开始与服务器通信 #### 基于`MaixCAM`与服务器通信 为了简化篇幅这里放了示例客户端代码的链接，自行拷贝。注意大部分情况音频数据要求采样率`16000Hz`， 采样通道为`1`。 `MaixCAM`流式识别点击[这里](https://github.com/sipeed/MaixPy/blob/main/examples/audio/asr/asr_streaming_websockt_client)获取代码 `MaixCAM`非流式识别点击[这里](https://github.com/sipeed/MaixPy/blob/main/examples/audio/asr/asr_non_streaming_websockt_client)获取代码 ```shell # 修改服务器地址 SERVER_ADDR \"127.0.0.1\" SERVER_PORT 6006 ``` 修改服务器地址和端口号后，再使用`maixvision`运行即可。如果你运行的是流式识别的代码，那么尝试跟`MaixCAM`开始对话吧～ > 注：这里没有过多赘述客户端和服务器通信的协议的原因之一是因为它们通信很简单，基本是`websocket`连接后的数据裸收发，建议先上手体验后直接看代码来了解真正想知道的信息。 至此就部署完成了"},"/maixpy/doc/zh/audio/play.html":{"title":"MaixCAM MaixPy 播放音频","content":" title: MaixCAM MaixPy 播放音频 update: date: 2024 05 20 author: lxowalle version: 1.0.0 content: 初版文档 ## 简介 本文档提供播放音频的使用方法 ## 使用方法 ### 硬件支持情况 设备 麦克风 喇叭 MaixCAM ✅ ❌ MaixCAM2 ✅ ✅ MaixCAM Pro ✅ ✅ ### 硬件操作 ![image 20240520134637905](../../../static/image/maixcam_hardware_back.png) `MaixCAM`没有内置喇叭，因此需要自行焊接一个功率在`1W`内的喇叭。喇叭焊接的引脚见上图的Speaker对应的`VOP`和`VON`脚。 注：如果`MaixCAM`在这两个脚上连接了铜柱，则可以直接焊接在铜柱上，为了美观也可以焊接在板子的另一面。 ### 编写代码 #### 播放一个`WAV`文件 ```python from maix import audio, time, app p audio.Player(\"/root/output.wav\") p.play() p.volume(80) while not app.need_exit(): time.sleep_ms(10) print(\"play finish!\") ``` 步骤： 1. 导入audio、time和app模块 ```python from maix import audio, time, app ``` 2. 初始化播放器 ```python p audio.Player(\"/root/output.wav\") p.volume(80) ``` 默认的采样率是48k，采样格式为小端格式 有符号16位，采样通道为1。你也可以像这样自定义参数`p audio.Player(sample_rate 48000, format audio.Format.FMT_S16_LE, channel 1)`。目前只测试过采样率48000，`FMT_S16_LE`格式，和采样通道数为1。 如果是`.wav`文件，则会自动获取采样率、采样格式和采样通道。 `p.volume(80)`设置音量为80，范围为[0~100]。 3. 播放音频 ```python p.play() ``` 该操作将会阻塞直到写入所有音频数据，但不会阻塞到实际播放完所有音频数据。如果调用`play()`后退出了程序，则部分待播放的音频数据可能会丢失。 4. 完成 #### 用`PCM`数据播放 ```python from maix import audio, time, app p audio.Player() with open('/root/output.pcm', 'rb') as f: ctx f.read() p.play(bytes(ctx)) while not app.need_exit(): time.sleep_ms(10) print(\"play finish!\") ``` 步骤： 1. 导入audio、time和app模块 ```python from maix import audio, time, app ``` 2. 初始化播放器 ```python p audio.Player() ``` 注意默认的采样率是48k，采样格式为小端格式 有符号16位，采样通道为1。你也可以像这样自定义参数`p audio.Player(sample_rate 48000, format audio.Format.FMT_S16_LE, channel 1)`。目前只测试过采样率48000，`FMT_S16_LE`格式，和采样通道数为1 3. 打开并播放一个PCM文件 ```python with open('/root/output.pcm', 'rb') as f: ctx f.read() p.play(bytes(ctx)) while not app.need_exit(): time.sleep_ms(10) ``` `with open('xxx','rb') as f:`打开文件`xxx`， 并获取文件对象`f` `ctx f.read()`将读取文件的内容到`ctx`中 `p.play(bytes(ctx))`播放音频，`p`是已打开的播放器对象， `ctx`是转换为bytes类型的`PCM`数据 `time.sleep_ms(10)`这里有一个循环来等待播放完成，因为播放操作是异步执行的，如果提前退出了程序，那么可能导致音频不会完全播放。 4. 完成 #### 非阻塞播放 当做语音助手, 实时通信等场景时通常需要播放音频的过程不能阻塞主线程, 因此可以将`Player`设置为非阻塞模式,并添加一些应用层代码来支持播放时不阻塞主线程的方法. 参考示例如下: ```python from maix import audio, app, time import threading from queue import Queue, Empty class StreamPlayer: def __init__(self, sample_rate 16000, channel 1, block:bool False): self.p audio.Player(sample_rate sample_rate, channel channel, block block) self.p.volume(50) zero_data bytes([0] * 4096) self.p.play(zero_data) self.queue Queue(maxsize 250) self.t threading.Thread(target self.__thread, daemon True) self.t.start() def wait_idle_size(self, size:int): while not app.need_exit(): idle_frames self.p.get_remaining_frames() write_frames size / self.p.frame_size() if idle_frames > write_frames: break time.sleep_ms(10) def __thread(self): while not app.need_exit(): try: pcm self.queue.get(timeout 500) # wait player is idle self.wait_idle_size(len(pcm)) self.p.play(pcm) except Empty: continue def write(self, pcm:bytes): remain_len len(pcm) period_bytes self.p.frame_size() * self.p.period_size() offset 0 while remain_len > 0: write_bytes period_bytes if period_bytes < remain_len else period_bytes remain_len new_pcm pcm[offset:offset+write_bytes] self.queue.put(new_pcm) remain_len write_bytes offset + write_bytes def wait_finish(self): total_frames self.p.period_count() * self.p.period_size() while not app.need_exit(): idle_frames self.p.get_remaining_frames() if idle_frames total_frames: break time.sleep_ms(10) if __name__ '__main__': stream_player StreamPlayer() with open('/maixapp/share/audio/demo.wav', 'rb') as f: pcm f.read() t time.ticks_ms() stream_player.write(pcm) print(f'write pcm data cost {time.ticks_ms() t} ms') t time.ticks_ms() stream_player.wait_finish() print(f'write play finish cost {time.ticks_ms() t} ms') ``` 这个示例里通过`block`参数将`Player`对象设置为了非阻塞模式, 因此调用`play()`方法时不会阻塞主线程 由于内部的缓存大小的限制, 如果一定时间内播放的数据量大于缓冲量时, 还是会阻塞在`play`方法中, 因此可以通过`get_remaining_frames()`方法来获取buffer剩余空间的大小, 需要注意该方法返回的单位为`帧`, 通过`frame_size()`方法可以将要`帧`转换为`字节` ```python remaining_frames p.get_remaining_frames()\t\t# unit:frame remaining_bytes p.frame_size(remaining_frames) # unit: bytes ``` 可以将播放操作放在另一个线程中, 并且可以播放前检查如果剩余空间足够时, 再调用`play()`来播放, 这样就能保证一定不会阻塞主线程."},"/maixpy/doc/zh/audio/keyword.html":{"title":"MaixCAM MaixPy 关键词识别","content":" title: MaixCAM MaixPy 关键词识别 update: date: 2024 10 08 author: 916BGAI version: 1.0.0 content: 初版文档 ## 简介 `MaixCAM` 移植了 `Maix Speech` 离线语音库，实现了连续中文数字识别、关键词识别以及大词汇量语音识别功能。支持 `PCM` 和 `WAV` 格式的音频识别，且可通过板载麦克风进行输入识别。 ## Maix Speech [`Maix Speech`](https://github.com/sipeed/Maix Speech) 是一款专为嵌入式环境设计的离线语音识别库，针对语音识别算法进行了深度优化，显著降低内存占用，同时在识别准确率方面表现优异。详细说明请参考 [Maix Speech 使用文档](https://github.com/sipeed/Maix Speech/blob/master/usage_zh.md)。 ## 关键词识别 ```python from maix import app, nn speech nn.Speech(\"/root/models/am_3332_192_int8.mud\") speech.init(nn.SpeechDevice.DEVICE_MIC) kw_tbl ['xiao3 ai4 tong2 xue2', 'ni3 hao3', 'tian1 qi4 zen3 me yang4'] kw_gate [0.1, 0.1, 0.1] def callback(data:list[float], len: int): for i in range(len): print(f\"\\tkw{i}: {data[i]:.3f};\", end ' ') print(\"\\n\") speech.kws(kw_tbl, kw_gate, callback, True) while not app.need_exit(): frames speech.run(1) if frames < 1: print(\"run out\\n\") break ``` ### 使用方法 1. 导入 `app` 和 `nn` 模块 ```python from maix import app, nn ``` 2. 加载声学模型 ```python speech nn.Speech(\"/root/models/am_3332_192_int8.mud\") ``` 也可以加载 `am_7332` 声学模型，模型越大精度越高但是消耗的资源也越大 3. 选择对应的音频设备 ```python speech.init(nn.SpeechDevice.DEVICE_MIC) speech.init(nn.SpeechDevice.DEVICE_MIC, \"hw:0,0\") # 指定音频输入设备 ``` 这里使用的是板载的麦克风，也选择 `WAV` 和 `PCM` 音频作为输入 ```python speech.init(nn.SpeechDevice.DEVICE_WAV, \"path/audio.wav\") # 使用 WAV 音频输入 ``` ```python speech.init(nn.SpeechDevice.DEVICE_PCM, \"path/audio.pcm\") # 使用 PCM 音频输入 ``` 注意 `WAV` 需要是 `16KHz` 采样，`S16_LE` 存储格式，可以使用 `arecord` 工具转换 ```shell arecord d 5 r 16000 c 1 f S16_LE audio.wav ``` 在 `PCM/WAV` 识别时，如果想要重新设置数据源，例如进行下一个WAV文件的识别可以使用 `speech.device` 方法，内部会自动进行缓存清除操作： ```python speech.device(nn.SpeechDevice.DEVICE_WAV, \"path/next.wav\") ``` 4. 设置解码器 ```python kw_tbl ['xiao3 ai4 tong2 xue2', 'ni3 hao3', 'tian1 qi4 zen3 me yang4'] kw_gate [0.1, 0.1, 0.1] def callback(data:list[float], len: int): for i in range(len): print(f\"\\tkw{i}: {data[i]:.3f};\", end ' ') print(\"\\n\") speech.kws(kw_tbl, kw_gate, callback, True) ``` 用户可以同时设置多个解码器，`kws` 解码器用于输出最近一帧所有注册的关键词的概率列表，用户可以观察概率值，自行设定阈值进行唤醒。 设置 `kws` 解码器时需要设置 `关键词列表`，以拼音间隔空格填写，`关键词概率门限表`，按顺序排列输入即可，是否进行 `自动近音处理`，设置为 `True` 则会自动将不同声调的拼音作为近音词来合计概率。最后还要设置一个回调函数用于处理解码出的数据。 用户还可以使用 `speech.similar` 方法手工注册近音词，每个拼音可以注册最多 `10` 个近音词。（注意，使用该接口注册近音词会覆盖使能 `自动近音处理` 里自动生成的近音表） ```python similar_char ['zhen3', 'zheng3'] speech.similar('zen3', similar_char) ``` 如果不再需要使用某个解码器，可以通过调用 `speech.dec_deinit` 方法进行解除初始化。 ```python speech.dec_deinit(nn.SpeechDecoder.DECODER_KWS) ``` 5. 识别 ```python while not app.need_exit(): frames speech.run(1) if frames < 1: print(\"run out\\n\") break ``` 使用 `speech.run` 方法运行语音识别，传入的参数为每次运行的帧数，返回实际运行的帧数。用户可以选择每次运行1帧后进行其他处理，或在一个线程中持续运行，使用外部线程进行停止。 若需清除已识别结果的缓存，可以使用 `speech.clear` 方法。 在识别过程中切换解码器，切换后的第一帧可能会出现识别错误。可以使用 `speech.skip_frames(1)` 跳过第一帧，确保后续结果准确。 ### 识别结果 如果上述程序运行正常，对板载麦克风说话，会得到关键词识别结果，如： ```shell kws log 2.048s, len 24 decoder_kws_init get 3 kws 00, xiao3 ai4 tong2 xue2 01, ni3 hao3 02, tian1 qi4 zen3 me yang4 find shared memory(491520), saved:491520 kw0: 0.959; \tkw1: 0.000; \tkw2: 0.000; # 小爱同学 kw0: 0.000; \tkw1: 0.930; \tkw2: 0.000; # 你好 kw0: 0.000; \tkw1: 0.000; \tkw2: 0.961; # 天气怎么样 ```"},"/maixpy/doc/zh/audio/record.html":{"title":"MaixCAM MaixPy 录音","content":" title: MaixCAM MaixPy 录音 update: date: 2024 05 20 author: lxowalle version: 1.0.0 content: 初版文档 date: 2025 01 24 author: lxowalle version: 1.0.1 content: 更新audio模块的使用方法 ## 简介 本文档提供录音的使用方法，支持录入`PCM`和`WAV`格式的音频。 `PCM(Pulse Code Modulation)` 是一种数字音频编码格式，用于将模拟音频信号转换为数字信号，也是一般需要硬件处理所需的常用格式 `WAV(Waveform Audio File Format)`是一种常见的音频文件格式。它通常用于存储未压缩的` PCM `音频数据，但也支持其他编码格式。 `MaixCAM`板载了麦克风，所以你可以直接使用录音功能。 ### 硬件支持情况 设备 麦克风 喇叭 MaixCAM ✅ ❌ MaixCAM2 ✅ ✅ MaixCAM Pro ✅ ✅ ### 使用方法 #### 录制一个`PCM`/`WAV`格式的音频文件 在创建`Recorder`对象时传入了`path`， 则录入的音频将会保存到`path`文件中，你也可以通过`record`方法获取当前录入的`PCM`数据。`path`只支持`.pcm`和`.wav`后缀的路径。当录入`.wav`时，`record`方法不会返回`WAV`头部信息，只会返回`PCM`数据。 ```python from maix import audio r audio.Recorder(\"/root/test.wav\") r.volume(100) print(f\"channel: {r.channel()}\") print(f\"sample rate: {r.sample_rate()}\") r.record(3000) ``` 步骤： 1. 导入audio模块 ```python from maix import audio ``` 2. 初始化录制器 ```python r audio.Recorder(\"/root/test.wav\") r.volume(100) ``` 音频文件会保存到`/root/test.wav` 注意默认的采样率是48k，采样格式为小端格式 有符号16位，采样通道为1。你也可以像这样自定义参数`p audio.Recorder(sample_rate 48000, format audio.Format.FMT_S16_LE, channel 1)`。目前只测试过采样率16000和48000，`FMT_S16_LE`格式，和采样通道数为1 `r.volume(100)`用来设置音量，音量范围为[0,100] 3. 开始录制 ```python r.record(3000) ``` 录制`3000`毫秒的音频 该函数会阻塞直到录入完成 4. 完成 #### 录制一个`PCM`/`WAV`格式的音频文件（非阻塞） 开发应用是如果需要录音，但又不希望录音函数占用其他应用的时间，则可以开启非阻塞模式 ```python from maix import audio, app, time r audio.Recorder(\"/root/test.wav\", block False) r.volume(100) r.reset(True) while not app.need_exit(): data r.record(50) // Your application time.sleep_ms(50) print(\"finish!\") ``` 注意： 1. 非阻塞录制时，需要使用`reset(True)`函数来启用音频流，使用`reset(False)`函数来停止音频流 2. `record`返回的音频数据长度不一定与传入的时间对等，比如假设录制`50ms`音频，但此时音频缓冲区只有`20ms`的数据已经准备好了，那么`record(50)`只会返回`20ms`的音频数据 3. 如果希望record()返回的音频数据与传入参数相等，则可以让等待缓存区准备了足够的音频数据后再读取 ```python remaining_frames r.get_remaining_frames() need_frames 50 * r.sample_rate() / 1000 if remaining_frames > need_frames: data r.record(50) ``` 使用`get_remaining_frames()`函数获取接收缓冲区剩余的帧数，注意返回的是帧数，不是字节数。通过`sample_rate()`获取音频采样率，并计算实际要读取的帧数。 #### 获取实时`PCM`音频流 开发需要处理音频数据的应用时，不需要保存文件，只需要获取`PCM`裸流的场景。要实现这个功能，只需要在创建`Recorder`时不传入路径即可。当然你也可以开启非阻塞模式。 ```python from maix import audio, app, time r audio.Recorder(block False) r.volume(100) r.reset(True) while not app.need_exit(): data r.record(50) print(f'record {len(data)} bytes') // Your application time.sleep_ms(50) ``` 代码含义基本同上。"},"/maixpy/doc/zh/audio/digit.html":{"title":"MaixCAM MaixPy 连续中文数字识别","content":" title: MaixCAM MaixPy 连续中文数字识别 update: date: 2024 10 08 author: 916BGAI version: 1.0.0 content: 初版文档 ## 简介 `MaixCAM` 移植了 `Maix Speech` 离线语音库，实现了连续中文数字识别、关键词识别以及大词汇量语音识别功能。支持 `PCM` 和 `WAV` 格式的音频识别，且可通过板载麦克风进行输入识别。 ## Maix Speech [`Maix Speech`](https://github.com/sipeed/Maix Speech) 是一款专为嵌入式环境设计的离线语音识别库，针对语音识别算法进行了深度优化，显著降低内存占用，同时在识别准确率方面表现优异。详细说明请参考 [Maix Speech 使用文档](https://github.com/sipeed/Maix Speech/blob/master/usage_zh.md)。 ## 连续中文数字识别 ```python from maix import app, nn speech nn.Speech(\"/root/models/am_3332_192_int8.mud\") speech.init(nn.SpeechDevice.DEVICE_MIC) def callback(data: str, len: int): print(data) speech.digit(640, callback) while not app.need_exit(): frames speech.run(1) if frames < 1: print(\"run out\\n\") break ``` ### 使用方法 1. 导入 `app` 和 `nn` 模块 ```python from maix import app, nn ``` 2. 加载声学模型 ```python speech nn.Speech(\"/root/models/am_3332_192_int8.mud\") ``` 也可以加载 `am_7332` 声学模型，模型越大精度越高但是消耗的资源也越大 3. 选择对应的音频设备 ```python speech.init(nn.SpeechDevice.DEVICE_MIC) speech.init(nn.SpeechDevice.DEVICE_MIC, \"hw:0,0\") # 指定音频输入设备 ``` 这里使用的是板载的麦克风，也选择 `WAV` 和 `PCM` 音频作为输入 ```python speech.init(nn.SpeechDevice.DEVICE_WAV, \"path/audio.wav\") # 使用 WAV 音频输入 ``` ```python speech.init(nn.SpeechDevice.DEVICE_PCM, \"path/audio.pcm\") # 使用 PCM 音频输入 ``` 注意 `WAV` 需要是 `16KHz` 采样，`S16_LE` 存储格式，可以使用 `arecord` 工具转换 ```shell arecord d 5 r 16000 c 1 f S16_LE audio.wav ``` 在 `PCM/WAV` 识别时，如果想要重新设置数据源，例如进行下一个WAV文件的识别可以使用 `speech.device` 方法，内部会自动进行缓存清除操作： ```python speech.device(nn.SpeechDevice.DEVICE_WAV, \"path/next.wav\") ``` 4. 设置解码器 ```python def callback(data: str, len: int): print(data) speech.digit(640, callback) ``` 用户可以同时设置多个解码器，`digit` 解码器的作用是输出最近4s内的中文数字识别结果。返回的识别结果为字符串形式，支持 `0123456789 .(点) S(十) B(百) Q(千) W(万)`。 设置 `digit` 解码器时需要设置 `blank` 值，超过该值（ms）则在输出结果里插入一个 `_` 表示空闲静音 如果不再需要使用某个解码器，可以通过调用 `speech.dec_deinit` 方法进行解除初始化。 ```python speech.dec_deinit(nn.SpeechDecoder.DECODER_DIG) ``` 5. 识别 ```python while not app.need_exit(): frames speech.run(1) if frames < 1: print(\"run out\\n\") break ``` 使用 `speech.run` 方法运行语音识别，传入的参数为每次运行的帧数，返回实际运行的帧数。用户可以选择每次运行1帧后进行其他处理，或在一个线程中持续运行，使用外部线程进行停止。 若需清除已识别结果的缓存，可以使用 `speech.clear` 方法。 在识别过程中切换解码器，切换后的第一帧可能会出现识别错误。可以使用 `speech.skip_frames(1)` 跳过第一帧，确保后续结果准确。 ### 识别结果 如果上述程序运行正常，对板载麦克风说话，会得到连续中文数字识别结果，如： ```shell _0123456789 ```"},"/maixpy/doc/zh/audio/recognize.html":{"title":"MaixCAM MaixPy 语音实时识别","content":" title: MaixCAM MaixPy 语音实时识别 update: date: 2024 10 08 author: 916BGAI version: 1.0.0 content: 初版文档 date: 2025 05 13 author: lxowalle version: 1.0.1 content: 新增whisper的使用说明 ## 简介 `MaixCAM` 移植了 `Maix Speech` 离线语音库，实现了连续中文数字识别、关键词识别以及大词汇量语音识别功能。支持 `PCM` 和 `WAV` 格式的音频识别，且可通过板载麦克风进行输入识别。 此外，我们把 OpenAI 的语音识别模型 Whisper 移植到`MaixCAM2`上，即使是在资源比较有限的设备上，也能运行强大的语音转文字功能。 语音识别模型支持列表: MaixCAM MaixCAM Pro MaixCAM2 Whisper ❌ ❌ ✅ Speech ✅ ✅ ❌ ## 使用Whisper做语音转文字 > MaixCAM和MaixCAM Pro不支持使用whisper模型 目前支持`base`尺寸的whisper模型，支持输入单通道、16k采样率的wav音频文件，支持识别中文和英文。下面是使用Whisper识别语音的简单示例： ```python from maix import nn whisper nn.Whisper(model \"/root/models/whisper base/whisper base.mud\") wav_path \"/maixapp/share/audio/demo.wav\" res whisper.transcribe(wav_path) print('res:', res) ``` 注： 1. 首先需要导入nn模块才能创建Whisper模型对象 ```python from maix import nn ``` 2. 选择需要加载的模型，目前支持base尺寸的whisper模型 ```python whisper nn.Whisper(model \"/root/models/whisper base/whisper base.mud\") ``` 3. 准备一个单通道、16k采样率的wav音频文件，并进行推理，推理结果会直接返回 ```python wav_path \"/maixapp/share/audio/demo.wav\" res whisper.forward(wav_path) print('whisper:', res) ``` 4. 输出结果 ```shell whisper: 开始愉快的探索吧 ``` 5. 动手试试吧～ 默认为识别中文，如果需要识别英文，在初始化对象时填入language参数 ```python whisper nn.Whisper(model \"/root/models/whisper base/whisper base.mud\", language \"en\") ``` ## Maix Speech [`Maix Speech`](https://github.com/sipeed/Maix Speech) 是一款专为嵌入式环境设计的离线语音识别库，针对语音识别算法进行了深度优化，显著降低内存占用，同时在识别准确率方面表现优异。详细说明请参考 [Maix Speech 使用文档](https://github.com/sipeed/Maix Speech/blob/master/usage_zh.md)。 ### 连续大词汇量语音识别 ```python from maix import app, nn speech nn.Speech(\"/root/models/am_3332_192_int8.mud\") speech.init(nn.SpeechDevice.DEVICE_MIC) def callback(data: tuple[str, str], len: int): print(data) lmS_path \"/root/models/lmS/\" speech.lvcsr(lmS_path + \"lg_6m.sfst\", lmS_path + \"lg_6m.sym\", \\ lmS_path + \"phones.bin\", lmS_path + \"words_utf.bin\", \\ callback) while not app.need_exit(): frames speech.run(1) if frames < 1: print(\"run out\\n\") break ``` ### 使用方法 1. 导入 `app` 和 `nn` 模块 ```python from maix import app, nn ``` 2. 加载声学模型 ```python speech nn.Speech(\"/root/models/am_3332_192_int8.mud\") ``` 也可以加载 `am_7332` 声学模型，模型越大精度越高但是消耗的资源也越大 3. 选择对应的音频设备 ```python speech.init(nn.SpeechDevice.DEVICE_MIC) speech.init(nn.SpeechDevice.DEVICE_MIC, \"hw:0,0\") # 指定音频输入设备 ``` 这里使用的是板载的麦克风，也选择 `WAV` 和 `PCM` 音频作为输入 ```python speech.init(nn.SpeechDevice.DEVICE_WAV, \"path/audio.wav\") # 使用 WAV 音频输入 ``` ```python speech.init(nn.SpeechDevice.DEVICE_PCM, \"path/audio.pcm\") # 使用 PCM 音频输入 ``` 注意 `WAV` 需要是 `16KHz` 采样，`S16_LE` 存储格式，可以使用 `arecord` 工具转换 ```shell arecord d 5 r 16000 c 1 f S16_LE audio.wav ``` 在 `PCM/WAV` 识别时，如果想要重新设置数据源，例如进行下一个WAV文件的识别可以使用 `speech.device` 方法，内部会自动进行缓存清除操作： ```python speech.device(nn.SpeechDevice.DEVICE_WAV, \"path/next.wav\") ``` 4. 设置解码器 ```python def callback(data: tuple[str, str], len: int): print(data) lmS_path \"/root/models/lmS/\" speech.lvcsr(lmS_path + \"lg_6m.sfst\", lmS_path + \"lg_6m.sym\", \\ lmS_path + \"phones.bin\", lmS_path + \"words_utf.bin\", \\ callback) ``` 用户可以同时设置多个解码器，`lvcsr` 解码器用于输出连续语音识别结果（小于1024个汉字结果）。 设置 `lvcsr` 解码器时需要设置 `sfst` 文件路径，`sym` 文件路径（输出符号表），`phones.bin` 的路径（拼音表），和 `words.bin` 的路径（词典表）。最后还要设置一个回调函数用于处理解码出的数据。 如果不再需要使用某个解码器，可以通过调用 `speech.dec_deinit` 方法进行解除初始化。 ```python speech.dec_deinit(nn.SpeechDecoder.DECODER_LVCSR) ``` 5. 识别 ```python while not app.need_exit(): frames speech.run(1) if frames < 1: print(\"run out\\n\") break ``` 使用 `speech.run` 方法运行语音识别，传入的参数为每次运行的帧数，返回实际运行的帧数。用户可以选择每次运行1帧后进行其他处理，或在一个线程中持续运行，使用外部线程进行停止。 若需清除已识别结果的缓存，可以使用 `speech.clear` 方法。 在识别过程中切换解码器，切换后的第一帧可能会出现识别错误。可以使用 `speech.skip_frames(1)` 跳过第一帧，确保后续结果准确。 ### 识别结果 如果上述程序运行正常，对板载麦克风说话，会得到实时语言识别结果，如： ```shell ### SIL to clear decoder! ('今天天气 怎么样 ', 'jin1 tian1 tian1 qi4 zen3 me yang4 ') ```"},"/maixpy/doc/zh/audio/synthesis.html":{"title":"MaixCAM MaixPy 语音合成","content":" title: MaixCAM MaixPy 语音合成 update: date: 2025 08 15 author: lxowalle version: 1.0.0 content: 初版文档 ## 简介 本文档提供内置TTS的使用方法，以支持将文本转为语音的功能。 TTS支持列表 MaixCAM MaixCAM Pro MaixCAM2 MeloTTS ❌ ❌ ✅ ## TTS介绍 TTS(Text to speech)的作用是把文本转为语音,你可以编辑一段文本,然后交给支持TTS的模型,运行模型后会输出内容为该文本的音频数据. 现实常用TTS来实现视频配音,地图导航,公共场合播报等等.简单理解TTS就是“把文字念出来的技术” ## MelloTTS MeloTTS是由MIT和MyShell.ai联合开发的一款高质量多语言文本转语音库. 目前支持`melotts zh`模型, 该模型支持中英文语音合成, 但是英文合成的效果还不太好. 默认输出音频为采样率44100, 单通道, 16位采样深度的PCM数据. > 采样率: 每秒采集声音的次数 > > 通道: 每次采集声音的声道数. 单通道可以认为是采集单声道的音频, 双通道可以是采集左右两个声道的音频. 为了降低AI推理的复杂度, 一般使用单通道的音频数据. > > 采样深度: 每次采集声音的数据范围. 16位采样深度一般表示一次采集16位有符号整数大小的数据.采样深度越大, 越容易采集到声音的细微变化. ```python from maix import nn, audio # Only MaixCAM2 supports this model. sample_rate 44100 p audio.Player(sample_rate sample_rate) p.volume(80) melotts nn.MeloTTS(model \"/root/models/melotts/melotts zh.mud\", speed 0.8, language 'zh') pcm melotts.infer('你好', output_pcm True) p.play(pcm) ``` 注： 1. 首先需要导入nn模块才能创建MelloTTS模型对象 ```python from maix import nn ``` 2. 选择需要加载的模型，目前支持`melotts zh`模型 speed用来设置播放的语速 language用来设置语言类型 ```python melotts nn.MeloTTS(model \"/root/models/melotts/melotts zh.mud\", speed 0.8, language 'zh') ``` 3. 开始推理 这里推理的文本为'你好' 将output_pcm设置为True来返回pcm数据 ```python pcm melotts.infer('你好', output_pcm True) ``` 4. 使用音频播放模块来播放刚才生成的音频 注意采样率要设置为与模型输出的采样率一致 把使用`p.volume(80)`来控制输出的音量, 范围为[0, 100] 使用`p.play(pcm)`开始播放由MeloTTS生成的pcm ```shell p audio.Player(sample_rate sample_rate) p.volume(80) p.play(pcm) ```"},"/maixpy/doc/zh/audio/ai_classify.html":{"title":"MaixCAM MaixPy AI 声音分类","content":" title: MaixCAM MaixPy AI 声音分类 TODO: 待完成，如果你急需，可以先自行移植模型，或者先将声音用 FFT 处理成瀑布图，再以图片的方式进行训练 AI 分类识别。"},"/maixpy/doc/zh/faq.html":{"title":"MaixCAM MaixPy FAQ(常见问题)","content":" title: MaixCAM MaixPy FAQ(常见问题) >! 此页面列出了 MaixPy 相关的常见问题和解决方案，如果你遇到了问题，请先在这里找寻答案。 > 另外还有其它途径： > * [MaixHub 讨论版块](https://maixhub.com/discussion): 交流讨论，支持红包打赏。 > * [MaixPy issue](https://github.com/sipeed/MaixPy/issues?q ): 源码相关问题。 > * [MaixCAM 硬件 FAQ](https://wiki.sipeed.com/hardware/zh/maixcam/faq.html): MaixCAM 硬件常见问题。 ## MaixVision 无法搜索到设备？ 先确认连接方式是 WiFi 还是 USB 线， **WiFi**: * 确认 WiFi 是否正确连接上并且获取到 IP 地址， 可以在 `设置 >设备信息` 或者`设置 >WiFi` 里面看到 `ip`。 **USB线**: * 确保设备通过 Type C 数据线连接到电脑，设备处于开机状态并且进入了功能选择界面。 * 确保设备驱动已经安装： * Windows 下可以在`设备管理器`中查看是否有 USB 虚拟网卡设备，如果有感叹号则是去动没有安装好，按照[快速开始](./index.html) 中的方法安装驱动即可。 * Linux 下可以通过`ifconfig`或者`ip addr`查看是否有`usb0`设备或者`lsusb`查看所有 USB 设备。 Linux 已经自带去动，所以识别不到检查硬件连接，设备系统是否是最新，以及设备是否已经正常启动即可。 * Mac OS 同 Linux 方法，或者在`系统设置` > `网络` 里面看有没有 usb 网卡。 * 另外 检查 USB 线缆的质量，换一个高质量的线缆。 * 另外 检查电脑 USB 口的质量，比如实测某些小主机 USB 口 EMI 设计太糟糕，外接一个质量好点的 USB HUB 反而可以使用了，也可以换 USB 口 或者直接换台电脑。 ## MaixVision 运行摄像头例程显示图像卡顿 默认配的 GC4653 摄像头最高帧率为 30 帧，摄像头例程正常情况下 MaixVision 的显示肉眼不会有卡顿感，如果卡顿，首先考虑传输问题： * 检查网络连接质量，比如 WiFi。 * 如果用的 USB 连接，检查 USB 线质量， 电脑 USB 口质量，可以尝试换台电脑或者 USB 口 或者 USB 线缆尝试对比。 ## MaixVision MacOS 无法运行 对于 MacOS，由于前期还没有用开发者账号签名，可能会遇到 提示权限不足或者文件损坏问题， 请参考[这里](https://maixhub.com/discussion/100301) 解决（在终端中执行命令sudo xattr dr com.apple.quarantine /Applications/应用名称.app来移除这个属性）。 ## 此产品适合量产吗 答案：适合。 * 软件上使用 Python 即可稳定运行，方便开发也可靠。 * 软件上另外支持和 MaixPy 相同 API 的 C++ SDK（MaixCDK），满足高效率和稳定要求。 * 硬件上提供各种形式的 PCB 和外壳，核心板和整板都有，芯片供货稳定，如果有量产需求可以联系 support@sipeed.com 咨询。 * 量大价更优。 ## MaixPy v4 和 v1 v3 有什么区别？ * MaixPy v4 使用 Python 语言，是吸取了 v1 v3 经验的集大成之作，有更好的配套软件和生态，更多的功能，更简单的使用方式和更完善的文档；硬件有很大提升的同时加个和另外两者的硬件价格想当甚至更便宜；另外也做了兼容 K210 的使用体验和 API，方便用户从 v1 快速迁移到 v4。 * v1 使用了 Micropython 语言，有很多局限性，比如第三方库支持有限；同时受限于 Maix I (K210) 的硬件性能，内存不够用，AI 模型支持有限，很多编解码不支持硬件加速等缺点。 * v3 也是使用了 Python 语言，基于 Maix II Dock (v831) 硬件，硬件 AI 模型支持有限，而且全志的基础生态不够开放，API 也不够完善，此版本仅作为 Maix II Dock (v831)上面使用，不会继续更新。 ## MaixPy 目前只支持 MaixCAM 吗，用其它同款芯片的板子行不行？ MaixPy 目前仅支持 MaixCAM 系列板子，其它同款芯片的板子也不支持（包括 Sipeed 的同款芯片板子 比如 LicheeRV Nano），强烈不建议尝试，导致设备损坏（比如冒烟烧屏等）后果自负。 未来 Sipeed 出的 Maix 系列的产品都将继续得到 MaixPy 支持，目前如果 MaixCAM 有什么无法满足的需求，可以到 [MaixHub 讨论版块](https://maixhub.com/discussion) 提出需求或者发送邮件到 support@sipeed.com. ## 可以用除了官方搭配的摄像头或者屏幕以外的自己的摄像头或者屏幕吗？ 不建议这样操作，除非你有够丰富的软硬件知识和经验，否则可能导致设备损坏。 官方搭配的配件对应的软硬件是调教过的，表现效果是最好的，上手即可使用，其它配件可能接口不同，驱动不同，软件不同，需要自己去调教，这是一个非常复杂的过程，不建议尝试。 当然，如果你是大佬，我们也欢迎你提交 PR！ ## 运行模型报错 cvimodel built for xxxcv181x CANNOT run on platform cv181x 解析模型文件失败了，一般情况是模型文件损坏造成的，确保你的模型文件是没有损坏的。 比如： * 用编辑器编辑了二进制文件导致文件损坏。比如用 maixvision 打开了 cvimodel 文件，由于 maixvision 的自动保存功能会破坏二进制文件，所以不要用 maixvision 等文本编辑器打开二进制文件并保存（后面 MaixVision 会修复这个问题，即去掉 maixvision 的自动保存功能）。 * 如果是从网上下载的，保证下载没有出问题，一般网上的文件提供 sha256sum/md5 校验值，下载下来后可以对比一下，具体方法请自行搜索或者问 ChatGPT。 * 如果是来自压缩包，请确认解压过程没有出错，可以从压缩包重新解压一遍保证中间没有出错。 * 保证传输到设备的过程没有造成文件损坏，可以对比一下设备中的文件和电脑中的文件 sha256sum 值，具体方法请自性搜索或者问 ChatGPT。 ## 上电启动黑屏，屏幕无显示 请看 [MaixCAM FAQ](https://wiki.sipeed.com/hardware/zh/maixcam/faq.html) ## 通过 USB 连接了电脑和 MaixCAM 为什么电脑没有出现串口？ MaixCAM 的 USB 口是芯片的 USB2.0 接口，不是 USB 转串口接口，所以插上电脑不会出现串口，这是正常现象。 没有 USB 转串口怎么通信呢？ 默认 USB 会模拟出 USB 网卡，所以当你将 USB 插上电脑时会出现虚拟网卡，按照 [快速开始](./index.html) 中的说明可以使用 MaixVision 与 MaixCAM 通信实现代码运行、图像预览、文件管理等功能。 另外，因为 USB 模拟了网卡，所以你也可以用通用的 SSH 软件连接 MaixCAM，实现通信。 或者你也可以连接 WiFi 和电脑在同一个局域网下通信。 如果你要使用串口，分为两种情况： 1. 串口和电脑通信：需要自行购买任意一款 USB 转串口模块来连接电脑的 USB 和板子的串口（对于MaixCAM 是 UART0 的 A16(TX) 和 A17(RX) 引脚，或者连接 MaixCAM 套餐送的 USB 转接板引出的两个 TX RX 引脚，也是 A16 A17 引脚，是等效的） 2. 串口和其它 MCU/SOC 通信: 直接连接 MaixCAM 的 A16(TX)和 A17(RX) 到 单片机的 RX 和 TX 引脚即可。 ## 红色屏幕，提示初始化显示失败，请查看FAQ 从子面意思可以看到是显示驱动初始化失败了。 MaixCAM 的底层的显示驱动目前（2024.7）是和摄像头驱动绑定在一起初始化的，所以遇到这个问题多半是摄像头驱动初始化失败了。 解决方法： * 尝试更新到最新的系统，安装最新的运行库（重要！！！）因为运行库需要和系统里面的驱动配合工作，版本不一致可能会出错，所以更新到最新的镜像安装最新运行库即可一般就能解决。 * 有可能是多个进程一起企图占用驱动，最简单粗暴的方法就是重启。 * 硬件上摄像头连接有问题，检查摄像头硬件连接，以及摄像头是否损坏。 ## Runtime、MaixPy、系统镜像有什么区别，我应该升级哪个？ * **Runtime** 是运行时环境，系统很多功能依赖这个，包括 MaixPy 也依赖此环境，遇到无法运行程序的问题首先联网检查更新这个。 * 系统镜像包含了基本的操作系统、硬件驱动、内置应用，以及 MaixPy 固件等，是基础环境，最好是保持最新, 特别是在[Release](https://github.com/sipeed/MaixPy/releases)页面中版本更新中提到了系统有更新，则强烈建议更新系统，因为有些 MaixPy 功能可能依赖系统里面的驱动。 > 更新系统会格式化所有之前的数据，更新前请备份好设备系统中有用的数据。 * **MaixPy** 是运行 MaixPy 程序的依赖库，如果不需要更新系统功能，以及更新日志中没有提到系统有重要更新比如驱动，那可以单独更新 MaixPy 即可，不过以防有驱动变化，最好是直接重新烧录系统。 ## 加载 MUD 模型文件报错 *****.cvimodel not exists， load model failed * 检查设备中（注意不是电脑里面，需要传到设备里面去）是否真的存在你加载的 .mud 文件。 * 检查你写的模型路径写错没有。 * 如果你改过文件名，需要注意： MUD 文件是一个模型描述文件，可以用文本编辑器编辑，实际的模型文件是 .cvimodel 文件（对于MaixCAM)，.mud 文件中指定了 .cvimodel 的文件名和路径，所以如果你改动了 `.cvimodel`的文件名，那么也要修改`.mud`文件中的`model`路径，比如这里 Yolov5 模型的 mud： ```ini [basic] type cvimodel model yolov5s_224_int8.cvimodel [extra] model_type yolov5 input_type rgb mean 0, 0, 0 scale 0.00392156862745098, 0.00392156862745098, 0.00392156862745098 anchors 10,13, 16,30, 33,23, 30,61, 62,45, 59,119, 116,90, 156,198, 373,326 labels person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair drier, toothbrush ``` 这里制定了 `model` 为相对这个`.mud`文件目录的 `yolov5s_224_int8.cvimodel` 文件为模型文件，如果你改了`yolov5s_224_int8.cvimodel` 为其它名，那也需要改这里。 ## MaixVision import maix 显示红色波浪线 \"maix\" is not accessed MaixVision 显示 `no maix moudle` `\"maix\" is not accessed` 或者 `Import \"maix\" could not be resolved`。 这是 MaixVision 的代码提示功能报错找不到 maix 模块。 这里需要搞清楚一个概念： MaixVision 的代码提示依赖的是电脑本地的 Python 包，代码运行依赖的设备端的 Python 包，所以要让 MaixVision 能够提示就要在电脑上也安装 Python 和 `MaixPy` 包。具体请看[MaixVision 使用文档](./basic/maixvision.html)。 ## MaixVision 如何编写多个文件，一个文件导入另一个文件的代码 仔细阅读 [MaixVision 使用文档](./basic/maixvision.html)。 ## MaixCAM 启动非常缓慢，甚至超过了 1 分钟，或者屏幕在闪动 多半是由于供电不足造成的， MaixCAM 需要 5v 150mA~500mA 左右的电压和点流，如果你遇到了这种现象，可以使用 USB 转 TTL 模块连接 MaixCAM 的串口到电脑，可以看到`Card did not respond to voltage select! : 110` 这样的字样，说明供电不足，换一个更加的稳定的供电设备即可。 对于 MaixCAM，在开机会有 400mA 的电流，待机且屏幕有显示需要 250mA，全速运行 AI 模型需要 400mA~500mA 的电流，所以保证电源的稳定性十分重要！ ## MaixCAM 黑屏无法启动，或者卡在 LOGO 界面 参考[MaixCAM FAQ](https://wiki.sipeed.com/hardware/zh/maixcam/faq.html) ## MaixVision 启动程序一直“卡在“ start running ... MaixVision 的日志输出窗口在开始启动程序是会打印一句`start running ...`代表程序开始发送到设备并开始执行， 后面再打印（输出）什么取决于你的程序，比如你调用了`print(\"hello\")` 则会打印`hello`，如果你的程序没有任何打印那就不会有任何日志。。。 所以实际上不是卡住了，而是你的程序就没有输出过任何东西，自然也就不会显示任何日志了，可以尝试在自己的程序中加`print(\"xxx\")`来打印，这也是我们调试程序最简单的方法。 ## 为什么硬件有 256MB 内存，在系统里只能用 128MB 内存呢？ 因为其它内存给底层驱动和内核预留了，用于摄像头、屏幕、硬件编解码、NPU 等驱动使用，可以通过 `cat /sys/kernel/debug/ion/cvi_carveout_heap_dump/summary` 看到驱动使用的内存（算能特有，叫 ION 内存），以及其它内存可以通过`cat /proc/meminfo`看到，如果你想调整内存分配，需要自己编译系统，修改系统的`LicheeRV Nano Buildbuild/boards/sg200x/sg2002_licheervnano_sd/memmap.py` 文件中的 `ION_SIZE` 来调整（看[定制系统文档](./pro/compile_os.html)）。 ## 为什么无法安装运行库，提示错误 请求失败! * 请保证设备已经成功连接到互联网，可以换一个手机热点试试。 * 确保系统镜像是烧录的最新的。 * 如果提示 DNS 解析失败，可能时网络 DNS 设置问题，可以换一个手机热点试试，或者手动修改 `/boot/resolv.conf`(只修改这个文件需要重启) 和 `/etc/resolv.conf`（修改了这个文件不用重启，重启就是把前者拷贝覆盖到这个文件）中的 DNS 服务器设置。 * 确保你是从 Sipeed 购买的正版 MaixCAM。 * 咨询客服，带上系统版本可以 device_key （可以连接上 MaixVision 点击断开连接按钮后看到，有屏幕的也可以在`系统设置 >系统信息`中看到） ## 编译报错: type not registered yet? ``` from ._maix.peripheral.key import add_default_listener ImportError: arg(): could not convert default argument into a Python object (type not registered yet?). #define ``` 显示有对象没有定义成 python 对象，在 MaixPy 中一般是由于自动扫描API生成时的顺序问题造成的，比如在`a.hpp`中有一个`@maixpy`声明的`API`， 在`b.hpp` 中有另一个`API`而且参数使用了`a.hpp`中的定义，那么可以说`b.hpp`需要依赖`a.hpp`，但目前`MaixPy`的编译脚本不会做依赖关系扫描，所以需要在`MaixPy`项目中的`components/maix/headers_priority.txt`文件中手动指定一下，`a.hpp`在`b.hpp`前面扫描就可以了。 ## MaixVision 画面有延迟 一般情况下应该是因为用了 WiFi 传输，信号不好时或者图像分辨率过大时就会有延迟。 解决方法就是： * 更换有线方式连接，具体看快速入门文档。 * 减小图像分辨率，在代码中 `disp.show(img)` `img` 的分辨率小一点。 ## 运行应用时提示: Runtime error: mmf vi init failed 提示信息的意思是摄像头初始化失败了，可能的原因有:1. 摄像头被其他应用占用了; 2. 摄像头没有排线松了; 3. 没有安装运行库 解决步骤： 1. 检查maixvision的程序和板子自带程序是否同时运行，确保只有一个地方占用摄像头(注：一般情况连接maixvision后板子自带的程序会主动退出) 2. 将摄像头排线取下来重新插一下 3. 更新最新的运行库 ## 运行应用时提示：`maix multi media driver released`或者`maix multi media driver destroyed` 这不是错误日志，这是多媒体框架释放资源时的提示信息，一般在程序退出时会打印 ## 为什么不能显示中文 默认只有英文字体，如果要显示中文，需要更换中文字体，具体请看[基本图像操作 中文支持和自定义字体 部分](./vision/image_ops.md#中文支持和自定义字体) ## 程序退出并提示 app exit with code: 1, log in /maixapp/tmp/last_run.log 这是因为程序出错异常退出了，需要尝试看日志来找到问题所在。 看日志方法： * 方法一： 出错后立即查看 `/maixapp/tmp/last_run.log` 文件，查看方式： 1. MaixVision 运行 `MaixPy/examples/tools/show_last_run_log.py` 代码查看。 2. 在 ssh 终端中 `cat /maixapp/tmp/last_run.log` 查看。 * 方法二： * 先使用 MaixVision 连接上设备以让所有占用显示和摄像头的程序退出。 * 然后通过 ssh 连接设备进入 ssh 终端，进入方法见[Linux 基础](./basic/linux_basic.html) 中描述。 * 执行命令手动运行程序 * 如果是 Python 程序 `cd /maixapp/apps/xxx && python main.py` 这里 `xxx`是出错应用的 ID。 * 如果不是 Python 程序 `cd /maixapp/apps/xxx && ./xxx` 这里 `xxx`是出错应用的 ID。 * 仔细查看日志看有没有报错，注意报错可能不在最后一行，可以从后往前仔细查找。 * 方法三：如果是 Python 编写的应用，使用 MaixVision 运行源码查看运行错误并修正，注意报错可能不在最后一行，可以从后往前仔细查找。 ## 如何读写 SD/TF 卡，保存数据到 SD/TF 卡 MaixPy 基于 Linux 和 标准 Python3，操作系统在 SD/TF 卡上，同时文件系统也在 SD 卡上，保存和读取数据都从文件系统操作。 使用 Python 的标准 API 即可操作，比如读取文件： ```python with open(\"/root/a.txt\", \"r\") as f: content f.read() print(content) ``` 类似的，其它在文档中没介绍的功能可以尝试搜一艘是不是 Python 自带的库，可以直接调用。 ## 取图时出现`camera read timeout`的错误 这可能是在取图时摄像头缓存的图片缓存区没有新图片,导致取图超时.大部分情况是由于读图太快, 或者有多个Camera通道在同时读图时会遇到, 例如将一个Camera通道绑定到Rtsp服务后, 又在另一个线程从第二个Camera通道取图. 解决方法是捕获到异常后稍等片刻再次尝试取图, 参考代码: ```python img None try: img cam.read() except: time.sleep_ms(10) continue ``` ## 程序运行时出现 CVI_VENC_GetStream failed with 0xc0078012 这是因为上次程序没有正常退出，导致venc模块资源没有释放，再次启动应用就拿不到venc的资源了。 目前解决方法是： 1. 重启系统 2. 关掉maixvision的预览视图，或者切换到png流 由于这是底层框架上遗留的问题，目前只能从应用层解决，尽量保证程序正常的退出 ## 如何卸载已经安装的应用 在开发板 `应用商店` 中可以直接卸载已经安装的应用，请看[应用使用文档](./basic/app.html)。 ## 画面怎么很模糊，像加了高斯模糊一样 对于 MaixCAM， 镜头是需要手动对焦的，物理上拧镜头即可实现调焦。 ## No module named 'lcd' 'sensor'，OpenMV 的代码如何移植/兼容 OpenMV 的代码 MaixPy (v4) 兼容了 OpenMV 和 MaixPy v1 的代码，都放到了`maix.v1`模块下，比如 OpenMV 和 MaixPy v1 中： ```python import lcd, sensor ``` 在 MaixPy (v4) 中： ```python from maix.v1 import lcd, sensor ``` 或者直接导入所有兼容包（不推荐，程序可读性变差）： ```python from maix.v1 import * import lcd, sensor ``` 最新的 MaixPy 兼容 OpenMV/MaixPy v1 的方式是在新 API 的基础上封装了一个兼容层，源码在[https://github.com/sipeed/MaixPy/tree/main/maix/v1](https://github.com/sipeed/MaixPy/tree/main/maix/v1)。 所以**强烈推荐升级到新的 MaixPy API**，API 更丰富而且更高效。 如果一定要用旧的 API 而且发现某个 API 官方没有实现，可以尝试修改上述源码支持，底层调用新的API即可，然后提交贡献到[https://github.com/sipeed/MaixPy](https://github.com/sipeed/MaixPy) 即可，方法可以参考[参与 MaixPy 项目文档](./source_code/contribute.html) ## MaixCAM 自带的相机 APP 拍摄的照片和视频存在哪儿，怎么导出到电脑 MaixCAM 自带的**相机**应用拍摄的照片和视频可以在自带的**相册**应用看到照片，点击`Info`按钮可以看到照片路径。 通过 [MaixVision 的文件管理功能](./basic/maixvision.html) 或者其它拷贝工具（比如scp 或者 winscp）即可拷贝到电脑上。 ## 没有网络，文档有离线版本吗 有的。 提供 HTML 格式的离线文档，到[MaixPy release 页面](https://github.com/sipeed/MaixPy/releases) 找到`maixpy_v*.*.*_doc.zip` 下载。 解压后有`html`文件夹，保证电脑安装了`Python`，执行下面的`chmod +x ./view_doc.sh && view_doc.sh`(Linux/MacOS)或者`view_doc.bat`(Windows)。 然后访问`http://电脑IP:8000/maixpy/index.html`即可离线查看文档。 另外如果你只是想离线查看某一篇文档，你也可以在文档页面按`Ctrl+ P` 选择打印为 PDF 来保存单页面为 PDF到本地。"},"/maixpy/doc/zh/pro/customize_model.html":{"title":"为 MaixCAM MaixPy 添加新的 AI 模型","content":" title: 为 MaixCAM MaixPy 添加新的 AI 模型 update: date: 2024 11 01 author: neucrack version: 1.0.0 content: 新增移植文档 ## 简介 除了 MaixPy 自带的 AI 算法和模型外， MaixPy 有很大的扩展能力，你可以自己添加新的算法和模型。 因为视觉应用比较多，以下将分为视觉应用和其它应用进行讲解。 ## 如果 MaixPy 已经支持的框架，只是数据集不同 比如 MaixPy 已经支持了 YOLO11 检测，但是你的数据集不同，这种情况下，你只需要准备好数据集，然后训练模型，导出模型即可。 还有一个偷懒的最快的方式，就是先去网上找找有没有人已经训练好了模型或者开源了模型，下载转一下格式就能用了，或者基于其继续训练。 举个例子: 比如要识别火焰，在网上一搜，找到[Abonia1/YOLOv8 Fire and Smoke Detection](https://github.com/Abonia1/YOLOv8 Fire and Smoke Detection) 这个项目分享了基于 YOLOv8 的火焰和烟雾检测模型，下载下来，导出成 ONNX 格式再转换为 MaixPy 支持的格式即可。 可以上传到[MaixHub 模型库](https://maixhub.com/model/zoo)分享给更多人使用，也可以找其他人分享的模型。 ## 在 Python 层面添加视觉 AI 模型和算法 对于视觉，一般来说是对图像进行时别，即： * 输入：图像 * 输出：任何数据，比如分类、概率、图像、坐标等 在`MaixPy`中我们以常用的算法比如`YOLO11`检测为例： ```python from maix import nn, image detector nn.YOLO11(model \"/root/models/yolo11n.mud\", dual_buff True) img image.Image(detector.input_width(), detector.input_height(), detector.input_format()) objs detector.detect(img, conf_th 0.5, iou_th 0.45) for obj in objs: img.draw_rect(obj.x, obj.y, obj.w, obj.h, color image.COLOR_RED) msg f'{detector.labels[obj.class_id]}: {obj.score:.2f}' img.draw_string(obj.x, obj.y, msg, color image.COLOR_RED) ``` 可以看到先构建`YOLO11`对象读取模型，然后将图片传给`detect`方法时别，每一步内部分别做了： * nn.YOLO11()： 构造对象，读取加载模型到内存，解析模型。 * detector.detect(): * 预处理图像，一般是标准化图像即 `(值 mean) * scale` 将像素值调整到一个合适的范围比如[0,1]，这个由训练模型时决定，运行时要和训练时用的方法一致。 * 运行模型，将预处理好的数据发给 NPU，让 NPU 按照模型的网络进行计算，得到 AI 模型网络的最后 N 层输出，一般是 浮点 型数据。 * 后处理，一般模型的输出不是最后的结果，还要对模型的输出进行一定的处理才能得到结果。 所以，我们要添加一个新的模型和算法，也就是要自己实现一个类似 `YOLO11` 这样的类，伪代码： ```python class My_Model: def __init__(self, model : str): pass # 解析模型，可以自定义一个 MUD 文件从里面解析，比如解析出 mean scale 的值 def recognize(self, img : image.Image): pass # 预处理图像 # 运行模型 # 后处理 # 返回结果 ``` 我们借助 `nn.NN` 类可以实现模型解析和运行，具体方法可以看 [API](http://127.0.0.1:2333/maixpy/api/maix/nn.html#NN) 文档。 通过`nn.NN`我们可以解析我们写的`mud`模型描述文件，比如得到预处理的`mean`和`scale`的值，然后用`nn.NN.forward_image()`方法运行模型，这个方法集成了预处理和运行模型两个步骤可以减少内存拷贝会更快，如果你的预处理更复杂，可以自己写预处理然后调用`forward`方法运行模型得到模型的输出结果。 比如我们以分类模型为例，不使用内置的`nn.Classifier` 类，而是自己实现一个试试： ```python from maix import nn, image, tensor import os import numpy as np def parse_str_values(value : str) > list[float]: if \",\" in value: final [] values value.split(\",\") for v in values: final.append(float(v)) return final else: return [float(value)] def load_labels(model_path, path_or_labels : str): path \"\" if not (\",\" in path_or_labels or \" \" in path_or_labels or \"\\n\" in path_or_labels): path os.path.join(os.path.dirname(model_path), path_or_labels) if path and os.path.exists(path): with open(path, encoding \"utf 8\") as f: labels0 f.readlines() else: labels0 path_or_labels.split(\",\") labels [] for label in labels0: labels.append(label.strip()) return labels class My_Classifier: def __init__(self, model : str): self.model nn.NN(model, dual_buff False) self.extra_info self.model.extra_info() self.mean parse_str_values(self.extra_info[\"mean\"]) self.scale parse_str_values(self.extra_info[\"scale\"]) self.labels self.model.extra_info_labels() # self.labels load_labels(model, self.extra_info[\"labels\"]) # same as self.model.extra_info_labels() def classify(self, img : image.Image): outs self.model.forward_image(img, self.mean, self.scale, copy_result False) # 后处理， 以分类模型为例 for k in outs.keys(): out nn.F.softmax(outs[k], replace True) out tensor.tensor_to_numpy_float32(out, copy False).flatten() max_idx out.argmax() return self.labels[max_idx], out[max_idx] classifier My_Classifier(\"/root/models/mobilenetv2.mud\") file_path \"/root/cat_224.jpg\" img image.load(file_path, image.Format.FMT_RGB888) if img is None: raise Exception(f\"load image {file_path} failed\") label, score classifier.classify(img) print(\"max score:\", label, score) ``` 可以看到这里我们： * 加载模型，从模型的`mud`文件中获取到`mean` `scale`参数并解析成`float`类型 * 识别图片，直接调用`forward_image` 函数得到模型输出。 * 这里我们的模型最后的输出是没有经过`softmax`计算的（取决于模型本身以及导出模型时选择的节点），所以我们需要进行 softmax 后处理。 * 然后我们只取了一个最大概率的类别进行了显示作为例子。 注意到这里的后处理比较简单，只是一个 softmax 计算，对于更复杂的模型，可能有更复杂的后处理，比如 YOLO 的后处理就相对复杂，我们把 YOLO 模型后面的 CPU 计算的不适合量化的部分节点从模型中去掉并手动编写后处理完成。 ## 添加其它类型数据的 AI 模型和算法 对于其它类型的数据，比如音频数据，运动传感器数据等： * 输入：任何数据，比如音频数据，IMU 数据，压力数据等。 * 输出：任何数据，比如分类、概率、控制值等。 可以看到这里和视觉模型不同的就是输入数据类型，对于图片输入，我们用`forward_image`函数能高效地预处理图像并运行模型，对于非图像，我们可以用`forward`函数来运行裸`float32`数据。 按照`forward`函数的要求准备参数即可，这里比较麻烦就是准备`tensor.Tensors`类型的输入数据，可以通过 `numpy`数据转过来： ```python from maix import nn, tensor, time import numpy as np input_tensors tensor.Tensors() for layer in model.inputs_info(): print(layer) data np.zeros(layer.shape, dtype np.float32) t tensor.tensor_from_numpy_float32(data) input_tensors.add_tensor(layer.name, t, True, True) outputs model.forward(input_tensors, copy_result False, dual_buff_wait True) del input_tensors_li ``` 这样就实现了传裸数据给模型了。 另外这个代码还可以减少拷贝来加速运行，只不过写不好程序容易出错，可以参考： ```python from maix import nn, tensor, time import numpy as np input_tensors tensor.Tensors() input_tensors_li [] for layer in model.inputs_info(): print(layer) data np.zeros(layer.shape, dtype np.float32) t tensor.tensor_from_numpy_float32(data, copy False) input_tensors.add_tensor(layer.name, t, False, False) # we use `copy False` for add_tensor, so input_tensors' data is borrowed from t, # so we add to global var to prevent t to be collected until we don't use input_tensors anymore. input_tensors_li.append(t) outputs model.forward(input_tensors, copy_result False, dual_buff_wait True) del input_tensors_li ``` ## C++ 层面添加 AI 模型和算法 在 Python 层面写程序会比较快速地就能验证模型，不过如果后处理或预处理太复杂会导致程序运行比较慢，这种情况下可以考虑使用 C++ 进行封装。 可以参考 [YOLO11](https://github.com/sipeed/MaixCDK/blob/main/components/nn/include/maix_nn_yolo11.hpp) 的源码写即可。 另外， 用 C++ 写的好处是不光可以给 C++ 使用，也可以给 MaixPy 使用，只需要给类添加`@maixpy maix.nn.YOLO11` 这样的注释，编译后就能用在`MaixPy`通过`maix.nn.YOLO11`调用了，是不是非常方便。"},"/maixpy/doc/zh/pro/compile_os.html":{"title":"为 MaixCAM 编译系统","content":" title: 为 MaixCAM 编译系统 ## 为什么需要定制系统 正常情况下你只需要从 [https://github.com/sipeed/MaixPy/releases](https://github.com/sipeed/MaixPy/releases) 下载到适合 MaixCAM 的最新系统使用即可。 有些情况需要定制系统，比如： * 比如你要量产 1k 个产品，都想放一个自己的应用，并且自动开机启动，不想一个一个配置，就可以改一下`builtin_files`，然后打包一个系统，所有板子一烧录就自带了自定义的文件，不要开及后再拷贝一次。 * 现在官方的系统没有你想要的软件包或者驱动，可以自己编译系统，选择自己想要的软件包编译定制的系统。 ## 基础系统获取 原理是系统来自 [https://github.com/sipeed/LicheeRV Nano Build/releases](https://github.com/sipeed/LicheeRV Nano Build/releases) 作为基础系统（不能直接给 MaixCAM 烧录使用，否则有烧坏屏幕风险），然后将 MaixCAM 定制的相关文件拷贝到基础系统重新打包成 MaixCAM 能用的系统。 如果不需要对基础系统进行自定义，直接从 [https://github.com/sipeed/LicheeRV Nano Build/releases](https://github.com/sipeed/LicheeRV Nano Build/releases) 下载最新的系统镜像包即可。 如果基础系统无法满足你的要求，比如你需要自定义增删一些软件包和驱动等，按照 [https://github.com/sipeed/LicheeRV Nano Build](https://github.com/sipeed/LicheeRV Nano Build) README 文档进行编译， 尽量使用 docker 编译以避免遇到编译环境问题，以及使用`bash`，不要使用`zsh`。 注意编译出来的系统不能直接给 MaixCAM 烧录使用，否则有烧坏屏幕风险。 ## 为 MaixCAM 拷贝文件 准备以下内容： * 基础系统，是一个 `.img` 或者 `.img.xz` 文件。 * 对于 MaixCAM 还需要放一些额外的文件进去，到[MaixPy release](https://github.com/sipeed/MaixPy/releases) 下载最新的 `builtin_files.tar.xz` 文件。 > 如果你需要放一些自定义的文件进系统，可以解压后往目录里面填加，比如你想系统烧录后 `/root` 目录下就会有一个 `cat.jpg`， 那么就往这里 `root` 目录下放一个 `cat.jpg`。 * 下载或克隆 MaixPy 源码到本地。 * 编译 MaixPy 获得 `.whl` 安装包文件，你也可以到 [MaixPy release](https://github.com/sipeed/MaixPy/releases) 下载最新的安装包。 到`MaixPy/tools/os`目录下，执行 ```shell ./gen_os.sh <base_os_filepath> <maixpy_whl_filepath> <builtin_files_dir_path> <skip_build_apps> <device_name> ``` 这里参数说明： * **base_os_filepath**: 基础系统路径, img 或者 img.xz 格式。 * **maixpy_whl_filepath**： MaixPy 软件包， whl 格式。 * **builtin_files_dir_path**： MaixCAM 自定义文件， 可以在 MaixPy release 下载到最新的。 * **os_version_str**: 系统版本，格式要满足类似 `maixcam 2024 08 16 maixpy v4.4.21` 的规范。 * **skip_build_apps**: 跳过编译内置应用，可选参数，传 `1` 则会跳过，传 `0` 会将 MaixCDK 和 MaixPy 中的应用都编译并拷贝到系统中。 * **device name**: 可以选择`maixcam` 或者 `maixcam pro`，对应了设备的型号。 举例： ```shell ./gen_os.sh '/home/xxx/.../LicheeRV Nano Build/install/soc_sg2002_licheervnano_sd/images/2024 08 13 14 43 0de38f.img' ../../dist/MaixPy 4.4.21 py3 none any.whl '/home/xxx/.../maixcam_builtin_files' 0 maixcam pro ``` 等待编译内置应用以及拷贝完成，在 `MaixPy/tools/os/tmp` 目录下机会有一个`maixcam pro 2024 08 15 maixpy v4.4.21.img.xz`系统镜像了。"},"/maixpy/doc/zh/pro/memory.html":{"title":"MaixPy MaixCAM 内存使用说明","content":" title: MaixPy MaixCAM 内存使用说明 ## MaixPy MaixCAM 内存简介 MaixPy 基于 Python 语言，而 Python 语言跑在 Linux 系统上，摄像头、图像、模型、应用都需要大量内存，因为内存有限，掌握内存使用和管理方法十分重要。 我们可以通过很多种方式来获取当前的内存使用状态，使用 MaixPy 内置方法活着 Linux 通用方法即可，比如使用 Python: ```python from maix import sys print(sys.memory_info()) ``` 输出类似如下内容： ```json {'cma_total': 0, 'cma_used': 0, 'cmm_total': 2147483648, 'cmm_used': 177512448, 'hw_total': 4294967296, 'total': 2060726272, 'used': 339562496} ``` 或者 ```python import psutil # 获取虚拟内存信息 mem psutil.virtual_memory() print(f\"总内存: {mem.total / (1024 ** 3):.2f} GB\") print(f\"已用内存: {mem.used / (1024 ** 3):.2f} GB\") print(f\"空闲内存: {mem.available / (1024 ** 3):.2f} GB\") print(f\"内存使用率: {mem.percent}%\") ``` 或者命令行使用`cat /proc/meminfo` 或者使用`free`命令都可以看到。 从这里的 `total` `used`可以看到全部可用内存和已经使用的内存。 不过需要注意的是，这里看到的内存是 Linux 用户空间能使用的内存，小于实际内存，比如对于 4GiB 内存的 MaixCAM2，默认这里 是 1GiB，至于为什么这样，且看下文。 ## MaixPy MaixCAM 内存划分 由于使用了 Linux 系统，我们将内存根据用途划分几个区域： 区域 作用 大小 保留 底层驱动和特殊用途，不同设备和厂商不一样 不同设备不同，一般比较小 内核预留 给 Linux 内核专用的内存 根据物理内存大小和内核驱动调整，比如 MaixCAM2 大约 80MiB 用户内存 Linux 用户空间程序使用 根据物理内存大小和应用程序内存用量调整，比如 MaixCAM2 为 1.92GiB 左右 CMA 内存 Contiguous Memory Allocator, 连续内存分配区域，Linux 显卡/图像等使用 根据图像相关应用配置 CMM 内存 Contiguous Memory Management, 厂商或用户自定义连续内存分配区域，注意这不是 Linux 标准，一般作用和 CMA 类似，为了和CMA区分这里我们姑且称之为 CMM ， 比如 MaixCAM 图像都不用标准 CMA 内存，而是自定义了一块区域给 摄像头/NPU 等硬件驱动使用 根据应用使用情况分配，比如 MaixCAM2 默认 1GiB， MaixCAM 默认 128MiB 这里我们最需要关注的是两种内存： * **Linux 用户空间内存**：这是我们代码和应用程序能用到的总内存，比如分配数组、创建对象，加载程序都需要用到这部分内存。 * **CMM内存/CMA内存**： 对于 MaixCAM 系列，没有显卡的情况下，一般 CMA 为 0 即不使用，芯片厂商都喜欢自己定义一套规范，比如 MaixCAM 和 MaixCAM2 都使用了自定义的内存区域用来给 摄像头/NPU 等需要频繁使用大内存的驱动和应用使用，以提高运行效率和减少内存碎片化。比如： * **摄像头读取一帧图像**：先将图像读取到这部分内存中，在 Linux 用户空间如果要查看图像，再将这部分内存直接映射或者拷贝到用户空间。所以一般来说应用设置摄像头分辨率越大，就需要占用更多的内存。 * **NPU 跑模型**：加载模型时不是加载在用户空间内存的，是加载在自定义内存，比如 LLM 模型有 1.5GiB，那么需要保证这部分内存大于 1.5GiB 才能正常加载模型。 ## 不同设备默认值 设备 硬件内存大小 Linux 内核 + 用户空间 CMM CMA MaixCAM 256MiB 151MiB 105MiB 0MiB MaixCAM2 4GiB 1GiB 3GiB 0MiB MaixCAM2 1GiB 512MiB 512MiB 0MiB ## 调整内存分配 如上所说，一般应用用默认值就足够了，如果你想调整大小，比如让 CMM 内存更多以加载更大的模型，则可以自己修改分配。 由于一般 CMM 是 CPU 厂商设计的，所以不同设备修改方法： * MaixCAM: MaixCAM 的 CMM 厂商实际叫作 ION 内存，修改比较麻烦，必须重新编译系统，参考[github 修改](https://github.com/sipeed/LicheeRV Nano Build/commit/713161599e1b590249b1cd8a9e7f2a7f68d8d52d)。 * MaixCAM2: MaixCAM 的 CMM 厂商就叫作 CMM 内存，MaixCAM2 镜像做了优化，只需要修改 `/boot/configs` 中的 `maix_memory_cmm 2048` 修改为想要的大小就好了，单位是 MiB， 默认值是 1 代表使用默认值。"},"/maixpy/doc/zh/pro/datasets.html":{"title":"MaixCAM MaixPy 训练模型哪里能找到模型和数据集","content":" title: MaixCAM MaixPy 训练模型哪里能找到模型和数据集 ## 哪里找 MaixPy MaixCAM 直接能使用的模型 到[MaixHub 模型库](https://maixhub.com/model/zoo) 筛选对应的硬件平台即可找到。 ## 数据集有什么用 可以先到[MaixHub 模型库](https://maixhub.com/model/zoo)看看有没有你需要的模型，如果没有，你可以自己训练模型，训练模型需要数据集，数据集就是用来训练模型的。 ## 转换已有的模型给 MaixCAM MaixPy 使用 MaixPy 默认支持了一些模型框架，比如 YOLOv8/YOLO11/Mobilenet 等等，所以只要是这些框架训练的模型，只需要导出成 ONNX 格式再转换为 MaixCAM 支持的格式后 MaixPy MaixCAM 就可以使用了。 一些常见的数据，不自己训练，网上可以找到开源分享的训练好的预训练模型，比如 YOLO11/YOLOv8/YOLOv5 就会有很多，比如[这里](https://github.com/Eric Canas/qrdet/releases)可以下载到检测二维码的 YOLOv8 与训练模型(qrdet *.pt)，直接拿来导出成 ONNX 格式再转换为 [MaixCAM 支持的格式](https://maixhub.com/model/zoo/480)即可。 转换方法看[MaixCAM 模型转换文档](../ai_model_converter/maixcam.html)。 ## 哪里找数据集 * 方法一：去算法官方官方找数据集。 比如对于 YOLO11/YOLOv8， [YOLO 官方文档 数据集](https://docs.ultralytics.com/datasets/) 中可以看到有很多开源数据集，按照其文档使用一行命令就能快速训练。同样导出 ONNX 格式再转换为 MaixCAM 支持的格式即可。 * 方法二：去数据集网站获取。 比如 [Kaggle](https://www.kaggle.com/datasets/riondsilva21/hand keypoint dataset 26k)、 [roboflow](https://universe.roboflow.com/)等等。 * 方法三：找开源数据集制作成模型训练脚本（比如 YOLO）支持的格式。"},"/maixpy/doc/zh/peripheral/pwm.html":{"title":"MaixCAM MaixPy 使用 PWM","content":" title: MaixCAM MaixPy 使用 PWM update: date: 2025 08 08 author: Neucrack version: 1.1.0 content: 重构文档，更以于初学者理解 ## 前置知识 请先学会使用[pinmap](./pinmap.html) 模块设置引脚功能。 要让一个引脚能使用 `PWM` 功能，先用`pinmap`设置对应引脚功能为`PWM`。 ## PWM 简介 使用 `PWM` 可以通过一个引脚输出一个方波，设置合适的周期和占空比（低电平占整个周期的比例）可以在不同场景中发挥作用，比如： * 控制舵机转向。 * 控制无刷电机旋转速度。 * 控制灯光亮度（PWM 调光）。 关于更多 PWM 基础知识，网上有很多好教程，本文不展开讲解，请自行搜索学习。 ## 选择合适的 PWM 使用 首先我们需要知道设备有哪些引脚和 PWM，如图： 设备型号 引脚简图 引脚复用说明 MaixCAM ![](https://wiki.sipeed.com/hardware/zh/lichee/assets/RV_Nano/intro/RV_Nano_3.jpg) 板子丝印比如`A19`是引脚名，`PWM7`是功能名 MaixCAM Pro ![maixcam_pro_io](/static/image/maixcam_pro_io.png) 第一个名如`A19`是引脚名，对应`PWM7`是功能名 MaixCAM2 ![maixcam2_io](/static/image/maixcam2_io.png) 第一个名如`B25`是引脚名，对应`PWM6`是功能名 需要注意的是，引脚默认可能用做其它用途，最好避开这些引脚，请看[pinmap](./pinmap.html) 文档中的说明。 比如： * `MaixCAM/MaixCAM Pro`: 因为`WiFi` 使用了`SDIO1`的所有引脚，所以`PWM4~9`不建议使用。 * `MaixCAM2`: 默认有 4个 PWM 引脚可以直接使用，照明 LED 也可以用`PWM6` 控制，注意`PWM6` 只能在`A30`和照明 LED 二选一使用。 ## MaixPy 使用 PWM 控制 LED 亮度 利用人眼的暂留效应，一直打开 LED 就是最亮，不停高速开关 LED 就能实现调亮度，关的时间占比越长就越暗。 ```python from maix import pwm, time, pinmap, sys, err # get pin and pwm number according to device id device_id sys.device_id() if device_id \"maixcam2\": pin_name \"B25\" # LED light pwm_id 6 else: pin_name \"A18\" # A18 pin pwm_id 6 # set pinmap err.check_raise(pinmap.set_pin_function(pin_name, f\"PWM{pwm_id}\"), \"set pinmap failed\") SERVO_PERIOD 100000 # 100kHz 0.01ms out pwm.PWM(pwm_id, freq SERVO_PERIOD, duty 0, enable True) for i in range(100): print(i) out.duty(i) time.sleep_ms(100) for i in range(100): print(100 i) out.duty(100 i) time.sleep_ms(100) ``` ## MaixPy 使用 PWM 控制舵机 控制舵机角度就是控制占空比，不同占空比对应不同角度，可以看舵机的文档。 现在控制舵机从最小角度旋转到最大角度再旋转回最小角度： ```python from maix import pwm, time, pinmap, err SERVO_PERIOD 50 # 50Hz 20ms SERVO_MIN_DUTY 2.5 # 2.5% > 0.5ms SERVO_MAX_DUTY 12.5 # 12.5% > 2.5ms # get pin and pwm number according to device id device_id sys.device_id() if device_id \"maixcam2\": pin_name \"A31\" pwm_id 7 else: pin_name \"A19\" pwm_id 7 # set pinmap err.check_raise(pinmap.set_pin_function(pin_name, f\"PWM{pwm_id}\"), \"set pinmap failed\") def angle_to_duty(percent): return (SERVO_MAX_DUTY SERVO_MIN_DUTY) * percent / 100.0 + SERVO_MIN_DUTY out pwm.PWM(pwm_id, freq SERVO_PERIOD, duty angle_to_duty(0), enable True) for i in range(100): out.duty(angle_to_duty(i)) time.sleep_ms(100) for i in range(100): out.duty(angle_to_duty(100 i)) time.sleep_ms(100) ``` ## 更多例程 看[MaixPy examples](https://github.com/sipeed/MaixPy/tree/main/examples/peripheral/pwm)。 ## API 文档 更多 API 看 [PWM API 文档](https://wiki.sipeed.com/maixpy/api/maix/peripheral/pwm.html)"},"/maixpy/doc/zh/peripheral/i2c.html":{"title":"MaixCAM MaixPy 使用 I2C","content":" title: MaixCAM MaixPy 使用 I2C update: date: 2025 08 08 author: Neucrack version: 1.1.0 content: 重构文档，更以于初学者理解 ## 前置知识 请先学会使用[pinmap](./pinmap.html) 模块设置引脚功能。 要让一个引脚能使用 `I2C` 功能，先用`pinmap`设置对应引脚功能为`I2C`。 ## I2C 简介 `I2C` 使用两个引脚`SCL` `SDA` 即可实现总线通信，即一个主机可以挂多个从机，实现一对多通信，十分方便。 常用来： * 读取传感器数据，比如温湿度、IMU、触摸屏。 * 控制设备，比如设置摄像头参数。 * 两个设备通信。 关于 I2C 基础知识，网上有很多好教程，本文不展开讲解，请自行搜索学习。 ## 选择合适的 I2C 使用 首先我们需要知道设备有哪些引脚和 I2C，如图： 设备型号 引脚简图 引脚复用说明 MaixCAM ![](https://wiki.sipeed.com/hardware/zh/lichee/assets/RV_Nano/intro/RV_Nano_3.jpg) 板子丝印比如`A15`是引脚名，`I2C5_SCL`是功能名 MaixCAM Pro ![maixcam_pro_io](/static/image/maixcam_pro_io.png) 第一个名如`A15`是引脚名，对应`I2C5_SCL`是功能名 MaixCAM2 ![maixcam2_io](/static/image/maixcam2_io.png) 第一个名如`A1`是引脚名，对应`I2C6_SCL`是功能名 需要注意的是，引脚默认可能用做其它用途，最好避开这些引脚，请看[pinmap](./pinmap.html) 文档中的说明。 比如： * 对于`MaixCAM / MaixCAM Pro`, 引出的 `I2C1` `I2C3` 引脚和 WiFi 模块（SDIO1）重合了，所以不建议使用了，另外还有一个`I2C5`，是底层驱动软件模拟的，建议使用它，底层已经做好了驱动，使用时和使用硬件`I2C`一样。 * `MaixCAM2`引出的`I2C6 / I2C7`则是空闲的，设置了 `pinmap` 就能使用。 ## MaixPy 中使用 I2C 先用`pinmap`设置引脚功能为`I2C`，然后初始化`I2C`对象即可： ```python from maix import i2c, pinmap, sys, err # get pin and i2c number according to device id device_id sys.device_id() if device_id \"maixcam2\": scl_pin_name \"A1\" scl_i2c_name \"I2C6_SCL\" sda_pin_name \"A0\" sda_i2c_name \"I2C6_SDA\" i2c_id 6 else: scl_pin_name \"A15\" scl_i2c_name \"I2C5_SCL\" sda_pin_name \"A27\" sda_i2c_name \"I2C5_SDA\" i2c_id 5 # set pinmap err.check_raise(pinmap.set_pin_function(scl_pin_name, scl_i2c_name), \"set pin failed\") err.check_raise(pinmap.set_pin_function(sda_pin_name, sda_i2c_name), \"set pin failed\") bus i2c.I2C(i2c_id, i2c.Mode.MASTER) slaves bus.scan() print(\"find slaves:\") for s in slaves: print(f\"{s}[0x{s:02x}]\") ``` ## 更多例程 看[MaixPy examples](https://github.com/sipeed/MaixPy/tree/main/examples/peripheral/i2c)。 ## API 文档 更多 API 看 [i2c API 文档](https://wiki.sipeed.com/maixpy/api/maix/peripheral/i2c.html) ## 使用其它库 另外，由于是 Linux 标准驱动，除了使用 MaixPy 提供的 API，你也可以使用 Linux 通用库，比如`smbus / smbus2`。 使用步骤： * 在开发板终端执行`pip install smbus` 安装库。 * 使用`pinmap` 映射引脚功能。 * 调用`smbus` API 对 `i2c` 进行读写。 ```python from maix import i2c, pinmap, sys, err import smbus # get pin and i2c number according to device id device_id sys.device_id() if device_id \"maixcam2\": scl_pin_name \"A1\" scl_i2c_name \"I2C6_SCL\" sda_pin_name \"A0\" sda_i2c_name \"I2C6_SDA\" i2c_id 6 else: scl_pin_name \"A15\" scl_i2c_name \"I2C5_SCL\" sda_pin_name \"A27\" sda_i2c_name \"I2C5_SDA\" i2c_id 5 # set pinmap err.check_raise(pinmap.set_pin_function(scl_pin_name, scl_i2c_name), \"set pin failed\") err.check_raise(pinmap.set_pin_function(sda_pin_name, sda_i2c_name), \"set pin failed\") bus smbus.SMBus(i2c_id) ```"},"/maixpy/doc/zh/peripheral/key.html":{"title":"MaixCAM MaixPy 按键事件使用","content":" title: MaixCAM MaixPy 按键事件使用 update: date: 2025 01 08 version: v1.0 author: neucrack content: 添加文档 ## 简介 MaixCAM 机身自带了按键，包括 user/ok 按键，电源按键等。 默认 user/ok 按键在 MaixPy 中是退出按钮，按下会自动调用`maix.app.set_exit_flag(True)`，如果你的程序调用了`maix.app.need_exit()`作为退出依据，则按下按键就会退出程序。 另外，你也可以自定义按键的作用，自定义后上面说的默认的设置退出标志行为就会取消。 ## MaixCAM MaixPy 中读取按键 ### 默认行为，即按下会设置程序退出标志 无需显示调用，默认就有： ```python from maix import app, time cout 0 while not app.need_exit(): time.sleep(1) print(cout) cout + 1 ``` 按下按键就会退出循环了。 ### 读取按键事件和自定义回调函数 使用`key.Key`类即可，回调函数有两个参数： * `key_id`: 按键 ID，取值看[maix.key.Keys API 文档](/api/maix/peripheral/key.html#Keys)，自定义的驱动由驱动决定。 * `state`: 按键状态，取值看[maix.key.State API 文档](/api/maix/peripheral/key.html#State)。 ```python from maix import key, app, time def on_key(key_id, state): ''' this func is called in a single thread ''' print(f\"key: {key_id}, state: {state}\") # key.c or key.State.KEY_RELEASED key_obj key.Key(on_key) while not app.need_exit(): time.sleep(1) ``` 完善一些的例程： ```python from maix import image, key, app, display class App: def __init__(self): self.key_obj key.Key(self.on_key) self.disp display.Display() self.key_id 0 self.state 0 def on_key(self, key_id, state): ''' this func called in a single thread ''' print(f\"key: {key_id}, state: {state}\") # key.c or key.State.KEY_RELEASED self.key_id key_id self.state state def run(self): while not app.need_exit(): img image.Image(self.disp.width(), self.disp.height(), image.Format.FMT_RGB888) msg f\"key: {self.key_id}, state: {self.state}\" img.draw_string(0, 10, msg, image.Color.from_rgb(255, 255, 255), 1.5) self.disp.show(img) App().run() ``` ## 自定义按键驱动 MaixPy 基于 Linux 系统，你可以给系统编写按键驱动，然后在`/boot/board` 里面将自己的按键设备添加到`key_devices`键值中，支持多个设备，多个设备用逗号隔开，比如： `key_devices:/dev/my_keys1,/dev/my_keys2`。 驱动编写方法： * 方法一：内核驱动，按照通用的 Linux 驱动开发方法，使用交叉编译工具链编译出 `ko`驱动文件，开机在`/etc/init.d` 中自动加载。 * 方法二：用户层驱动，比如你的按键接到了 GPIO 上，可以直接基于 GPIO API 编写，使用`/dev/uinput`导出一个设备文件即可，具体方法可以自行搜索，这种方法需要有读取 GPIO 代码一直在运行，可以和你的程序写到一起，也可以单独写一个程序运行在后台，比较灵活。"}}